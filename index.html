<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"acking.cc","root":"/","scheme":"Muse","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="share cs knowledge">
<meta property="og:type" content="website">
<meta property="og:title" content="AcKing">
<meta property="og:url" content="http://acking.cc/index.html">
<meta property="og:site_name" content="AcKing">
<meta property="og:description" content="share cs knowledge">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Sam Shen">
<meta property="article:tag" content="Database &amp; Distributed System &amp; Algorithm">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://acking.cc/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>AcKing</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">AcKing</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">for dreams</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="en fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="en fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="en fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="en fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="en fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://acking.cc/2023/01/28/ch01/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="Sam Shen">
      <meta itemprop="description" content="share cs knowledge">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AcKing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/mit6.s081-ch1" class="post-title-link post-title-link-external" itemprop="url">mit6.s081-ch1<i class="fa fa-external-link-alt"></i></a>
          
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-01-28 00:00:00 / Modified: 20:35:57" itemprop="dateCreated datePublished" datetime="2023-01-28T00:00:00+08:00">2023-01-28</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mit6-s081/" itemprop="url" rel="index"><span itemprop="name">mit6.s081</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mit6-s081/OS/" itemprop="url" rel="index"><span itemprop="name">OS</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Chapter-1"><a href="#Chapter-1" class="headerlink" title="Chapter 1"></a>Chapter 1</h1><h3 id="主要内容"><a href="#主要内容" class="headerlink" title="主要内容"></a>主要内容</h3><p>第一节课主要是介绍课程内容，考核方式，以及宏观讲述os的结构，实际内容主要讲解若干系统调用。</p>
<p>由于系统调用是操作系统提供的服务的接口，所以系统调用长什么样，应用程序期望从系统调用得到什么返回，系统调用是怎么工作的，这些还是挺重要的。</p>
<p>整个课程中，XV6 运行在一个 RISC-V 微处理器上，实验中我们会在 QEMU 模拟器上运行 XV6。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220225010755776.png" alt="image-20220225010755776"></p>
<h3 id="read"><a href="#read" class="headerlink" title="read()"></a>read()</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span>    </span></span><br><span class="line"><span class="function"><span class="type">ssize_t</span> <span class="title">read</span><span class="params">(<span class="type">int</span> fd, <span class="type">void</span> *buf, <span class="type">size_t</span> count)</span></span>;  </span><br></pre></td></tr></table></figure>

<ul>
<li><p>第一个参数是文件描述符，指向一个之前打开的文件。Shell 会确保默认情况下，当一个程序启动时，文件描述符 0 连接到标准输入，文件描述符 1 连接到了标准输出。所以我可以通过这个程序看到控制台打印我的输入。当然，这里的程序会预期文件描述符已经被 Shell 打开并设置好。这里的 0，1 文件描述符是非常普遍的Unix 风格，许多的 Unix 系统都会从文件描述符 0 读取数据，然后向文件描述符 1 写入数据。</p>
</li>
<li><p>第二个参数是指向某段内存的指针，程序可以通过指针对应的地址读取内存中的数据。在代码第 10 行，程序在栈里面申请了 64 字节的内存，并将指针保存在 buf 中，这样 read 可以将数据保存在这64字节中。</p>
</li>
<li><p>read 的第三个参数是代码想读取的最大长度，<code>sizeof(buf)</code> 表示，最多读取 64 字节的数据，所以这里的read 最多只能从连接到文件描述符 0 的设备，也就是标准输入中，读取 64 字节的数据。</p>
</li>
</ul>
<p>返回值情况：</p>
<ul>
<li><p>read的返回值可能是读到的字节数，在上面的截图中也就是 6（ <code>xyzzy</code> 加上结束符）</p>
</li>
<li><p>read可能从一个文件读数据，如果到达了文件的结尾没有更多的内容了，read会返回 0</p>
</li>
<li><p>如果出现了一些错误，比如文件描述符不存在，read或许会返回 -1。</p>
<blockquote>
<p> 在后面的很多例子中，比如第16行，我都没有通过检查系统调用的返回来判断系统调用是否出错，但是你应该比我更加小心，你应该清楚系统调用通常是通过返回 -1 来表示错误，你应该检查所有系统调用的返回值以确保没有错误，这点和我们计算机系统安全的老师观点一致，值得重视。</p>
</blockquote>
</li>
</ul>
<h3 id="open"><a href="#open" class="headerlink" title="open()"></a>open()</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">open</span><span class="params">(<span class="type">const</span> <span class="type">char</span> * pathname, <span class="type">int</span> flags, <span class="type">mode_t</span> mode)</span></span>; </span><br></pre></td></tr></table></figure>

<p>代码中的第11行，执行了 open 系统调用，将文件名 <code>output.txt</code> 作为第一个参数传入，第二个参数是一些标志位，用来告诉 open 系统调用在内核中的实现：我们将要创建并写入一个文件。</p>
<p>open 系统调用会返回一个新分配的文件描述符，这里的文件描述符是一个小的数字，可能是2，3，4或者其他的数字。</p>
<h3 id="wirte"><a href="#wirte" class="headerlink" title="wirte()"></a>wirte()</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//函数向打开的设备或文件中写数据。</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span>   </span></span><br><span class="line"><span class="type">ssize_t</span> <span class="title function_">write</span><span class="params">(<span class="type">int</span> fd, <span class="type">const</span> <span class="type">void</span> *buf, <span class="type">size_t</span> count)</span>;  </span><br></pre></td></tr></table></figure>

<p>之后，这个文件描述符作为第一个参数被传到了 write，write 的第二个参数是数据的指针，第三个参数是要写入的字节数，数据被写入到了文件描述符对应的文件中。</p>
<p>每个进程都有一张文件描述符的表单，且<strong>这个文件描述符空间独立于其他进程</strong>，其中每一项指向不同的文件。文件描述符是独立的，但是不同进程可以同时打开相同的文件，且其文件描述符不一定相同，相同的文件描述符也可能指向不同的文件。</p>
<h3 id="shell"><a href="#shell" class="headerlink" title="shell"></a>shell</h3><p>比如，当我输入 <code>ls</code> 时，实际的意义是我要求 Shell 运行名为 <code>ls</code> 的程序，文件系统中会有一个文件名为 <code>ls</code>，这个文件中包含了一些计算机指令，所以实际上，当我输入 <code>ls</code> 时，我是在<strong>要求 shell 运行位于文件ls内的这些计算机指令。</strong></p>
<p><code>grep x</code> 会搜索输入中包含 <code>x</code> 的行，我可以告诉 shell 将输入重定向到文件 <code>out</code>，这样我们就可以查看 <code>out</code> 中的 <code>x</code>。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220225011302133.png" alt="image-20220225011302133"></p>
<h3 id="fork"><a href="#fork" class="headerlink" title="fork()"></a>fork()</h3><p>fork() 系统调用是重点，lab中会用到。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220225011344942.png" alt="image-20220225011344942">在第12行，我们调用了 fork。</p>
<p><code>fork</code> 会拷贝当前进程的内存，并创建一个新的进程，这里的内存包含了进程的指令和数据。之后，我们就有了两个拥有完全一样内存的进程。</p>
<p>fork系统调用在两个进程中都会返回，在原始的进程中，fork系统调用会返回大于0的整数，这个是新创建进程的ID，而在新创建的进程中，fork系统调用会返回 0。</p>
<p>所以即使两个进程的内存是完全一样的，我们还是可以通过 fork 的返回值区分旧进程和新进程。</p>
<blockquote>
<p>学生提问：<code>fork</code> 产生的子进程是不是总是与父进程是一样的？它们有可能不一样吗？</p>
<p>Robert教授：在XV6中，除了 <code>fork</code> 的返回值，两个进程是一样的。两个进程的指令是一样的，数据是一样的，栈是一样的，同时，两个进程又有各自独立的地址空间，它们都认为自己的内存从0开始增长，但这里是不同的内存。 在一个更加复杂的操作系统，有一些细节我们现在并不关心，这些细节偶尔会导致父子进程不一致，但是在XV6中，父子进程除了fork的返回值，其他都是一样的。</p>
<p>除了内存是一样的以外，<strong>文件描述符的表单也从父进程拷贝到子进程。</strong>所以如果父进程打开了一个文件，子进程可以看到同一个文件描述符，尽管子进程看到的是一个文件描述符的表单的拷贝。除了拷贝内存以外，fork还会拷贝文件描述符表单这一点还挺重要的。</p>
</blockquote>
<p>当我们在 Shell 中运行东西的时候，Shell 实际上会创建一个新的进程来运行你输入的每一个指令。所以，当我输入 ls 时，我们需要 Shell 通过 fork 创建一个进程来运行ls，这里需要某种方式来让这个新的进程来运行ls程序中的指令，加载名为ls的文件中的指令（也就是后面的exec系统调用）。</p>
<h3 id="exec"><a href="#exec" class="headerlink" title="exec()"></a>exec()</h3><p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220225011530170.png" alt="image-20220225011530170"></p>
<p>代码会执行exec系统调用，这个系统调用<strong>会从指定的文件中读取并加载指令，并替代当前调用进程的指令。</strong>从某种程度上来说，这样相当于<strong>丢弃了调用进程的内存，并开始执行新加载的指令。</strong></p>
<p>所以第12行的系统调用exec会有这样的效果：操作系统从名为 <code>echo</code> 的文件中加载指令到当前的进程中，并替换了当前进程的内存，之后开始执行这些新加载的指令。同时，你可以传入命令行参数，exec 允许你传入一个命令行参数的数组，这里就是一个C语言中的指针数组，在上面代码的第10行设置好了一个字符指针的数组，这里的字符指针本质就是一个字符串（string）。</p>
<p>所以这里等价于运行echo命令，并带上“this is echo” 这三个参数。所以当我运行exec文件：</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220225011637130.png" alt="image-20220225011637130"></p>
<ul>
<li><p><strong>exec 系统调用会保留当前的文件描述符表单</strong>。所以任何在 exec 系统调用之前的文件描述符，例如0，1，2等，它们在新的程序中表示相同的东西。</p>
</li>
<li><p><strong>通常来说 exec 系统调用不会返回，因为 exec 会完全替换当前进程的内存，相当于当前进程不复存在了，所以exec系统调用已经没有地方能返回了。</strong></p>
</li>
</ul>
<p>所以，exec 系统调用从文件中读取指令，执行这些指令，然后就没有然后了。exec 系统调用只会当出错时才会返回，因为某些错误会阻止操作系统为你运行文件中的指令，例如程序文件根本不存在，因为 exec 系统调用不能找到文件，exec 会返回 <code>-1</code> 来表示：出错了，我找不到文件。所以通常来说 exec 系统调用不会返回，它只会在kernel 不能运行相应的文件时返回。</p>
<blockquote>
<p>学生提问：argv 中的最后一个 0 是什么意思？</p>
<p>Robert教授：它标记了数组的结尾，我们将 0 作为最后一个指针。argv 中的每一个字符串实际上是一块包含了数据的内存指针，但是第 5 个元素是 0，通常来说指针 0 是一个 NULL 指针，它只表明结束。所以内核中的代码会遍历这里的数组，直到它找到了值为0的指针。</p>
</blockquote>
<p>展示一个 <code>forkexec.c</code> 程序：</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220225011753270.png" alt="image-20220225011753270"></p>
<p>在这个程序中的第12行，调用了fork。子进程从第14行开始，我们在子进程中与前一个程序一样调用exec。子进程会用echo命令来代替自己，echo执行完成之后就退出。之后父进程重新获得了控制。fork会在父进程中返回大于0的值，父进程会继续在第19行执行。</p>
<p>Unix提供了一个wait系统调用，如第20行所示。<strong>wait会等待之前创建的子进程退出。</strong>当我在命令行执行一个指令时，我们一般会希望shell等待指令执行完成。所以wait系统调用，使得父进程可以等待任何一个子进程返回。</p>
<p><strong>这里wait的参数status，是一种让退出的子进程以一个整数（32 bit的数据）的格式与等待的父进程通信方式。所以在第17行，exit的参数是1，操作系统会将1从退出的子进程传递到第20行，也就是等待的父进程处。&amp;status，是将status对应的地址传递给内核，内核会向这个地址写入子进程向exit传入的参数。</strong></p>
<blockquote>
<p>此处贴一下我的理解， <code>wait(&amp;status)</code> 在父进程中调用，目的是让子进程把他的 <code>exit()</code> 状态码存储到 <code>status</code> 变量中。</p>
</blockquote>
<p>Unix 中的风格是，如果一个程序成功的退出了，那么exit的参数会是0，如果出现了错误，那么就会像第17行一样，会向exit传递1。所以，如果你关心子进程的状态的话，父进程可以读取wait的参数，并决定子进程是否成功的完成了。</p>
<blockquote>
<p>注意，上面是一种常用写法，先调用 <code>fork</code> ，再在子进程中调用 <code>exec</code> 。这里实际上有些浪费， <code>fork</code> 首先拷贝了整个父进程的内存，但是随后执行的 <code>exec</code> 将这整个拷贝丢弃了，并且用将要运行的文件替换了原来的内容。</p>
<p>某种程度上来说这里的拷贝操作浪费了，因为所有拷贝的内存都被丢弃并被 <code>exec</code> 替换。在大型程序中这里的影响会比较明显。如果你运行了一个几 GB 的程序，并且调用 <code>fork</code> ，那么实际就会拷贝所有的内存，可能会要消耗将近 1 秒钟来完成拷贝，这可能会是个问题。</p>
<p>之后的课程会实现一些优化，比如说 <code>copy-on-write fork</code> ，这种方式会消除 <code>fork</code> 的几乎所有的明显的低效，而只拷贝执行 <code>exec</code> 所需要的内存，这里需要很多涉及到虚拟内存系统的技巧。你可以构建一个 <code>fork</code> ，对于内存实行懒拷贝，通常来说 fork 之后立刻是 exec，这样你就不用实际的拷贝，因为子进程实际上并没有使用大部分的内存。</p>
</blockquote>
<blockquote>
<p>学生提问：当我们说子进程从父进程拷贝了所有的内存，这里具体指的是什么呢？是不是说子进程需要重新定义变量之类的？</p>
<p>Robert教授：在编译之后， C 程序就是一些在内存中的指令，这些指令存在于内存中。所以这些指令可以被拷贝，因为它们就是<strong>内存中的字节</strong>，它们可以被拷贝到别处。通过一些有关虚拟内存的技巧，可以使得子进程的内存与父进程的内存一样，这里实际就是将父进程的内存镜像拷贝给子进程，并在子进程中执行。</p>
<p>实际上，当我们在看 C 程序时，你应该认为它们就是一些机器指令，这些机器指令就是内存中的数据，所以可以被拷贝。</p>
<p>学生提问：如果父进程有多个子进程，wait 是不是会在第一个子进程完成时就退出？这样的话，还有一些与父进程交错运行的子进程，是不是需要有多个wait来确保所有的子进程都完成？</p>
<p>Robert教授：是的，<strong>如果一个进程调用fork两次，如果它想要等两个子进程都退出，它需要调用wait两次。</strong>每个wait会在一个子进程退出时立即返回。当wait返回时，你实际上没有必要知道哪个子进程退出了，但是<strong>wait返回了子进程的进程号</strong>，所以在wait返回之后，你就可以知道是哪个子进程退出了。</p>
</blockquote>
<h3 id="IO重定向"><a href="#IO重定向" class="headerlink" title="IO重定向"></a>IO重定向</h3><p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220225012018361.png" alt="image-20220225012018361"></p>
<p>Shell 之所以有这样的能力，是因为 Shell 首先会像第 13 行一样 fork，然后在子进程中，Shell改变了文件描述符。文件描述符1通常是进程用来作为输出的（也就是控制台的标准输出），Shell会将文件描述符1改为output文件，之后再运行你的指令。同时，父进程的文件描述符1并没有改变。所以这里先fork，再更改子进程的文件描述符，是Unix中的常见的用来重定向指令的输入输出的方法，这种方法同时又不会影响父进程的输入输出。因为我们不会想要重定向Shell的输出，我们只想重定向子进程的输出。</p>
<p>我们可以看到预期的输出。代码第15行的close(1)的意义是，我们希望文件描述符1指向一个其他的位置。也就是说，在子进程中，我们不想使用原本指向console输出的文件描述符1。</p>
<p>代码第16行的open一定会返回1，因为open会返回当前进程未使用的最小文件描述符序号。因为我们刚刚关闭了文件描述符1，而文件描述符0还对应着console的输入，所以open一定可以返回1。在代码第16行之后，文件描述符1与文件output.txt关联。</p>
<p>这个例子同时也演示了分离fork和exec的好处。fork和exec是分开的系统调用，意味着在子进程中有一段时间，fork返回了，但是exec还没有执行，子进程仍然在运行父进程的指令。所以这段时间，尽管指令是运行在子进程中，但是这些指令仍然是父进程的指令，所以父进程仍然可以改变东西，直到代码执行到了第19行。这里fork和exec之间的间隔，提供了Shell修改文件描述符的可能。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://acking.cc/2023/01/28/ch03/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="Sam Shen">
      <meta itemprop="description" content="share cs knowledge">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AcKing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/mit6.s081-ch3" class="post-title-link post-title-link-external" itemprop="url">mit6.s081-ch3<i class="fa fa-external-link-alt"></i></a>
          
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-01-28 00:00:00 / Modified: 20:36:05" itemprop="dateCreated datePublished" datetime="2023-01-28T00:00:00+08:00">2023-01-28</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mit6-s081/" itemprop="url" rel="index"><span itemprop="name">mit6.s081</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mit6-s081/OS/" itemprop="url" rel="index"><span itemprop="name">OS</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Chapter-3"><a href="#Chapter-3" class="headerlink" title="Chapter 3"></a>Chapter 3</h1><h3 id="隔离性-isolation"><a href="#隔离性-isolation" class="headerlink" title="隔离性 isolation"></a>隔离性 isolation</h3><p>这一点主要体现在，multiplexing（CPU在多进程分时复用）和物理内存隔离。</p>
<p>之前通过 <code>fork</code> 创建了进程。进程本身不是CPU，但是它们对应了CPU，它们使得你可以在CPU上运行计算任务。<strong>应用程序不能直接与CPU交互，只能与进程交互。</strong>操作系统内核会完成不同进程在CPU上的切换。所以，操作系统不是直接将CPU提供给应用程序，而是向应用程序提供 <code>进程</code>，进程抽象了CPU，这样操作系统才能在多个应用程序之间复用一个或者多个CPU。</p>
<p>我们可以认为 exec 抽象了内存。当我们在执行 exec 系统调用的时候，我们会传入一个文件名，而这个文件名对应了一个应用程序的内存镜像。内存镜像里面包括了程序对应的指令，全局的数据。应用程序可以逐渐扩展自己的内存，但是应用程序并没有直接访问物理内存的权限，例如应用程序不能直接访问物理内存的 1000-2000 这段地址。不能直接访问的原因是，操作系统会提供内存隔离并控制内存，操作系统会在应用程序和硬件资源之间提供一个中间层。<strong>exec 是这样一种系统调用，它表明了应用程序不能直接访问物理内存。</strong></p>
<p>另一个例子是文件，文件基本上来说抽象了磁盘。应用程序不会直接读写挂在计算机上的磁盘本身，并且在 Unix 中这也是不被允许的。在 Unix 中，与存储系统交互的唯一方式就是通过 files。Files 提供了非常方便的磁盘抽象，你可以对文件命名，读写文件等等。之后，操作系统会决定如何将文件与磁盘中的块对应，确保一个磁盘块只出现在一个文件中，并且确保用户A 不能操作用户B 的文件。通过 files 的抽象，可以实现不同用户之间和同一个用户的不同进程之间的文件强隔离。</p>
<h3 id="防御性-defensive"><a href="#防御性-defensive" class="headerlink" title="防御性 defensive"></a>防御性 defensive</h3><p>当你在开发内核时，防御性是你必须掌握的一个思想。实际中的应用程序或许就是恶意的，这意味着我们需要在应用程序和操作系统之间提供强隔离性。</p>
<p>简单来说，就是防止应用进程攻破内核区，一般两个手段：</p>
<ul>
<li>user&#x2F;kernel mode切换</li>
<li>page table 即虚拟内存</li>
</ul>
<h3 id="硬件对于强隔离性的支持"><a href="#硬件对于强隔离性的支持" class="headerlink" title="硬件对于强隔离性的支持"></a>硬件对于强隔离性的支持</h3><p>举个例子，当一个应用程序尝试执行一条特殊权限指令，因为不允许在user mode执行特殊权限指令，处理器会拒绝执行这条指令。通常来说，这时会将控制权限从 user mode 切换到 kernel mode，当操作系统拿到控制权之后，或许会杀掉进程，因为应用程序执行了不该执行的指令。</p>
<blockquote>
<p>学生提问：那 BIOS 呢？BIOS 会在操作系统之前运行还是之后？</p>
<p>Frans教授：BIOS 是一段计算机自带的代码，它会先启动，之后它会启动操作系统，所以BIOS需要是一段可被信任的代码，它最好是正确的，且不是恶意的。</p>
<p>学生提问：之前提到，设置处理器中kernel mode的bit位的指令是一条特殊权限指令，那么一个用户程序怎么才能让内核执行任何内核指令？因为现在切换到kernel mode的指令都是一条特殊权限指令了，对于用户程序来说也没法修改那个bit位。</p>
<p>Frans教授：你说的对，这也是我们想要看到的结果。可以这么来看这个问题，首先这里不是完全按照你说的方式工作，在RISC-V中，如果你在用户空间（user space）尝试执行一条特殊权限指令，用户程序会通过系统调用来切换到kernel mode。当用户程序执行系统调用，会通过ECALL触发一个软中断（software interrupt），软中断会查询操作系统预先设定的中断向量表，并执行中断向量表中包含的中断处理程序。中断处理程序在内核中，这样就完成了user mode到kernel mode的切换，并执行用户程序想要执行的特殊权限指令。</p>
</blockquote>
<p>处理器包含了 page table，而 page table 将虚拟内存地址与物理内存地址做了对应。</p>
<p>每一个进程都会有自己独立的 page table，这样的话，每一个进程只能访问出现在自己 page table 中的物理内存。<strong>操作系统会设置 page table，使得每一个进程都有不重合的物理内存，这样一个进程就不能访问其他进程的物理内存</strong>，因为其他进程的物理内存都不在它的 page table 中。一个进程甚至都不能随意编造一个内存地址，然后通过这个内存地址来访问其他进程的物理内存。这样就给了我们内存的强隔离性。</p>
<p>page table 定义了对于内存的视图，而每一个用户进程都有自己对于内存的独立视图。这给了我们非常强的内存隔离性。</p>
<h3 id="User-x2F-Kernel-Mode-切换"><a href="#User-x2F-Kernel-Mode-切换" class="headerlink" title="User&#x2F;Kernel Mode 切换"></a>User&#x2F;Kernel Mode 切换</h3><p>我们可以认为 user&#x2F;kernel mode 是分隔用户空间和内核空间的边界，用户空间运行的程序运行在 user mode，内核空间的程序运行在 kernel mode，操作系统位于内核空间。</p>
<p>我们需要有一种方式能够让应用程序可以将控制权转移给内核。在 RISC-V 中，有一个专门的指令用来实现这个功能，叫做 <code>ECALL</code>。<code>ECALL</code> 接收一个数字参数，当一个用户程序想要将程序执行的控制权转移到内核，它只需要执行 <code>ECALL</code> 指令，并传入一个数字。这里的数字参数代表了应用程序想要调用的系统调用。</p>
<p>这里需要澄清的是，用户空间和内核空间的界限是一个硬性的界限，用户不能直接调用 <code>fork</code>，用户的应用程序执行系统调用的唯一方法就是通过 <code>ECALL</code> 指令。</p>
<blockquote>
<p>学生提问：操作系统在什么时候检查是否允许执行 <code>fork</code> 或者<code> write</code>？现在看起来应用程序只需要执行 <code>ECALL</code> 再加上系统调用对应的数字就能完成调用，但是内核在什么时候决定这个应用程序是否有权限执行特定的系统调用？</p>
<p>Frans教授：是个好问题。原则上来说，在内核侧实现 <code>fork</code> 的位置可以实现任何的检查，例如检查系统调用的参数，并决定应用程序是否被允许执行 <code>fork</code> 系统调用。在 Unix 中，任何应用程序都能调用 fork，我们以 write 为例吧，<strong>write 的实现需要检查传递给 write 的地址（需要写入数据的指针）属于用户应用程序，这样内核才不会被欺骗向别的不属于应用程序的位置写入数据。</strong></p>
<p>学生提问：当应用程序表现的恶意或者就是在一个死循环中，内核是如何夺回控制权限的？</p>
<p>Frans教授：<strong>内核会通过硬件设置一个定时器，定时器到期之后会将控制权限从用户空间转移到内核空间</strong>，之后内核就有了控制能力并可以重新调度 CPU 到另一个进程中。我们接下来会看一些更加详细的细节。</p>
</blockquote>
<h3 id="宏内核与微内核"><a href="#宏内核与微内核" class="headerlink" title="宏内核与微内核"></a>宏内核与微内核</h3><p>内核有时候也被称为可被信任的计算空间（Trusted Computing Base），在一些安全的术语中也被称为 TCB。基本上来说，要被称为 TCB，内核首先要是正确且 bug-free 的。</p>
<h4 id="宏内核"><a href="#宏内核" class="headerlink" title="宏内核"></a>宏内核</h4><p>大多数的 Unix 操作系统实现都运行在 kernel mode。比如，XV6 中，所有的操作系统服务都在 kernel mode 中，这种形式被称为 Monolithic Kernel Design（<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Monolithic_kernel">宏内核</a>）。</p>
<p>这里有几件事情需要注意：</p>
<ul>
<li>如果考虑Bug的话，宏内核不太好。在一个宏内核中，任何一个操作系统的Bug都有可能成为漏洞。因为我们现在在内核中运行了一个巨大的操作系统，出现Bug的可能性更大了。你们可以去查一些统计信息，平均每3000行代码都会有几个Bug，所以如果有许多行代码运行在内核中，那么出现严重Bug的可能性也变得更大。所以从安全的角度来说，在内核中有大量的代码是宏内核的缺点。</li>
<li>另一方面，如果你去看一个操作系统，它包含了各种各样的组成部分，比如说文件系统，虚拟内存，进程管理，这些都是操作系统内实现了特定功能的子模块。宏内核的优势在于，<strong>因为这些子模块现在都位于同一个程序中，它们可以紧密的集成在一起，这样的集成提供很好的性能</strong>。例如 Linux，它就有很不错的性能。</li>
</ul>
<h4 id="微内核"><a href="#微内核" class="headerlink" title="微内核"></a>微内核</h4><p>另一种设计主要关注点是减少内核中的代码，它被称为 Micro Kernel Design（<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Microkernel">微内核</a>）。在这种模式下，希望在 kernel mode 中运行尽可能少的代码。所以这种设计下还是有内核，但是内核只有非常少的几个模块，例如，内核通常会有一些 IPC 的实现或者是 Message passing；非常少的虚拟内存的支持，可能只支持了 page table；以及分时复用 CPU 的一些支持。</p>
<p>某种程度上来说，这是一种好的设计。因为在内核中的代码的数量较小，<strong>更少的代码意味着更少的 Bug，微内核的问题在于性能更差</strong>，这里有两个方面需要考虑：</p>
<ul>
<li><p>在 user&#x2F;kernel mode 反复跳转带来的性能损耗。</p>
</li>
<li><p>在一个类似宏内核的紧耦合系统，各个组成部分，例如文件系统和虚拟内存系统，可以很容易的共享 page cache。而在微内核中，每个部分之间都很好的隔离开了，这种共享更难实现，进而导致更难在微内核中得到更高的性能。</p>
</li>
</ul>
<h3 id="编译运行kernel"><a href="#编译运行kernel" class="headerlink" title="编译运行kernel"></a>编译运行kernel</h3><p>接下来我会切换到代码介绍，来看一下 XV6 是如何工作的。</p>
<p>首先，我们来看一下代码结构，你们或许已经看过了。代码主要有三个部分组成：</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226095531234.png" alt="image-20220226095531234"></p>
<ul>
<li>第一部分是 kernel ：我们可以 <code>ls kernel</code> 的内容，里面包含了基本上所有的内核文件。因为 XV6 是一个宏内核结构，这里所有的文件会被编译成一个叫做 <code>kernel</code> 的二进制文件，然后这个二进制文件会被运行在  kernle mode 中。</li>
</ul>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226095603980.png" alt="image-20220226095603980"></p>
<ul>
<li>第二部分是 user ：这基本上是运行在 user mode 的程序。这也是为什么一个目录称为 kernel，另一个目录称为 user 的原因。</li>
<li>第三部分是 mkfs ：它会创建一个空的文件镜像，我们会将这个镜像存在磁盘上，这样我们就可以直接使用一个空的文件系统。</li>
</ul>
<p>接下来，让我们不带 gdb 运行 XV6（make 会读取 Makefile 文件中的指令）。这里会编译文件，然后调用 QEMU（qemu-system-riscv64指令）。这里本质上是通过C语言来模拟仿真 RISC-V 处理器。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226095659801.png" alt="image-20220226095659801"></p>
<p>我们来看传给QEMU的几个参数：</p>
<ul>
<li>-kernel：这里传递的是内核文件（kernel 目录下的 kernel 文件），这是将在 QEMU 中运行的程序文件。</li>
<li>-m：这里传递的是 RISC-V 虚拟机将会使用的内存数量</li>
<li>-smp：这里传递的是虚拟机可以使用的 CPU 核数</li>
<li>-drive：传递的是虚拟机使用的磁盘驱动，这里传入的是 fs.img 文件</li>
</ul>
<p>直观来看，QEMU 是一个大型的开源C程序，你可以下载或者 <code>git clone</code> 它。<strong>但是在内部，在QEMU的主循环中，只在做一件事情：</strong></p>
<ul>
<li>读取 4 字节或者 8 字节的 RISC-V 指令。</li>
<li>解析RISC-V指令，并找出对应的操作码（op code）。我们之前在看 <code>kernel.asm</code> 的时候，看过一些操作码的二进制版本。通过解析，或许可以知道这是一个 ADD 指令，或者是一个 SUB 指令。</li>
<li>之后，在软件中执行相应的指令。</li>
</ul>
<h3 id="XV6-启动过程"><a href="#XV6-启动过程" class="headerlink" title="XV6 启动过程"></a>XV6 启动过程</h3><p>接下来，我会系统的介绍 XV6，让你们对 XV6 的结构有个大概的了解。在后面的课程，我们会涉及到更多的细节。</p>
<p>首先，我会启动 QEMU，并打开 gdb。本质上来说 QEMU 内部有一个 gdb server，当我们启动之后，QEMU 会等待 gdb 客户端连接。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226100740533.png" alt="image-20220226100740533"></p>
<p>在连接上之后，我会在程序的入口处设置一个断点，因为我们知道这是 QEMU 会跳转到的第一个指令。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226100811732.png" alt="image-20220226100811732"></p>
<p>设置完断点之后，我运行程序，可以发现代码并没有停在 0x8000000（见3.7 <code>kernel.asm</code> 中，0x80000000 是程序的起始位置），而是停在了 <code>0x8000000a</code>。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226100839203.png" alt="image-20220226100839203"></p>
<p>如果我们查看kernel的汇编文件，</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226100856581.png" alt="image-20220226100856581"></p>
<p>我们可以看到，在地址 <code>0x8000000a</code> 读取了控制系统寄存器（Control System Register）mhartid，并将结果加载到了 <code>a1</code> 寄存器。所以QEMU会模拟执行这条指令，之后执行下一条指令。</p>
<p>地址 <code>0x80000000</code> 是一个被QEMU认可的地址。也就是说如果你想使用QEMU，那么第一个指令地址必须是它。所以，我们会让内核加载器从那个位置开始加载内核。如果我们查看 <code>kernel.ld</code>，</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226100940653.png" alt="image-20220226100940653"></p>
<p>我们可以看到，这个文件定义了内核是如何被加载的，从这里也可以看到，内核使用的起始地址就是QEMU指定的 0x80000000 这个地址。这就是我们操作系统最初运行的步骤。</p>
<p>回到 gdb，我们可以看到 gdb 也显示了指令的二进制编码</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226101014271.png" alt="image-20220226101014271"></p>
<p>可以看出，csrr 是一个4字节的指令，而 addi 是一个 2 字节的指令。</p>
<p>我们这里可以看到，XV6 从 <code>entry.s</code> 开始启动，这个时候没有内存分页，没有隔离性，并且运行在 machine mode。XV6 会尽可能快的跳转到 kernel mode 或者说是 supervisor mode。我们在 main 函数设置一个断点，main 函数已经运行在supervisor mode 了。接下来我运行程序，代码会在断点，也就是 main 函数的第一条指令停住。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226101059110.png" alt="image-20220226101059110"></p>
<p>上图中，左下是gdb的断点显示，右边是main函数的源码。接下来，我想运行在 gdb 的 <code>layout split</code> 模式：</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226101200955.png" alt="image-20220226101200955"></p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226101214918.png" alt="image-20220226101214918"></p>
<p>从这个视图可以看出 gdb 要执行的下一条指令是什么，断点具体在什么位置。</p>
<p>这里我只在一个 CPU 上运行 QEMU（见最初的 make 参数），这样会使得gdb调试更加简单。因为现在只指定了一个 CPU 核，QEMU只会仿真一个核，我可以单步执行程序（<strong>在单核或者单线程场景下，单个断点就可以停止整个程序的运行</strong>）。</p>
<p>通过在 gdb 中输入 n，可以挑到下一条指令。这里调用了一个名为 <code>consoleinit</code> 的函数，它的工作与你想象的完全一样，也就是设置好console。一旦 <code>console</code> 设置好了，接下来可以向 <code>console</code> 打印输出（代码16、17行）。执行完16、17行之后，我们可以在 QEMU 看到相应的输出。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226101310563.png" alt="image-20220226101310563"></p>
<p>除了 console 之外，还有许多代码来做初始化。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226101330404.png" alt="img"></p>
<ul>
<li>kinit：设置好页表分配器（page allocator）</li>
<li>kvminit：设置好虚拟内存，这是下节课的内容</li>
<li>kvminithart：打开页表，也是下节课的内容</li>
<li>processinit：设置好初始进程或者说设置好进程表单</li>
<li>trapinit&#x2F;trapinithart：设置好user&#x2F;kernel mode转换代码</li>
<li>plicinit&#x2F;plicinithart：设置好中断控制器PLIC（Platform Level Interrupt Controller），我们后面在介绍中断的时候会详细的介绍这部分，这是我们用来与磁盘和console交互方式</li>
<li>binit：分配buffer cache</li>
<li>iinit：初始化inode缓存</li>
<li>fileinit：初始化文件系统</li>
<li>virtio_disk_init：初始化磁盘</li>
<li>userinit：最后当所有的设置都完成了，操作系统也运行起来了，会通过 userinit 运行第一个进程，这里有点意思，接下来我们看一下userinit</li>
</ul>
<blockquote>
<p>学生提问：这里的初始化函数的调用顺序重要吗？</p>
<p>Frans教授：重要，哈哈。一些函数必须在另一些函数之后运行，某几个函数的顺序可能不重要，但是对它们又需要在其他的一些函数之后运行。</p>
</blockquote>
<p>可以通过 gdb 的 s 指令，跳到 <code>userinit</code> 内部。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226101414105.png" alt="img"></p>
<p>上图是 <code>userinit</code> 函数，右边是源码，左边是 gdb 视图。<code>userinit</code> 有点像是胶水代码（Glue code，胶水代码不实现具体的功能，只是为了适配不同的部分而存在），它利用了 XV6 的特性，并启动了第一个进程。我们总是需要有一个用户进程在运行，这样才能实现与操作系统的交互，所以这里需要一个小程序来初始化第一个用户进程。这个小程序定义在 <code>initcode</code> 中。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226101514511.png" alt="image-20220226101514511"></p>
<p>这里直接是程序的二进制形式，它会链接或者在内核中直接静态定义。实际上，这段代码对应了下面的汇编程序。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226101527673.png" alt="image-20220226101527673"></p>
<p>这个汇编程序中，它首先将 init 中的地址加载到 a0（la a0, init），argv 中的地址加载到 a1（la a1, argv），exec 系统调用对应的数字加载到 a7（li a7, SYS_exec），最后调用 ECALL。所以这里执行了 3 条指令，之后在第4条指令将控制权交给了操作系统。</p>
<p>如果我在 syscall 中设置一个断点，</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226101628075.png" alt="img"></p>
<p>并让程序运行起来。userinit 会创建初始进程，返回到用户空间，执行刚刚介绍的3条指令，再回到内核空间。这里是任何XV6用户会使用到的第一个系统调用。让我们来看一下会发生什么。通过在 gdb 中执行 <code>c</code>，让程序运行起来，我们现在进入到了 syscall 函数。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226101648651.png" alt="img"></p>
<p>我们可以查看 syscall 的代码，</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226101744620.png" alt="img"></p>
<p><code>num = p-&gt;trapframe-&gt;a7</code> 会读取使用的系统调用对应的整数。当代码执行完这一行之后，我们可以在 gdb 中打印 <code>num</code>，可以看到是7。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226101815494.png" alt="img"></p>
<p>如果我们查看 <code>syscall.h</code>，可以看到 7 对应的是 exec 系统调用。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226101832443.png" alt="img"></p>
<p>所以，这里本质上是告诉内核，某个用户应用程序执行了 ECALL 指令，并且想要调用 exec 系统调用。</p>
<p><code>p-&gt;trapframe-&gt;a0 = syscall[num]()</code> 这一行是实际执行系统调用。这里可以看出，num 用来索引一个数组，这个数组是一个函数指针数组，可以预期的是 <code>syscall[7]</code> 对应了 exec 的入口函数。我们跳到这个函数中去，可以看到，我们现在在 <code>sys_exec</code> 函数中。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226102020008.png" alt="img"></p>
<p><code>sys_exec</code> 中的第一件事情是从用户空间读取参数，它会读取 path，也就是要执行程序的文件名。这里首先会为参数分配空间，然后从用户空间将参数拷贝到内核空间。之后我们打印 path，</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226102055734.png" alt="img"></p>
<p>可以看到传入的就是 init 程序。所以，综合来看，initcode 完成了通过 exec 调用 init 程序。让我们来看看 init 程序，</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226102131715.png" alt="img"></p>
<p>init 会为用户空间设置好一些东西，比如配置好 console，调用 fork，并在 fork 出的子进程中执行 shell。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220226102158685.png" alt="img"></p>
<p>最终的效果就是 shell 运行起来了。如果我再次运行代码，我还会陷入到 syscall 中的断点，并且同样也是调用 exec 系统调用，只是这次是通过 exec 运行 shell。当 shell 运行起来之后，我们可以从 QEMU 看到 shell。</p>
<p>这里简单的介绍了一下 XV6 是如何从零开始直到第一个 shell 程序运行起来。并且我们也看了一下第一个系统调用是在什么时候发生的。我们并没有看系统调用背后的具体机制，这个在后面会介绍。但是目前来说，这些对于你们完成这周的 syscall lab 是足够了。这些就是你们在实验中会用到的部分。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://acking.cc/2023/01/28/ch05/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="Sam Shen">
      <meta itemprop="description" content="share cs knowledge">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AcKing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/mit6.s081-ch5" class="post-title-link post-title-link-external" itemprop="url">mit6.s081-ch5<i class="fa fa-external-link-alt"></i></a>
          
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-01-28 00:00:00 / Modified: 20:36:23" itemprop="dateCreated datePublished" datetime="2023-01-28T00:00:00+08:00">2023-01-28</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mit6-s081/" itemprop="url" rel="index"><span itemprop="name">mit6.s081</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mit6-s081/OS/" itemprop="url" rel="index"><span itemprop="name">OS</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Chapter-5"><a href="#Chapter-5" class="headerlink" title="Chapter 5"></a>Chapter 5</h1><h3 id="GDB-和汇编代码执行"><a href="#GDB-和汇编代码执行" class="headerlink" title="GDB 和汇编代码执行"></a>GDB 和汇编代码执行</h3><p>接下来我们来看一些真实的汇编代码：</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228010120267.png" alt="img"></p>
<p>图中的代码，上半部分的注释是对应的 C 代码，这是个简单的函数，它累加了从 1 到 n 的所有数字，并返回结果。下半部分是可以编译出的最简单的汇编代码。如果你在自己的计算机编写同样的 C 代码并编译，你得到的极有可能是差别较大的汇编代码。这里有很多原因，有一些原因我们之后会讲，有一些原因是因为编译器。当将 C 代码编译成汇编代码时，现代的编译器会执行各种各样的优化，所以你们自己编译得到的汇编代码可能看起来是不一样的。例如，当你在 gdb 中做 debug 的时候，有时候你会看到 gdb 提示你说某些变量被优化掉了，这意味着编译器决定了自己不再需要那个变量，变量以及相关的信息会在某个时间点删掉。</p>
<p>上图中的代码都很直观，首先将寄存器 <code>a0</code> 中的值保存在寄存器 <code>t0</code> 中。之后将寄存器 <code>a0</code> 设置为 0，之后在每个循环中将 t0 中的数据加到 a0 中，直到 t0 变成 0。这就是代码的所有内容。</p>
<blockquote>
<p>学生提问：这里面 .secion，.global，.text 分别是什么意思？</p>
<p>TA：global 表示你可以在其他文件中调用这个函数。text 表明这里的是代码，如果你还记得 XV6 中的图3.4，</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228010214854.png" alt="img"></p>
<blockquote>
<p>每个进程的 page table 中有一个区域是 text，汇编代码中的 text 表明这部分是代码，并且位于 page table 的 text 区域中，text 中保存的就是代码。</p>
</blockquote>
<p>如果你对内核比较感兴趣，在编译完之后，你可以查看 <code>kernel.asm</code> 文件，你可以看到 XV6 完整内核的汇编版本。文件中每一行左边的数字表明的是这条指令会在内存中的哪个位置，这个信息非常有用。在汇编代码中还可以看到函数对应的 label，以及它们是在哪里定义的。这些信息在我们调试代码的时候可能会非常非常有用，我稍后会展示这部分。</p>
<blockquote>
<p>学生提问：<code>.asm</code> 文件和 <code>.s</code> 文件有什么区别？</p>
<p>TA：我并不是百分百确定。<strong>这两类文件都是汇编代码，<code>.asm</code> 文件中包含大量额外的标注，而 <code>.s</code> 文件中没有</strong>。所以通常来说当你编译你的C代码，你得到的是 <code>.s</code> 文件。如果你好奇我们是如何得到 <code>.asm</code> 文件，makefile 里面包含了具体的步骤。</p>
</blockquote>
<p>现在回到函数 <code>sum_to</code>，我们看一下如何在 gdb 中检查这个函数。首先是要启动 QEMU，</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228014220124.png" alt="img"></p>
<p>在另一个窗口打开 gdb，</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228014236718.png" alt="img"></p>
<p>gdb 中输入 <code>tui enable</code> 可以打开源代码展示窗口。</p>
<p><code>sum_to</code> 的代码现在都位于内核中，我在 <code>sum_to</code> 中设置一个断点。然后继续代码的执行，代码在断点处停住。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228014316761.png" alt="img"></p>
<p>gdb 窗口的左上角是程序计数器，我们可以看到当前的值是 <code>0x800065e2</code>。如果我们去 <code>kernel.asm</code>中，查找这个地址，我们可以看到这个地址就是 <code>sum_to</code> 函数的起始地址。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228014331612.png" alt="img"></p>
<p>如果代码出现了问题，在 gdb 中看到的地址，你可以直接在 <code>kernel.asm</code> 找到具体的行，分析问题的原因，然后再向相应的地址设置断点。</p>
<p>在 gdb 中输入 <code>layout asm</code>，可以在 tui 窗口看到所有的汇编指令。再输入 <code>layout reg</code> 可以看到所有的寄存器信息。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228014407718.png" alt="img"></p>
<p>在寄存器窗口，可以看到 t0，a0 寄存器的值。在执行完一条汇编指令之后，<code>t0</code> 寄存器拥有了 <code>a0</code> 寄存器的内容，也就是 5。在寄存器窗口，更新了的寄存器会被高亮出来。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228014450069.png" alt="img"></p>
<p>之后持续的单步执行代码，直到函数返回。</p>
<p><strong>如果你关心你设置了哪些断点，或着你跟踪代码的时候迷糊了，</strong>你可以在 gdb 中输入 <code>info breakpoints</code> ，你可以看到所有设置了的断点。你甚至可以看到这个断点已经被命中了几次。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228014608402.png" alt="img"></p>
<p>类似的，你也可以通过输入 <code>info reg</code> 查看<strong>寄存器</strong>的信息。</p>
<blockquote>
<p>学生提问：为什么这里展示的是汇编代码而不是 C 代码？</p>
<p>TA：从最初的代码可以看出，这里的程序完全是汇编代码实现的，所以自然也没有关联的 C 程序。如果我将断点设置在 C 代码中，在命中断点之后输入 <code>layout split</code> 或者 <code>layout source</code>，就可以看到相应的 C 代码了。<code>layout split</code>  会同时展现C代码和汇编，而 <code>layout source</code> 只会展示C代码。</p>
<p>学生提问：在C代码中，断点设置在某一行，如果这一行有多个语句的话，断点会设置在哪个语句？</p>
<p>TA：断点会设置在第一个语句。</p>
</blockquote>
<h3 id="RISC-V-寄存器"><a href="#RISC-V-寄存器" class="headerlink" title="RISC-V 寄存器"></a>RISC-V 寄存器</h3><p>我们之前看过了汇编语言和 RISC-V 的介绍，接下来我们看一下之后 lab 相关的内容。这部分的内容其实就是本节课的<a target="_blank" rel="noopener" href="https://pdos.csail.mit.edu/6.828/2020/readings/riscv-calling.pdf">准备材料</a>中的内容。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228014718657.png" alt="img"></p>
<p>你们现在对于这个表达应该都很熟悉了，这个表里面是 <code>RISC-V 的寄存器</code>。寄存器是 CPU 或者处理器上，预先定义的可以用来存储数据的位置。寄存器之所以重要是因为汇编代码并不是在内存上执行，而是在寄存器上执行，也就是说，当我们在做 <code>add，sub</code> 时，我们是对寄存器进行操作。所以你们通常看到的汇编代码中的模式是，我们通过load将数据存放在寄存器中，这里的数据源可以是来自内存，也可以来自另一个寄存器。之后我们在寄存器上执行一些操作。如果我们对操作的结果关心的话，我们会将操作的结果存储在某个地方。这里的目的地可能是内存中的某个地址，也可能是另一个寄存器。这就是通常使用寄存器的方法。</p>
<p>寄存器是用来进行任何运算和数据读取的最快的方式，这就是为什么使用它们很重要，也是为什么我们更喜欢使用寄存器而不是内存。当我们调用函数时，你可以看到这里有a0 - a7寄存器。通常我们在谈到寄存器的时候，我们会用它们的ABI名字。不仅是因为这样描述更清晰和标准，同时也因为在写汇编代码的时候使用的也是ABI名字。第一列中的寄存器名字并不是超级重要，它唯一重要的场景是在 RISC-V 的 Compressed Instruction 中。基本上来说，RISC-V 中通常的指令是 64bit，但是在 Compressed Instruction 中指令是16bit。在 Compressed Instruction 中我们使用更少的寄存器，也就是 x8 - x15 寄存器。我猜你们可能会有疑问，为什么 s1 寄存器和其他的s寄存器是分开的，因为 s1 在Compressed Instruction 是有效的，而 s2-s11 却不是。除了 Compressed Instruction，寄存器都是通过它们的 ABI 名字来引用。</p>
<p>a0 到 a7 寄存器是用来作为函数的参数。如果一个函数有超过 8个参数，我们就需要用内存了。从这里也可以看出，当可以使用寄存器的时候，我们不会使用内存，我们只在不得不使用内存的场景才使用它。</p>
<p>表单中的第4列，Saver列，当我们在讨论寄存器的时候也非常重要。</p>
<p>它有两个可能的值Caller，Callee。我经常混淆这两个值，因为它们只差一个字母，我发现最简单的记住它们的方法是：</p>
<ul>
<li>Caller Saved寄存器在函数调用的时候不会保存</li>
<li>Callee Saved寄存器在函数调用的时候会保存</li>
</ul>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228020134831.png" alt="img"></p>
<p><strong>这里的意思是，一个Caller Saved寄存器可能被其他函数重写</strong>。假设我们在函数a中调用函数b，任何被函数a使用的并且是Caller Saved寄存器，调用函数b可能重写这些寄存器。我认为一个比较好的例子就是Return address寄存器（注，保存的是函数返回的地址），你可以看到ra寄存器是Caller Saved，这一点很重要，它导致了当函数a调用函数b的时侯，b会重写Return address。所以基本上来说，任何一个Caller Saved寄存器，作为调用方的函数要小心可能的数据可能的变化；任何一个Callee Saved寄存器，作为被调用方的函数要小心寄存器的值不会相应的变化。我经常会弄混这两者的区别，然后会到这张表来回顾它们。</p>
<p>如果你们还记得的话，所有的寄存器都是 64bit，各种各样的数据类型都会被改造的可以放进这 64bit 中。比如说我们有一个 32bit 的整数，取决于整数是不是有符号的，会通过在前面补 32 个 0 或者 1 来使得这个整数变成 64bit 并存在这些寄存器中。</p>
<blockquote>
<p>学生提问：返回值可以放在 a1 寄存器吗？</p>
<p>TA：这是个好问题。我认为理论上是可以的，如果一个函数的返回值是long long型，也就是128bit，我们可以把它放到一对寄存器中。这也同样适用于函数的参数。所以，如果返回值超过了一个寄存器的长度，也就是64bit，我们可以将返回值保存在a0和a1。但是如果你只将返回值放在a1寄存器，我认为会出错。</p>
<p>学生提问：除了 Stack Pointer 和 Frame Pointer，我不认为我们需要更多的Callee Saved寄存器。</p>
<p>TA：s0 - s11都是Callee寄存器，我认为它们是提供给编译器而不是程序员使用。在一些特定的场景下，你会想要确保一些数据在函数调用之后仍然能够保存，这个时候编译器可以选择使用s寄存器。</p>
</blockquote>
<h3 id="Stack"><a href="#Stack" class="headerlink" title="Stack"></a>Stack</h3><p>接下来我们讨论一下栈。栈之所以很重要的原因是，它使得我们的函数变得有组织，且能够正常返回。</p>
<p>下面是一个非常简单的栈的结构图，其中每一个区域都是一个 <strong>Stack Frame，每执行一次函数调用就会产生一个Stack Frame。</strong></p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228020408160.png" alt="img"></p>
<p>每一次我们调用一个函数，函数都会为自己创建一个Stack Frame，并且只给自己用。函数通过移动 Stack Pointer 来完成 Stack Frame 的空间分配。</p>
<p>对于 Stack 来说，是从高地址开始向低地址使用。所以栈总是向下增长。当我们想要创建一个新的 Stack Frame 的时候，总是对当前的 Stack Pointer 做减法。一个函数的 Stack Frame 包含了保存的寄存器，本地变量，并且，如果函数的参数多于8个，额外的参数会出现在 Stack 中。所以 Stack Frame 大小并不总是一样，即使在这个图里面看起来是一样大的。不同的函数有不同数量的本地变量，不同的寄存器，所以 Stack Frame 的大小是不一样的。但是有关 Stack Frame 有两件事情是确定的：</p>
<ul>
<li><strong>Return address 总是会出现在 Stack Frame 的第一位</strong></li>
<li><strong>指向前一个 Stack Frame 的指针也会出现在栈中的固定位置</strong></li>
</ul>
<p>有关 Stack Frame 中有两个重要的寄存器，第一个是 SP（Stack Pointer），它指向 Stack 的底部并代表了当前 Stack Frame 的位置。第二个是 FP（Frame Pointer），它指向当前 Stack Frame 的顶部。因为 Return address 和指向前一个 Stack Frame 的指针都在当前Stack Frame的固定位置，所以可以通过当前的FP寄存器寻址到这两个数据。</p>
<p>我们保存前一个Stack Frame的指针的原因是为了让我们能跳转回去。所以当前函数返回时，我们可以将前一个Frame Pointer存储到FP寄存器中。所以我们使用Frame Pointer来操纵我们的Stack Frames，并确保我们总是指向正确的函数。</p>
<p>Stack Frame 必须要被汇编代码创建，所以是<strong>编译器生成了汇编代码，进而创建了Stack Frame</strong>。所以通常，在汇编代码中，函数的最开始你们可以看到 Function prologue，之后是函数的本体，最后是Epollgue。这就是一个汇编函数通常的样子。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228020624180.png" alt="img"></p>
<p>我们从汇编代码中来看一下这里的操作。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228020718715.png" alt="img"></p>
<p>在我们之前的 sum_to 函数中，只有函数主体，并没有 Stack Frame 的内容。它这里能正常工作的原因是它足够简单，并且它是一个 leaf 函数。leaf 函数是指不调用别的函数的函数，它的特别之处在于它不用担心保存自己的Return address 或者任何其他的Caller Saved寄存器，因为它不会调用别的函数。</p>
<p>而另一个函数 sum_then_double 就不是一个leaf函数了，这里你可以看到它调用了sum_to。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228020920984.png" alt="img"></p>
<p>所以在这个函数中，需要包含 prologue。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228021006444.png" alt="img"></p>
<p>这里我们对Stack Pointer减16，这样我们为新的 Stack Frame 创建了16字节的空间。之后我们将 Return address 保存在 Stack Pointer 位置。</p>
<p>之后就是调用 sum_to 并对结果乘以2，最后是 Epllogue，</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228021159511.png" alt="image-20220228021159511"></p>
<p>这里首先将 Return address 加载回 ra 寄存器，通过对 Stack Pointer 加 16 来删除刚刚创建的 Stack Frame，最后 ret 从函数中退出。</p>
<p>这里我替大家问一个问题，如果我们删除掉Prologue和Epllogue，然后只剩下函数主体会发生什么？有人可以猜一下吗？</p>
<blockquote>
<p>学生回答：sum_then_double将不知道它应该返回的Return address。所以调用sum_to的时候，Return address被覆盖了，最终sum_to函数不能返回到它原本的调用位置。</p>
</blockquote>
<p>是的，完全正确，我们可以看一下具体会发生什么。先在修改过的sum_then_double设置断点，然后执行sum_then_double。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228021659428.png" alt="img"></p>
<p>我们可以看到现在的ra寄存器是 0x80006392，它指向demo2函数，也就是sum_then_double的调用函数。之后我们执行代码，调用了sum_to。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228021649880.png" alt="img"></p>
<p>我们可以看到ra寄存器的值被 sum_to重写成了0x800065f4，指向sum_then_double，这也合理，符合我们的预期。我们在函数sum_then_double中调用了sum_to，那么sum_to就应该要返回到sum_then_double。</p>
<p>之后执行代码直到sum_then_double返回。如前面那位同学说的，因为没有恢复sum_then_double自己的Return address，现在的Return address仍然是sum_to对应的值，现在我们就会进入到一个无限循环中。</p>
<p>我认为这是一个很好的例子用来展示为什么跟踪Caller和Callee寄存器是重要的。</p>
<p>接下来我们来看一些C代码。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228021640522.png" alt="img"></p>
<p>demo4函数里面调用了dummymain函数。我们在dummymain函数中设置一个断点，</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228021631418.png" alt="img"></p>
<p>现在我们在dummymain函数中。如果我们在gdb中输入info frame，可以看到有关当前Stack Frame许多有用的信息。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228090107324.png" alt="image-20220228090107324"></p>
<ul>
<li>Stack level 0，表明这是调用栈的最底层</li>
<li>pc，当前的程序计数器</li>
<li>saved pc，demo4的位置，表明当前函数要返回的位置</li>
<li>source language c，表明这是C代码</li>
<li>Arglist at，表明参数的起始地址。当前的参数都在寄存器中，可以看到 argc &#x3D; 3，argv 是一个地址</li>
</ul>
<p>如果输入 <code>backtrace</code>（简写bt）可以看到从当前调用栈开始的所有 Stack Frame。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228021832784.png" alt="image-20220228021832784"></p>
<p>如果对某一个Stack Frame感兴趣，可以先定位到那个 frame 再输入 <code>info frame</code>，假设对 syscall 的 Stack Frame 感兴趣。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228090128324.png" alt="image-20220228090128324"></p>
<p>在这个Stack Frame中有更多的信息，有一堆的 Saved Registers，有一些本地变量等等。这些信息对于调试代码来说超级重要。</p>
<blockquote>
<p>学生提问：为什么有的时候编译器会优化掉 <code>argc</code> 或者 <code>argv</code> ？这个以前发生过。</p>
<p>TA：这意味着编译器发现了一种更有效的方法，不使用这些变量，而是通过寄存器来完成所有的操作。如果一个变量不是百分百必要的话，这种优化还是很有常见的。我们并没有给你编译器的控制能力，但是在你们的日常使用中，你可以尝试设置编译器的optimization flag为 0，不过就算这样，编译器也会做某些程度的优化。</p>
</blockquote>
<h3 id="Struct"><a href="#Struct" class="headerlink" title="Struct"></a>Struct</h3><p>今天我想讨论的最后一个话题是 struct，stuct 非常重要并且在课程的实验中会经常出现。我会稍微介绍一下 struct 在内存中的结构是怎样。基本上来说，struct 在内存中是一段连续的地址，如果我们有一个 struct，并且有f1，f2，f3三个字段。</p>
<p>当我们创建这样一个struct时，内存中相应的字段会彼此相邻。你可以认为 struct 像是一个数组，但是里面的不同字段的类型可以不一样。（注，这应该是这一节中最有用的一句话了。。。）</p>
<p>我们可以将struct作为参数传递给函数。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228090154065.png" alt="image-20220228090154065"></p>
<p>这里有一个名字是Person的struct，它有两个字段。我将这个struct作为参数传递给printPerson并打印相关的信息。我们在printPerson中设置一个断点，当程序运行到函数内部时打印当前的Stack Frame。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228090208092.png" alt="img"></p>
<p>我们可以看到当前函数有一个参数p。打印p可以看到这是struct Person的指针，打印p的反引用可以看到struct的具体内容。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220228090227304.png" alt="img"></p>
<blockquote>
<p>学生提问：是谁创建了编译器来将C代码转换成各种各样的汇编代码，是不同的指令集创建者，还是第三方？</p>
<p>TA：我认为不是指令集的创建者，通常是第三方创建的。你们常见的两大编译器，一个是 gcc，这是由 GNU 基金会维护的；一个是 llvm，这个是开源的，你可以查到相应的代码。当一个新的指令集，例如 RISC-V，发布之后，我认为会指令集的创建者和编译器的设计者之间会有一些高度合作。简单来说我认为是第三方配合指令集的创建者完成的编译器。RISC-V 或许是个例外，因为它是来自于一个研究项目，相应的团队或许自己写了编译器，但是我不认为 Intel 对于 gcc 或者 llvm 有任何输入。</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://acking.cc/2023/01/28/ch04/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="Sam Shen">
      <meta itemprop="description" content="share cs knowledge">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AcKing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/mit6.s081-ch4" class="post-title-link post-title-link-external" itemprop="url">mit6.s081-ch4<i class="fa fa-external-link-alt"></i></a>
          
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-01-28 00:00:00 / Modified: 20:36:19" itemprop="dateCreated datePublished" datetime="2023-01-28T00:00:00+08:00">2023-01-28</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mit6-s081/" itemprop="url" rel="index"><span itemprop="name">mit6.s081</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mit6-s081/OS/" itemprop="url" rel="index"><span itemprop="name">OS</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Chapter-4-Page-Tables"><a href="#Chapter-4-Page-Tables" class="headerlink" title="Chapter 4 Page Tables"></a>Chapter 4 Page Tables</h1><p>存在某种形式的映射关系，并且映射关系对于实现隔离性 isolation 来说有帮助。</p>
<h3 id="地址空间"><a href="#地址空间" class="headerlink" title="地址空间"></a>地址空间</h3><p>当我们运行 <code>cat</code> 时，它的地址空间从 0 到某个地址结束。当我们运行 <code>Shell</code> 时，它的地址也从 0 开始到某个地址结束。内核的地址空间也从 0 开始到某个地址结束。如果 <code>cat</code> 程序想要向地址 1000 写入数据，那么 <code>cat</code> 只会向它自己的地址 1000，而不是向 <code>Shell</code> 的地址 1000 写入数据。</p>
<p><strong>每个程序都运行在自己的地址空间，并且这些地址空间彼此之间相互独立。在这种不同地址空间的概念中，<code>cat</code> 程序甚至都不具备引用属于 <code>Shell</code> 的内存地址的能力。</strong>这是我们想要达成的终极目标，因为这种方式为我们提供了<strong>强隔离性</strong>，<code>cat</code> 现在不能引用任何不属于自己的内存。</p>
<p>所以现在的问题是如何在一个物理内存上，创建不同的地址空间，因为归根到底，我们使用的还是一堆存放了内存信息的 DRAM 芯片。</p>
<blockquote>
<p>Frans 教授提问：大家们，在XV6中从哪可以看到内存耗尽了？如果你们完成了 syscall 实验，你们会知道在 syscall 实验中有一部分是打印剩余内存的数量。</p>
<p>学生回答：kalloc？</p>
<p>Frans教授：是的。<code>kalloc</code> 保存了空余 page 的列表( freelist )，如果这个列表为空或者耗尽了，那么 kalloc 会返回一个空指针，内核会妥善处理并将结果返回给用户应用程序。并告诉用户应用程序，要么是对这个应用程序没有额外的内存了，要么是整个机器都没有内存了。</p>
<p>内核的一部分工作就是优雅的处理这些情况，这里的优雅是指向用户应用程序返回一个错误消息，而不是直接崩溃。</p>
</blockquote>
<h3 id="页表-Page-Table"><a href="#页表-Page-Table" class="headerlink" title="页表(Page Table)"></a>页表(Page Table)</h3><p>我们如何能够在一个物理内存上创建不同的地址空间？</p>
<p>最常见的方法，同时也是非常灵活的一种方法就是使用页表（Page Tables）。<strong>页表是在硬件中通过处理器和内存管理单元（Memory Management Unit,aka MMU）实现。</strong>所以在脑海中，应该有这么一张图：CPU 正在执行指令，例如 <code>sd $7, (a0)</code></p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227002431824.png" alt="image-20220227002431824"></p>
<p><strong>对于任何一条带有地址的指令，其中的地址应该认为是虚拟内存地址而不是物理地址</strong>。假设寄存器 <code>a0</code> 中是地址 <code>0x1000</code> ，那么这是一个虚拟内存地址。虚拟内存地址会被转到内存管理单元（MMU）</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227002924560.png" alt="image-20220227002924560"></p>
<p>内存管理单元会将虚拟地址翻译成物理地址，之后这个物理地址会被用来索引物理内存，并从物理内存加载，或者向物理内存存储数据。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227003015460.png" alt="img"></p>
<p><strong>从 CPU 的角度来说，一旦 MMU 打开了，它执行的每条指令中的地址都是虚拟内存地址。</strong></p>
<p>为了能够完成虚拟内存地址到物理内存地址的翻译，MMU 会有一个表单，表单中，一边是虚拟内存地址，另一边是物理内存地址。举个例子，虚拟内存地址 <code>0x1000</code> 对应了一个我随口说的物理内存地址 <code>0xFFF0</code> 。这样的表单可以非常灵活。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227003037993.png" alt="img"></p>
<p><strong>通常，内存地址对应关系的表单也保存在内存中。</strong>所以 CPU 中需要有一些寄存器用来存放<strong>表单在物理内存中的地址。</strong>现在，在内存的某个位置保存了地址关系表单，我们假设这个位置的物理内存地址是 <code>0x10</code> 。那么在 <code>RISC-V</code> 上一个叫做 <strong>SATP</strong> 的寄存器会保存地址 <code>0x10</code>。</p>
<p>这样，CPU 就可以告诉 MMU，可以从哪找到将虚拟内存地址翻译成物理内存地址的表单。</p>
<blockquote>
<p>sqf 注：page table一般存储在内存中，由寄存器 SATP 指向其起始地址。</p>
</blockquote>
<blockquote>
<p>学生提问：所以 MMU 并不会保存 page table，它只会从内存中读取 page table，然后完成翻译，是吗？</p>
<p>Frans教授：是的，这就是你们应该记住的。<strong>page table 保存在内存中，MMU 只是会去查看 page table</strong>， 我们接下来会看到，page table 比我们这里画的要稍微复杂一些。</p>
</blockquote>
<p>这里的基本想法是<strong>每个应用程序都有自己独立的表单，并且这个表单定义了应用程序的地址空间。</strong>所以当操作系统将CPU从一个应用程序切换到另一个应用程序时，同时也需要切换 <strong>SATP</strong> 寄存器中的内容，从而<strong>指向新的进程保存在物理内存中的地址对应表单。</strong>这样的话，<code>cat</code> 程序和 <code>shell</code> 程序中相同的虚拟内存地址，就可以翻译到不同的物理内存地址，因为每个应用程序都有属于自己的不同的地址对应表单。这样说得通吗？</p>
<blockquote>
<p>学生提问：刚刚说到 SATP 寄存器会根据进程而修改，我猜每个进程对应的 SATP 值是由内核保存的？</p>
<p>Frans教授：是的，<strong>内核会写 SATP 寄存器，写 SATP 寄存器是一条特殊权限指令。</strong>所以，用户应用程序不能通过更新这个寄存器来更换一个地址对应表单，否则的话就会破坏隔离性。所以，只有运行在 kernel mode 的代码可以更新这个寄存器。</p>
</blockquote>
<p>前面都是最基本的介绍，我们在前面画的图还有做的解释都比较初级且存在明显不合理的地方。有一件事情我刚刚没有提到，这里的表单是如何工作的？从刚刚画的图看来，对于每个虚拟地址，在表单中都有一个条目，如果我们真的这么做，表单会有多大？原则上说，在 RISC-V 上会有多少地址，或者一个寄存器可以保存多少个地址？寄存器是 64bit 的，所以有多少个地址呢？是的，$2^{64}$ 个地址，<strong>所以如果我们以地址为粒度来管理，表单会变得非常巨大</strong>。实际上，所有的内存都会被这里的表单耗尽，所以这一点也不合理。</p>
<p>所以，实际情况不可能是一个虚拟内存地址对应 page table 中的一个条目。接下来我将分两步介绍 RISC-V 中是如何工作的。</p>
<ul>
<li>不要为每个地址创建一条表单条目，而是为每个 page 创建一条表单条目，所以每一次地址翻译都是针对一个 page。而 RISC-V 中，一个 page 是 4KB，也就是 4096 Byte 。这个大小很常见，几乎所有的处理器都使用 4KB 大小的 page 或者支持 4KB 大小的 page。</li>
</ul>
<p>现在，内存地址的翻译方式略微的不同了。首先对于虚拟内存地址，我们将它划分为两个部分，index 和 offset，index 用来查找 page，offset 对应的是一个 page 中的哪个字节。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227003501859.png" alt="img"></p>
<p>当 MMU 在做地址翻译的时候，通过读取虚拟内存地址中的 index 可以知道物理内存中的 page 号，这个 page 号对应了物理内存中的 4096 个字节。之后虚拟内存地址中的 offset 指向了 page 中的 4096 个字节中的某一个，假设 offset 是 12，那么 page 中的第 12 个字节被使用了。将 offset 加上 page 的起始地址，就可以得到物理内存地址。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227003553962.png" alt="image-20220227003553962"></p>
<p>有关 RISC-V 的一件有意思的事情是，虚拟内存地址都是 64bit，这也说的通，因为 RISC-V 的寄存器是 64bit 的。但是实际上，在我们使用的 RSIC-V 处理器上，并不是所有的 64bit 都被使用了，也就是说高 25bit 并没有被使用。这样的结果是<strong>限制了虚拟内存地址的数量</strong>，虚拟内存地址的数量现在只有 $2^{39}$ 个，大概是 512 GB。当然，如果必要的话，最新的处理器或许可以支持更大的地址空间，只需要将未使用的 25bit 拿出来做为虚拟内存地址的一部分即可。在有效利用的 39 bit 中，有 27bit 被用来当做 index，12bit 被用来当做 offset，offset 必须是 12bit，因为对应了一个 page 的 4096 个字节。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227003719415.png" alt="img"></p>
<p>在 RISC-V 中，物理内存地址是 56bit，所以物理内存可以大于单个虚拟内存地址空间，但是也最多到 $2^{56}$。大多数主板还不支持 $2^{56}$ 这么大的物理内存，但是原则上，如果你能造出这样的主板，那么最多可以支持 $2^{56}$ 字节的物理内存。</p>
<p>物理内存地址是 56bit ，其中 44bit 是物理 page 号（PPN，Physical Page Number），剩下 12bit 是 offset 完全继承自虚拟内存地址（<strong>地址转换时，只需要将虚拟内存中的 27bit 翻译成物理内存中的 44bit 的 page 号，剩下的 12bit offset直接拷贝过来即可</strong>）。</p>
<p>这里有什么问题吗？这些的内容还挺重要的，你们需要掌握这的内容才能做出下一个 page table lab。</p>
<blockquote>
<p>学生：图中的 56bit 是根据什么确定的？</p>
<p>Frans教授：这是由硬件设计人员决定的，所以 RISC-V 的设计人员认为 56bit 的物理内存地址是个不错的选择。可以假定，他们是通过技术发展的趋势得到这里的数字。比如说，设计是为了满足 5 年的需求，可以预测物理内存在 5 年内不可能超过 $2^{56}$ 这么大。或许，他们预测是的一个小得多的数字，但是为了防止预测错误，他们选择了像 $2^{56}$ 这么大的数字。这里说的通吗？很多同学都问了这个问题。</p>
<p>学生提问：<strong>如果虚拟内存最多是 $2^{39}$，而物理内存最多是 $2^{56}$，这样我们可以有多个进程都用光了他们的虚拟内存，但是物理内存还有剩余，对吗？</strong></p>
<p>Frans教授：是的，完全正确。</p>
<p>学生提问：因为这是一个 64bit 的机器，为什么硬件设计人员本可以用 64bit 但是却用了 56bit？</p>
<p>Frans教授：选择 56bit 而不是 64bit 是因为在主板上只需要 56 根线。</p>
</blockquote>
<p>通过前面的第一步，我们现在的地址转换表是以 page 为粒度，而不是以单个内存地址为粒度，现在这个地址转换表已经可以被称为 page table 了。但是目前的设计还不能满足实际的需求。</p>
<p>如果每个进程都有自己的 page table，那么每个 page table 表会有多大呢？</p>
<p>这个page table最多会有 $2^{27}$ 个条目（虚拟内存地址中的 index 长度为27），这是个非常大的数字。如果每个进程都使用这么大的 page table，进程需要为 page table 消耗大量的内存，并且很快物理内存就会耗尽。</p>
<p>所以实际上，硬件并不是按照这里的方式来存储 page table。从概念上来说，你可以认为 page table 是从 0 到 $2^{27}$ ，但是实际上并不是这样。实际中，page table 是一个多级的结构。下图是一个真正的 RISC-V page table 结构和硬件实现。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227004115306.png" alt="img"></p>
<p>我们之前提到的虚拟内存地址中的 27bit 的 index，实际上是由 3 个 9bit 的数字组成（L2，L1，L0）。前 9bit 被用来索引最高级的 page directory（注：通常 page directory 是用来索引 page table 或者其他 page directory 物理地址的表单，但是在课程中，page table，page directory， page directory table 区分并不明显，可以都认为是有相同结构的地址对应表单）。</p>
<p>一个 directory 是 4096 Bytes，就跟 page 的大小是一样的，directory 中的一个条目被称为 PTE（Page Table Entry）是 64 bit，就像寄存器的大小一样，也就是 8 Bytes，所以一个 Directory page 有 512 个条目。</p>
<p>所以实际上，<strong>SATP 寄存器会指向最高一级的 page directory 的物理内存地址</strong>，之后我们用虚拟内存中 index 的高 9 bit 用来索引最高一级的 page directory，这样我们就能得到一个 PPN，也就是物理 page 号。这个 PPN 指向了中间级的 page directory。</p>
<p><strong>当我们在使用中间级的 page directory 时，我们通过虚拟内存地址中的 L1 部分完成索引。接下来会走到最低级的 page directory，我们通过虚拟内存地址中的 L0 部分完成索引。在最低级的 page directory 中，我们可以得到对应于虚拟内存地址的物理内存地址。</strong></p>
<p>从某种程度上来说，与之前一种方案还是很相似的，除了实际的索引是由 3 步，而不是 1 步完成。这种方式的主要优点是，如果地址空间中大部分地址都没有使用，你不必为每一个 index 准备一个条目。</p>
<blockquote>
<p> 举个例子，如果你的地址空间只使用了一个page，4096 Byte。除此之外，你没有使用任何其他的地址。现在，你需要多少个 page table entry，或者page table directory来映射这一个page？</p>
<p>在最高级，你需要一个 page directory。在这个 page directory 中，你需要一个数字是 0 的PTE，指向中间级 page directory。在中间级，你也需要一个 page directory，里面也是一个数字 0 的PTE，指向最低级 page directory。所以这里总共需要 3 个 page directory（也就是 3 * 512 个条目）。</p>
</blockquote>
<p>而在前一个方案中，虽然我们只使用了一个page，还是需要 $2^{27}$ 个PTE。而这个方案中，我们只需要 1536 个PTE，所需的空间大大减少了。这是实际上硬件采用这种层次化的 3 级 page directory 结构的主要原因。</p>
<p>这里有什么问题吗？这部分还是很重要的。</p>
<blockquote>
<p>Frans教授：所有的 page directory 传递的都是 PPN，对应的物理地址是 44bit 的PPN加上 12bit 的 0（注，也就是 page 的起始地址，因为每个 page directory 都使用一个完整的 page，所以直接从 page 起始地址开始使用就行）。如果我们查看这里的 PTE 条目，它们都有相同的格式，其中 44bit 是PPN，但是寄存器是 64bit 的，所有有一些 bit 是留空的。<strong>支持 page 的硬件在低 10bit 存了一些标志位用来控制地址权限。</strong></p>
<p>如果你把 44bit 的 PPN 和 10bit 的 Flags 相加是 54bit，也就是说还有 10bit 未被使用，这 10bit 被用来作为未来扩展。比如说某一天你有了一个新的 RISC-V 处理器，它的 page table 可能略有不同，或许有超过 44bit 的 PPN。如果你看下面这张图，你可以看到，这里有 10bit 是作为保留字段存在的。</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227004744286.png" alt="img"></p>
<p>接下来，让我们看看PTE中的 Flag，因为它也很重要。每个 PTE 的低 10bit 是一堆标志位：</p>
<ul>
<li>第一个标志位是 Valid。如果Valid bit位为1，那么表明这是一条合法的PTE，你可以用它来做地址翻译。对于刚刚举得那个小例子（应用程序只用了1个page的例子），我们只使用了3个page directory，每个page directory中只有第0个PTE被使用了，所以只有第0个PTE的Valid bit位会被设置成1，其他的511个PTE的Valid bit为0。这个标志位告诉MMU，你不能使用这条PTE，因为这条PTE并不包含有用的信息。</li>
<li>下两个标志位分别是 Readable 和 Writable。表明你是否可以读&#x2F;写这个 page。</li>
<li>Executable 表明你可以从这个page执行指令。</li>
<li>User 表明这个 page 可以被运行在用户空间的进程访问。</li>
<li>其他标志位并不是那么重要，他们偶尔会出现，前面 5个是重要的标志位。</li>
</ul>
<blockquote>
<p>学生提问：我对于这里的 3个 page table 有个问题，PPN是如何合并成最终的物理内存地址？</p>
<p>Frans教授：我之前或许没有很直接的说这部分，<strong>在最高级的page directory中的PPN，包含了下一级page directory的物理内存地址，依次类推。在最低级page directory，我们还是可以得到 44bit的PPN，这里包含了我们实际上想要翻译的物理page地址，然后再加上虚拟内存地址的 12bit offset，就得到了 56bit物理内存地址</strong>。</p>
<p>Frans教授：<strong>让我来问自己的一个有趣的问题，为什么是 PPN 存在这些 page directory 中？为什么不是一个虚拟内存地址？</strong></p>
<p>Frans教授：<strong>我们不能让我们的地址翻译依赖于另一个翻译，否则我们可能会陷入递归的无限循环中。所以 page directory 必须存物理地址。那 SATP 呢？它存的是物理地址还是虚拟地址？</strong></p>
<p>某学生回答：还是物理地址，因为最高级的 page directory 还是存在物理内存中，对吧。</p>
<p>Frans教授：是的，这里必须是物理地址，因为我们要用它来完成地址翻译，而不是对它进行地址翻译，所以 <strong>SATP 需要知道最高一级的 page directory 的物理地址是什么。</strong></p>
<p>学生提问： 这里有层次化的 3个 page table，每个 page table 都由虚拟地址的 9bit 来索引，所以是由虚拟地址中的 3个 9bit来分别索引 3个 page table，对吗？</p>
<p>Frans教授：是的，最高的 9bit 用来索引最高一级的 page directory，第二个 9bit 用来索引中间级的page directory，第三个 9bit 用来索引最低级的 page directory。</p>
<p>学生提问：当一个进程请求一个虚拟内存地址时，CPU 会查看 SATP 寄存器得到对应的最高一级 page table，这级 page table 会使用虚拟内存地址中 27bit index 的最高 9bit 来完成索引，如果索引的结果为空，MMU 会自动创建一个 page table吗？</p>
<p>Frans教授：不会的，MMU 会告诉操作系统或者处理器，抱歉我不能翻译这个地址，最终这会变成一个 page fault。如果一个地址不能被翻译，那就不翻译。就像你在运算时除以 0 一样，处理器会拒绝那样做。</p>
<p>学生提问：我想知道我们是怎么计算 page table 的物理地址，是不是这样，我们从最高级的 page table 得到 44bit 的PPN，然后再加上虚拟地址中的 12bit offset，就得到了完整的 56bit page table 物理地址？</p>
<p>Frans教授：我们不会加上虚拟地址中的 offset，这里只是使用了 12bit 的 0，<strong>我们用 44bit 的 PPN，再加上 12bit 的 0，这样就得到了下一级 page directory 的 56bit 物理地址</strong>。这里要求每个 page directory 都与物理 page 对齐（也就是 page directory 的起始地址就是某个 page 的起始地址，所以低 12bit 都为 0）</p>
</blockquote>
<h3 id="页表缓存-TLB-Translation-Lookside-Buffer"><a href="#页表缓存-TLB-Translation-Lookside-Buffer" class="headerlink" title="页表缓存 TLB(Translation Lookside Buffer)"></a>页表缓存 TLB(Translation Lookside Buffer)</h3><p>如果我们回想一下 page table 的结构，你可以发现，当处理器从内存加载或者存储数据时，基本上都要做3次内存查找，第一次在最高级的 page directory，第二次在中间级的 page directory，最后一次在最低级的 page directory。所以对于一个虚拟内存地址的寻址，需要读三次内存，这里代价有点高。所以实际中，几乎所有的处理器都会对于最近使用过的虚拟地址的翻译结果有缓存。这个缓存被称为：Translation Lookside Buffer（通常翻译成页表缓存），你会经常看到它的缩写 TLB。基本上来说，这就是 Page Table Entry 的缓存，也就是PTE的缓存。</p>
<p><strong>当处理器第一次查找一个虚拟地址时，硬件通过 3级 page table 得到最终的 PPN，TLB 会保存虚拟地址到物理地址的映射关系。这样下一次当你访问同一个虚拟地址时，处理器可以查看 TLB，TLB 会直接返回物理地址，而不需要通过 page table 得到结果。</strong></p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227005059594.png" alt="img"></p>
<blockquote>
<p>学生提问：前面说 TLB 会保存虚拟地址到物理地址的对应关系，如果在page 级别做 cache 是不是更加高效？</p>
<p>Frans教授：有很多种方法都可以实现 TLB，对于你们来说最重要的是知道 TLB 是存在的。TLB 实现的具体细节不是我们要深入讨论的内容。这是处理器中的一些逻辑，对于操作系统来说是不可见的，操作系统也不需要知道 TLB 是如何工作的。<strong>你们需要知道 TLB 存在的唯一原因是，如果你切换了 page table，操作系统需要告诉处理器当前正在切换 page table，处理器会清空 TLB。</strong>因为本质上来说，如果你切换了page table，TLB 中的缓存将不再有用，它们需要被清空，否则地址翻译可能会出错。所以操作系统知道 TLB 是存在的，但只会时不时的告诉操作系统，现在的 TLB 不能用了，因为要切换 page table 了。在 RISC-V 中，清空TLB的指令是 <code>sfence_vma</code> 。</p>
</blockquote>
<blockquote>
<p>学生提问：3级的 page table 是由操作系统实现的还是由硬件自己实现的？</p>
<p>Frans教授：这是由硬件实现的，所以 3级 page table 的查找都发生在硬件中。<strong>MMU 是硬件的一部分而不是操作系统的一部分。</strong>在 XV6 中，有一个函数也实现了 page table 的查找，因为时不时的 XV6 也需要完成硬件的工作，所以XV6有这个叫做 <code>walk</code> 的函数，它在软件中实现了 MMU 硬件相同的功能。</p>
<p>学生提问：在这个机制中，TLB 发生在哪一步，是在地址翻译之前还是之后？</p>
<p>Frans教授：整个 CPU 和 MMU 都在处理器芯片中，所以在一个 RISC-V 芯片中，<strong>有多个 CPU 核，MMU 和 TLB 存在于每一个 CPU核里面。</strong>RISC-V 处理器有 L1 cache，L2 Cache，有些 cache 是根据物理地址索引的，有些 cache 是根据虚拟地址索引的。<strong>由虚拟地址索引的 cache 位于 MMU 之前，由物理地址索引的 cache 位于 MMU 之后。</strong></p>
<p>学生提问：之前提到，硬件会完成 3级 page table 的查找，那为什么我们要在 XV6 中有一个 walk 函数来完成同样的工作？</p>
<p>Frans教授：非常好的问题。这里有几个原因：</p>
<ul>
<li>首先 XV6 中的 walk 函数设置了最初的 page table，它需要对 3级page table 进行编程，所以它首先需要能模拟 3级 page table。</li>
<li>另一个原因或许你们已经在 syscall 实验中遇到了，在 XV6 中，内核有它自己的 page table，用户进程也有自己的 page table，<strong>用户进程指向 <code>sys_info</code> 结构体的指针存在于用户空间的 page table，但是内核需要将这个指针翻译成一个自己可以读写的物理地址。</strong>如果你查看 <code>copy_in</code> ，<code>copy_out</code> ，你可以发现内核会通过用户进程的 page table，将用户的虚拟地址翻译得到物理地址，这样内核可以读写相应的物理内存地址。这就是为什么在 XV6 中需要有 walk 函数的一些原因。</li>
</ul>
<p>学生提问：为什么硬件不开发类似于 walk 函数的接口？这样我们就不用在 XV6 中用软件实现自己的接口，自己实现还容易有bug。为什么没有一个特殊权限指令，接收虚拟内存地址，并返回物理内存地址？</p>
<p>Frans教授：其实这就跟你向一个虚拟内存地址写数据，硬件会自动帮你完成工作一样（工作是指翻译成物理地址，并完成数据写入）。你们在page table实验中会完成相同的工作。我们接下来在看XV6的实现的时候会看到更多的内容。</p>
</blockquote>
<p>在我们介绍XV6之前，有关 page table 我还想说一点。用时髦的话说，page table 提供了一层抽象（<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Indirection">level of indirection</a>）。我这里说的抽象就是指从虚拟地址到物理地址的映射，这里的映射关系完全由操作系统控制。</p>
<p>因为操作系统对于这里的地址翻译有完全的控制，它可以实现各种各样的功能。比如，当一个 PTE 是无效的，硬件会返回一个 page fault，对于这个 page fault，操作系统可以更新 page table 并再次尝试指令。通过操纵 page table，在运行时有各种各样可以做的事情。我们在之后有一节课专门会讲，当出现 page fault 的时候，操作系统可以做哪些有意思的事情。现在只需要记住，page table 是一个无比强大的机制，它为操作系统提供了非常大的灵活性。这就是为什么 page table 如此流行的一个原因。</p>
<h3 id="Kernel-Page-Table"><a href="#Kernel-Page-Table" class="headerlink" title="Kernel Page Table"></a>Kernel Page Table</h3><p>接下来，我们看一下在 XV6 中，page table 是如何工作的？首先我们来看一下 kernel page 的分布。下图就是内核中地址的对应关系，左边是内核的虚拟地址空间，右边上半部分是物理内存或者说是DRAM，右边下半部分是 I&#x2F;O 设备。接下来我会首先介绍右半部分，然后再介绍左半部分。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227005631204.png" alt="image-20220227005631204"></p>
<p>图中的右半部分的结构完全由硬件设计者决定。如你们上节课看到的一样，当操作系统启动时，会从地址 <code>0x80000000</code> 开始运行，这个地址其实也是由硬件设计者决定的。具体的来说，如果你们看一个主板，中间是 RISC-V 处理器，我们现在知道了处理器中有 4个核，每个核都有自己的 MMU 和 TLB。处理器旁边就是 DRAM 芯片。主板的设计人员决定了，在完成了虚拟到物理地址的翻译之后，如果得到的物理地址大于 <code>0x80000000</code> 会走向 DRAM 芯片，如果得到的物理地址低于 <code>0x80000000</code> 会走向不同的 I&#x2F;O 设备。这是由这个主板的设计人员决定的物理结构。如果你想要查看这里的物理结构，你可以阅读主板的手册，手册中会一一介绍物理地址对应关系。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227005719186.png" alt="img"></p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227005730721.png" alt="img"></p>
<p>首先，地址 0 是保留的，地址 <code>0x10090000</code> 对应以太网，地址 <code>0x80000000</code> 对应 DDR 内存，处理器外的易失存储（Off-Chip Volatile Memory），也就是主板上的 DRAM 芯片。所以，在你们的脑海里应该要记住这张主板的图片，即使我们接下来会基于你们都知道的 C 语言程序—QEMU 来做介绍，但是最终所有的事情都是由主板硬件决定的。</p>
<blockquote>
<p>学生提问：当你说这里是由硬件决定的，硬件是特指 CPU 还是说 CPU 所在的主板？</p>
<p>Frans教授：CPU所在的主板，CPU 只是主板的一小部分，DRAM 芯片位于处理器之外。是主板设计者将处理器，DRAM 和许多 I&#x2F;O 设备汇总在一起。对于一个操作系统来说，CPU 只是一个部分，I&#x2F;O 设备同样也很重要。所以当你在写一个操作系统时，你需要同时处理 CPU 和 I&#x2F;O 设备，比如你需要向互联网发送一个报文，操作系统需要调用网卡驱动和网卡来实际完成这个工作。</p>
</blockquote>
<p>回到最初那张图的右侧：物理地址的分布。可以看到最下面是未被使用的地址，这与主板文档内容是一致的（地址为0）。<strong>地址 <code>0x1000</code> 是 boot ROM 的物理地址，当你对主板上电，主板做的第一件事情就是运行存储在 boot ROM 中的代码，当 boot 完成之后，会跳转到地址 <code>0x80000000</code>，操作系统需要确保那个地址有一些数据能够接着启动操作系统。</strong></p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227005839429.png" alt="img"></p>
<p>这里还有一些其他的 I&#x2F;O 设备：</p>
<ul>
<li>PLIC 是中断控制器（Platform-Level Interrupt Controller）我们下周的课会讲。</li>
<li>CLINT（Core Local Interruptor）也是中断的一部分。所以多个设备都能产生中断，需要中断控制器来将这些中断路由到合适的处理函数。</li>
<li>UART（Universal Asynchronous Receiver&#x2F;Transmitter）负责与 console 和显示器交互。</li>
<li>VIRTIO disk，与磁盘进行交互。</li>
</ul>
<p>地址 <code>0x02000000</code> 对应CLINT，当你向这个地址执行读写指令，你是向实现了 CLINT 的芯片执行读写。<strong>这里你可以认为你直接在与设备交互，而不是读写物理内存。</strong></p>
<blockquote>
<p>学生提问：确认一下，低于 <code>0x80000000</code> 的物理地址，不存在于 DRAM 中，当我们在使用这些地址的时候，指令会直接走向其他的硬件，对吗？</p>
<p>Frans教授：是的。高于 <code>0x80000000</code> 的物理地址对应 DRAM 芯片，但是对于例如以太网接口，也有一个特定的低于 <code>0x80000000</code> 的物理地址，我们可以对这个叫做内存映射I&#x2F;O（Memory-mapped I&#x2F;O）的地址执行读写指令，来完成设备的操作。</p>
<p> 学生提问：为什么物理地址最上面一大块标为未被使用？</p>
<p>Frans教授：物理地址总共有 $2^{56}$ 那么多，但是你不用在主板上接入那么多的内存。所以不论主板上有多少 DRAM 芯片，总是会有一部分物理地址没有被用到。实际上在 XV6 中，我们限制了内存的大小是 128MB。</p>
<p>学生提问：当读指令从CPU发出后，它是怎么路由到正确的 I&#x2F;O 设备的？比如说，当 CPU 要发出指令时，它可以发现现在地址是低于 <code>0x80000000</code>，但是它怎么将指令送到正确的I&#x2F;O设备？</p>
<p>Frans教授：你可以认为在 RISC-V 中有一个多路输出选择器（demultiplexer）。</p>
</blockquote>
<p>接下来我会切换到第一张图的左边，这就是 XV6 的虚拟内存地址空间。当机器刚刚启动时，还没有可用的 page，XV6 操作系统会设置好内核使用的虚拟地址空间，也就是这张图左边的地址分布。</p>
<p>因为我们想让 XV6 尽可能的简单易懂，所以这里的虚拟地址到物理地址的映射，大部分是相等的关系。比如说内核会按照这种方式设置 page table，虚拟地址 <code>0x02000000</code> 对应物理地址 <code>0x02000000</code>。这意味着左侧低于 PHYSTOP 的虚拟地址，与右侧使用的物理地址是一样的。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227010008879.png" alt="img"></p>
<p>所以，这里的箭头都是水平的，因为这里是完全相等的映射。除此之外，这里还有两件重要的事情：</p>
<p>第一件事情是，有一些 page 在虚拟内存中的地址很靠后，比如 kernel stack 在虚拟内存中的地址就很靠后。这是因为在它之下有一个未被映射的 Guard page，这个 Guard page 对应的 PTE 的 Valid 标志位没有设置，这样，如果 kernel stack 耗尽了，它会溢出到 Guard page，但是因为 Guard page 的 PTE 中 Valid 标志位未设置，会导致立即触发 page fault，这样的结果好过内存越界之后造成的数据混乱。立即触发一个 panic（也就是 page fault），你就知道 kernel stack 出错了。同时我们也又不想浪费物理内存给 Guard page，所以 Guard page 不会映射到任何物理内存，它只是占据了虚拟地址空间的一段靠后的地址。</p>
<p>同时，kernel stack 被映射了两次，在靠后的虚拟地址映射了一次，在 PHYSTOP 下的 Kernel data 中又映射了一次，但是实际使用的时候用的是上面的部分，因为有 Guard page 会更加安全。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227010120813.png" alt="img"></p>
<p>这是众多你可以通过 page table 实现的有意思的事情之一。你可以<strong>向同一个物理地址映射两个虚拟地址</strong>，你可以不将一个虚拟地址映射到物理地址。可以是一对一的映射，一对多映射，多对一映射。XV6至少在1-2个地方用到类似的技巧。这的 kernel stack 和 Guard page 就是 XV6 基于 page table 使用的有趣技巧的一个例子。</p>
<p>第二件事情是权限。例如 Kernel text page 被标位 R-X，意味着你可以读它，也可以在这个地址段执行指令，但是你不能向 Kernel text 写数据。通过设置权限我们可以尽早的发现 Bug 从而避免 Bug。对于Kernel data 需要能被写入，所以它的标志位是 RW-，但是你不能在这个地址段运行指令，所以它的 X标志位未被设置。（注，所以，kernel text 用来存代码，代码可以读，可以运行，但是不能篡改，kernel data 用来存数据，数据可以读写，但是不能通过数据伪装代码在 kernel 中运行）</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227010213494.png" alt="img"></p>
<blockquote>
<p>学生提问：对于不同的进程会有不同的 kernel stack 吗？</p>
<p>Frans：答案是的，<strong>每一个用户进程都有一个对应的 kernel stack</strong>。</p>
<p>学生提问：用户程序的虚拟内存会映射到未使用的物理地址空间吗？</p>
<p>Frans教授：在 kernel page table 中，有一段 Free Memory，它对应了物理内存中的一段地址。</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227010304924.png" alt="img"></p>
<blockquote>
<p><strong>XV6 使用这段 free memory 来存放用户进程的 page table，text 和 data。如果我们运行了非常多的用户进程，某个时间点我们会耗尽这段内存，这个时候 fork 或者 exec 会返回错误。</strong></p>
<p>同一个学生提问：这就意味着，用户进程的虚拟地址空间会比内核的虚拟地址空间小的多，是吗？</p>
<p>Frans教授：本质上来说，两边的虚拟地址空间大小是一样的。但是用户进程的虚拟地址空间使用率会更低。</p>
<p>学生提问：如果多个进程都将内存映射到了同一个物理位置，这里会优化合并到同一个地址吗？</p>
<p>Frans教授：XV6 不会做这样的事情，但是 page table 实验中有一部分就是做这个事情。真正的操作系统会做这样的工作。当你们完成了 page table 实验，你们就会对这些内容更加了解。</p>
</blockquote>
<blockquote>
<p>学生提问：每个进程都会有自己的 3级树状 page table，通过这个 page table 将虚拟地址翻译成物理地址。所以看起来当我们将内核虚拟地址翻译成物理地址时，我们并不需要 kernel 的 page table，因为进程会使用自己的树状 page table 并完成地址翻译（注，不太理解这个问题点在哪）。</p>
<p>Frans教授：当 kernel 创建了一个进程，针对这个进程的 page table 也会从 Free memory 中分配出来。内核会为用户进程的 page table 分配几个 page，并填入 PTE。在某个时间点，当内核运行了这个进程，内核会将进程的根 page table 的地址加载到 SATP 中。从那个时间点开始，处理器会使用内核为那个进程构建的虚拟地址空间。</p>
<p>同一个学生提问：所以内核为进程放弃了一些自己的内存，但是进程的虚拟地址空间理论上与内核的虚拟地址空间一样大，虽然实际中肯定不会这么大。</p>
<p>Frans教授：是的，下图是用户进程的虚拟地址空间分布，与内核地址空间一样，它也是从0到MAXVA。</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227010526643.png" alt="img"></p>
<blockquote>
<p>它有由内核设置好的，专属于进程的 page table 来完成地址翻译。</p>
</blockquote>
<blockquote>
<p>学生提问：但是我们不能将所有的 MAXVA 地址都使用吧？</p>
<p>Frans教授：是的我们不能，这样我们会耗尽内存。大多数的进程使用的内存都远远小于虚拟地址空间。</p>
</blockquote>
<h3 id="kvminit-函数"><a href="#kvminit-函数" class="headerlink" title="kvminit 函数"></a>kvminit 函数</h3><p>首先，我们来做一个的常规操作，启动我们的 XV6，这里 QEMU 实现了主板，同时我们打开 gdb。</p>
<p>上一次我们看了 boot 的流程，我们跟到了 main 函数。main 函数中调用的一个函数是 <code>kvminit</code>（3.9），这个函数会<strong>设置好 kernel 的地址空间</strong>。<code>kvminit</code> 的代码如下图所示：</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227012453315.png" alt="img"></p>
<p>我们在前一部分看了 kernel 的地址空间长成什么样，这里我们来看一下代码是如何将它设置好的。首先在 kvminit 中设置一个断点，之后运行代码到断点位置。在 gdb 中执行 layout split，可以看到（从上面的代码也可以看出）函数的第一步是为最高一级 page directory 分配物理 page（注，调用 kalloc就是分配物理 page），下一行将这段内存初始化为 0。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227012535095.png" alt="img"></p>
<p>之后，通过 kvmmap 函数，将每一个 I&#x2F;O 设备映射到内核。例如，下图中高亮的行将 UART0 映射到内核的地址空间。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227012614622.png" alt="img"></p>
<p>我们可以查看一个文件叫做 <code>memlayout.h</code>，它将4.5中的文档翻译成了一堆常量。在这个文件里面可以看到，UART0 对应了地址 <code>0x10000000</code>（注，4.5中的文档是真正 SiFive RISC-V 的文档，而下图是 QEMU 的地址，所以4.5中的文档地址与这里的不符）。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227012702699.png" alt="img"></p>
<p>通过 <code>kvmmap</code> 可以将物理地址映射到相同的虚拟地址（注，因为 kvmmap 的前两个参数一致）。</p>
<p>在 page table 实验中，第一个练习是实现 vmprint，这个函数会打印当前的 kernel page table。我们现在跳过这个函数，看一下执行完第一个 kvmmap 时的 kernel page table。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227012745337.png" alt="img"></p>
<p>我们来看一下这里的输出。第一行是最高一级 page directory 的地址，这就是存在 SATP 或者将会存在 SATP 中的地址。第二行可以看到最高一级 page directory 只有一条 PTE 序号为0，它包含了中间级 page directory 的物理地址。第三行可以看到中间级的 page directory 只有一条 PTE 序号为128，它指向了最低级 page directory 的物理地址。第四行可以看到最低级的 page directory 包含了 PTE 指向物理地址。你们可以看到最低一级 page directory 中 PTE 的物理地址就是 <code>0x10000000</code>，对应了 UART0。</p>
<p>前面是物理地址，我们可以从虚拟地址的角度来验证这里符合预期。我们将地址 <code>0x10000000</code> 向右移位 12bit，这样可以得到虚拟地址的高 27bit（index 部分）。之后我们再对这部分右移位 9bit，并打印成 10进制数，可以得到 128，这就是中间级 page directory 中 PTE 的序号。这与之前（4.4）介绍的内容是符合的。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227012925232.png" alt="img"></p>
<p>从标志位来看（fl 部分），最低一级 page directory 中的 PTE 有读写标志位，并且 Valid 标志位也设置了（4.3底部有标志位的介绍）。</p>
<p><strong>内核会持续的按照这种方式，调用 kvmmap 来设置地址空间。之后会对 VIRTIO0、CLINT、PLIC、kernel text、kernel data、最后是 TRAMPOLINE 进行地址映射。</strong>最后我们还会调用 vmprint 打印完整的 kernel page directory，可以看出已经设置了很多 PTE。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220303100606521.png" alt="image-20220303100606521"></p>
<p>这里就不过细节了，但是这些 PTE 构成了我们在 4.5 中看到的地址空间对应关系。</p>
<blockquote>
<p>学生：下面这两行内存不会越界吗？</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220303100546908.png" alt="image-20220303100546908"></p>
<blockquote>
<p>Frans：不会，这里 KERNBASE 是 <code>0x80000000</code>，这是内存开始的地址。kvmmap 的第三个参数是 size，etext 是 kernel text 的最后一个地址，etext - KERNBASE 会返回 kernel text 的字节数，我不确定这块有多大，大概是 60 - 90 个 page，这部分是 kernel 的 text 部分。PHYSTOP 是物理内存的最大位置，PHYSTOP - text 是 kernel 的 data 部分。会有足够的 DRAM 来完成这里的映射。</p>
</blockquote>
<h3 id="kvminithart-函数"><a href="#kvminithart-函数" class="headerlink" title="kvminithart 函数"></a>kvminithart 函数</h3><p>之后，kvminit 函数返回了，在 main 函数中，我们运行到了 kvminithart 函数。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227013114725.png" alt="img"></p>
<p>这个函数首先设置了 SATP 寄存器，<code>kernel_pagetable</code> 变量来自于 kvminit 第一行。所以这里实际上是内核告诉 MMU 来使用刚刚设置好的 page table。当这里这条指令执行之后，下一个指令的地址会发生什么？</p>
<p>在这条指令之前，还不存在可用的 page table，所以也就不存在地址翻译。执行完这条指令之后，程序计数器（Program Counter）增加了 4。<strong>而之后的下一条指令被执行时，程序计数器会被内存中的 page table 翻译。</strong></p>
<p>所以这条指令的执行时刻是一个非常重要的时刻。因为整个地址翻译从这条指令之后开始生效，之后的每一个使用的内存地址都可能对应到与之不同的物理内存地址。因为在这条指令之前，我们使用的都是物理内存地址，这条指令之后 page table 开始生效，所有的内存地址都变成了另一个含义，也就是虚拟内存地址。</p>
<p>这里能正常工作的原因是值得注意的。因为前一条指令还是在物理内存中，而后一条指令已经在虚拟内存中了。比如，下一条指令地址是 <code>0x80001110</code> 就是一个虚拟内存地址。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227013151324.png" alt="img"></p>
<p><strong>为什么这里能正常工作呢？因为 kernel page 的映射关系中，虚拟地址到物理地址是完全相等的。所以，在我们打开虚拟地址翻译硬件之后，地址翻译硬件会将一个虚拟地址翻译到相同的物理地址。所以实际上，我们最终还是能通过内存地址执行到正确的指令，因为经过地址翻译 <code>0x80001110</code> 还是对应 <code>0x80001110</code>。</strong></p>
<p>管理虚拟内存的一个难点是，一旦执行了类似于 SATP 这样的指令，你相当于将一个 page table 加载到了 SATP 寄存器，你的世界完全改变了。现在每一个地址都会被你设置好的 page table 所翻译。那么假设你的 page table 设置错误了，会发生什么呢？有人想回答这个问题吗？</p>
<blockquote>
<p>学生A回答：你可能会覆盖 kernel data。   </p>
<p>学生B回答：会产生 page fault。</p>
</blockquote>
<p>是的，因为 page table 没有设置好，虚拟地址可能根本就翻译不了，那么内核会停止运行并 panic。所以，如果 page table 中有 bug，你将会看到奇怪的错误和崩溃，这导致了 page table 实验将会比较难。如果你不够小心，或者你没有完全理解一些细节，你可能会导致 kernel 崩溃，这将会花费一些时间和精力来追踪背后的原因。但这就是管理虚拟内存的一部分，因为对于一个这么强大的工具，如果出错了，相应的你也会得到严重的后果。我并不是要给你们泼凉水，哈哈。另一方面，这也很有乐趣，经过了 page table 实验，你们会真正理解虚拟内存是什么，虚拟内存能做什么。</p>
<h3 id="walk-函数"><a href="#walk-函数" class="headerlink" title="walk 函数"></a>walk 函数</h3><blockquote>
<p>学生提问：我对于 walk 函数有个问题，从代码看它返回了最高级 page table 的 PTE，但是它是怎么工作的呢？（注，应该是学生理解有误，walk 函数模拟了 MMU，返回的是 va 对应的最低级 page table 的 PTE）</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220227013346242.png" alt="img"></p>
<blockquote>
<p>Frans教授：这个函数会返回 page table 的 PTE，而内核可以读写 PTE。我来画个图，首先我们有一个 page directory，这个 page directory 有 512 个 PTE，最下面是 0，最上面是 511。</p>
</blockquote>
<blockquote>
<p>这个函数的作用是返回某一个 PTE 的指针。</p>
<p>这是个虚拟地址，它指向了这个 PTE。之后内核可以通过向这个地址写数据来操纵这条 PTE 执行的物理 page。当 page table 被加载到 SATP 寄存器，这里的更改就会生效。</p>
<p>从代码看，这个函数从 L2 走到 L1 然后到 L0，如果参数 alloc 不为 0，且某一个 level 的 page table 不存在，这个函数会创建一个临时的 page table，将内容初始化为 0，并继续运行。所以最后总是返回的是最低一级的 page directory 的 PTE。</p>
<p>如果参数 alloc 没有设置，那么在第一个 PTE 对应的下一级 page table 不存在时就会返回。</p>
<p>学生提问：对于 walk 函数，我有一个比较困惑的地方，在写完 SATP 寄存器之后，内核还能直接访问物理地址吗？在代码里面看起来像是通过 page table 将虚拟地址翻译成了物理地址，但是这个时候 SATP 已经被设置了，得到的物理地址不会被认为是虚拟地址吗？</p>
<p>Frans教授：让我们来看 <code>kvminithart</code> 函数，这里的 <code>kernel_page_table</code> 是一个物理地址，并写入到 SATP 寄存器中。从那以后，我们的代码运行在一个我们构建出来的地址空间中。在之前的 kvminit 函数中，kvmmap 会对每个地址或者每个 page 调用 walk 函数。所以你的问题是什么？</p>
<p>学生：我想知道，在 SATP 寄存器设置完之后，walk 是不是还是按照相同的方式工作？</p>
<p>Frans：是的。它还能工作的原因是，内核设置了虚拟地址等于物理地址的映射关系，这里很重要，因为很多地方能工作的原因都是因为内核设置的地址映射关系是相同的。</p>
<p>学生：每一个进程的 SATP 寄存器存在哪？</p>
<p>Frans：每个 CPU 核只有一个 SATP 寄存器，但是在每个 proc 结构体，如果你查看 <code>proc.h</code>，里面有一个指向 page table 的指针，这对应了进程的根 page table 物理内存地址。</p>
</blockquote>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://acking.cc/2023/01/28/ch06/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="Sam Shen">
      <meta itemprop="description" content="share cs knowledge">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AcKing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/mit6.s081-ch6" class="post-title-link post-title-link-external" itemprop="url">mit6.s081-ch6<i class="fa fa-external-link-alt"></i></a>
          
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-01-28 00:00:00 / Modified: 20:36:27" itemprop="dateCreated datePublished" datetime="2023-01-28T00:00:00+08:00">2023-01-28</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mit6-s081/" itemprop="url" rel="index"><span itemprop="name">mit6.s081</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mit6-s081/OS/" itemprop="url" rel="index"><span itemprop="name">OS</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="Chapter-6-isolation-amp-syscall"><a href="#Chapter-6-isolation-amp-syscall" class="headerlink" title="Chapter 6 isolation &amp; syscall"></a>Chapter 6 isolation &amp; syscall</h1><h3 id="Trap-机制"><a href="#Trap-机制" class="headerlink" title="Trap 机制"></a>Trap 机制</h3><p>今天我想讨论一下，程序运行是<strong>完成用户空间和内核空间的切换</strong>。每当：</p>
<ul>
<li>程序执行系统调用</li>
<li>程序出现了类似 page fault 、运算时除以 0 的错误</li>
<li>一个设备触发了中断使得当前程序运行需要响应内核设备驱动</li>
</ul>
<p>都会发生这样的切换</p>
<p><strong>Trap</strong> ：用户空间和内核空间的切换</p>
<p><strong>系统总会频繁的切换到内核中，所以 trap 机制要尽可能的简单</strong>。</p>
<p>在这个 trap 过程中，硬件的状态非常重要，因为我们很多的工作都是将硬件从适合运行用户应用程序的状态，改变到适合运行内核代码的状态。</p>
<p>我们最关心的状态可能是 32 个用户寄存器。RISC-V 总共有 32 个寄存器，用户应用程序可以使用全部的寄存器（使用寄存器的指令性能是最好的）。</p>
<ul>
<li>在硬件中有一个寄存器叫做程序计数器 PC（Program Counter Register）</li>
<li>mode 表明当前 mode 的标志位，这个标志位表明了当前是 supervisor mode 还是 user mode。当我们在运行 Shell 的时候，自然是在 user mode</li>
<li>还有一堆控制 CPU 工作方式的寄存器，比如 SATP 寄存器，它包含了指向 page table 的物理内存地址。</li>
<li>还有一些对于今天讨论非常重要的寄存器，比如 STVEC（Supervisor Trap Vector Base Address Register）寄存器，它指向了内核中专门处理 trap 的指令的程序的起始地址。</li>
<li>SEPC（Supervisor Exception Program Counter）寄存器，在 trap 的过程中保存程序计数器的值。</li>
</ul>
<p>在 trap 的最开始，CPU 的所有状态都设置成运行用户代码而不是内核代码。在 trap 处理的过程中，我们实际上需要更改一些这里的状态，或者对状态做一些操作。这样我们才可以运行系统内核中的 C 程序。</p>
<p>接下来我们先来预览一下需要做的操作：</p>
<ul>
<li><p>我们需要保存 32 个用户寄存器。（很显然我们需要恢复用户应用程序的执行，尤其是当用户程序随机的被设备中断所打断时。我们希望内核能够响应中断，之后在用户程序完全无感知的情况下再恢复用户代码的执行。）</p>
</li>
<li><p>程序计数器也需要在某个地方保存，它几乎跟一个用户寄存器的地位是一样的，我们需要能够在用户程序运行中断的位置继续执行用户程序。</p>
</li>
<li><p>我们需要将 mode 切换到 supervisor mode，因为我们想要使用内核中的各种各样的特权指令。</p>
</li>
<li><p>SATP 寄存器现在正指向 user page table，而 user page table 只包含了用户程序所需要的内存映射和一两个其他的映射，它并没有包含整个内核数据的内存映射。所以在运行内核代码之前，我们需要将 SATP 指向 kernel page table。</p>
</li>
<li><p>我们需要将堆栈寄存器指向位于内核的一个地址，因为我们需要一个堆栈来调用内核的 C 函数。</p>
<blockquote>
<p>这里应该是要调用 SP、FP 等指针。</p>
</blockquote>
</li>
<li><p>一旦我们设置好了，并且所有的硬件状态都适合在内核中使用， 我们需要跳入内核的 C 代码。</p>
</li>
<li><p>一旦我们运行在内核的 C 代码中，那就跟平常的 C 代码是一样的。</p>
</li>
</ul>
<h4 id="安全和隔离"><a href="#安全和隔离" class="headerlink" title="安全和隔离"></a>安全和隔离</h4><p>我们不想让用户代码介入到这里的 <code>user/kernel</code> 切换，否则有可能会破坏安全性。<strong>所以这意味着，trap 中涉及到的硬件和内核机制不能依赖任何来自用户空间东西。</strong>比如说我们不能依赖 32 个用户寄存器，它们可能保存的是恶意的数据，所以，XV6 的 trap 机制不会查看这些寄存器，而只是将它们保存起来。</p>
<blockquote>
<p>出于安全性考虑，XV6 的 trap 机制只会保存 32 个寄存器，而不查看其之前的内容。</p>
</blockquote>
<p>在操作系统的 trap 机制中，我们仍然想保留隔离性并防御来自用户代码的可能恶意攻击。同样也很重要的是，我们想要让 trap 机制对用户代码是透明的，也就是说我们想要执行 trap，然后在内核中执行代码，同时用户代码并不用察觉到任何事情，这样也更容易写用户代码。</p>
<blockquote>
<p>user 到 kernel 的切换过程需要安全，kernel 内部也要保证安全。</p>
</blockquote>
<p><strong>有一点很重要：当这个标志位从 user mode 变更到 supervisor mode 时，我们能得到什么样的权限。实际上，这里获得的额外权限实在是有限。也就是说，你可以在 supervisor mode 完成，但是不能在 user mode 完成的工作，或许并没有你想象的那么有特权。</strong>所以，我们接下来看看 supervisor mode 可以控制什么？</p>
<p>其中的一件事情是，你现在可以读写控制寄存器了。比如说，当你在 supervisor mode 时，你可以：</p>
<ul>
<li>读写 SATP 寄存器，也就是 page table 的指针；</li>
<li>STVEC，也就是处理 trap 的内核指令地址；</li>
<li>SEPC，保存当发生 trap 时的程序计数器；</li>
<li>SSCRATCH 寄存器等等。</li>
</ul>
<p><strong>在 supervisor mode 你可以读写这些寄存器，而用户代码不能做这样的操作。</strong></p>
<p>另一件事情 supervisor mode 可以做的是，它可以使用 PTE_U 标志位为 0 的 PTE。当 PTE_U 标志位为 1 的时候，表明用户代码可以使用这个页表；如果这个标志位为 0，则只有 supervisor mode 可以使用这个页表。我们接下来会看一下为什么这很重要。</p>
<p><strong>这两点就是 supervisor mode 可以做的事情，除此之外就不能再干别的事情了。</strong></p>
<blockquote>
<p>总结，内核态就多了两点，第一是可以读写一些控制寄存器，第二是可以使用 PTE_U 为 0 的页表项。</p>
</blockquote>
<p>需要特别指出的是，supervisor mode 中的代码并不能读写任意物理地址。<strong>在 supervisor mode 中，就像普通的用户代码一样，也需要通过 page table 来访问内存。如果一个虚拟地址并不在当前由 SATP 指向的 page table 中，又或者 SATP 指向的 page table 中 <code>PTE_U = 1</code>，那么 supervisor mode 不能使用那个地址。</strong>所以，即使我们在 supervisor mode，我们还是受限于当前 page table 设置的虚拟地址。</p>
<h3 id="Trap-代码执行流程"><a href="#Trap-代码执行流程" class="headerlink" title="Trap 代码执行流程"></a>Trap 代码执行流程</h3><p>这节课大部分时间都会通过 gdb 来跟踪代码是如何通过 trap 进入到内核空间，这里会涉及到很多的细节。为了帮助你提前了解接下来的内容，我们会跟踪如何在 shell 中调用 write 系统调用。从 Shell 的角度来说，这就是个 Shell 代码中的 C 函数调用，但是实际上，write 通过执行 <code>ECALL</code> 指令来执行系统调用。<code>ECALL</code> 指令会切换到具有 supervisor mode 的内核中。在这个过程中，内核中执行的第一个指令是一个由汇编语言写的函数，叫做 <code>uservec</code>。这个函数是内核代码 <code>trampoline.s</code> 文件的一部分。所以执行的第一个代码就是这个 <code>uservec</code> 汇编函数。之后，在这个汇编函数中，代码执行跳转到了由 C 语言实现的函数 <code>usertrap</code> 中，这个函数在 <code>trap.c</code> 中。现在代码运行在 C 中，所以代码更加容易理解。在 <code>usertrap</code> 这个 C 函数中，我们执行了一个叫做 <code>syscall</code> 的函数。</p>
<p>这个函数会在一个表单中，根据传入的代表系统调用的数字进行查找，并在内核中执行具体实现了系统调用功能的函数。对于我们来说，这个函数就是 <code>sys_write</code>。</p>
<p><code>sys_write</code> 会将要显示数据输出到 <code>console</code> 上，当它完成了之后，它会返回给<code>syscall</code> 函数。</p>
<p>因为我们现在相当于在 <code>ECALL</code> 之后中断了用户代码的执行，为了用户空间的代码恢复执行，需要做一系列的事情。在 <code>syscall</code> 函数中，会调用一个函数叫做 <code>usertrapret</code> ，它也位于 <code>trap.c</code> 中，这个函数完成了部分方便在 C 代码中实现的返回到用户空间的工作。</p>
<p>除此之外，最终还有一些工作只能在汇编语言中完成。这部分工作通过汇编语言实现，并且存在于 <code>trampoline.s</code> 文件中的 <code>userret</code> 函数中。</p>
<p>最终，在这个汇编函数中会调用机器指令返回到用户空间，并且恢复 ECALL 之后的用户程序的执行。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304020140746.png" alt="image-20220304020140746"></p>
<p>对于这里的概述大家有问题吗？没有的话我要切到 gdb 了。</p>
<blockquote>
<p>学生提问：难道 <code>vm.c</code> 中的函数不是要直接访问物理内存吗？</p>
<p>Robert教授：是的，这些函数能这么做的原因是，内核小心地在 page table 中设置好了各个 PTE。这样当内核收到了一个读写虚拟内存地址的请求，会通过 kernel page table 将这个虚拟内存地址翻译成与之等价物理内存地址，再完成读写。所以，一旦使用了 kernel page table，就可以非常方便的在内核中使用所有这些直接的映射关系。但是直到 trap 机制切换到内核之前，这些映射关系都不可用。直到 trap 机制将程序运行切换到内核空间之前，我们使用的仍然是没有这些方便映射关系的 user page table。</p>
<p>学生提问：这个问题或许并不完全相关，read 和 write 系统调用，相比内存的读写，他们的代价都高的多，因为它们需要切换模式，并来回折腾。有没有可能当你执行打开一个文件的系统调用时， 直接得到一个 page table 映射，而不是返回一个文件描述符？这样只需要向对应于设备的特定的地址写数据，程序就能通过 page table 访问特定的设备。你可以设置好限制，就像文件描述符只允许修改特定文件一样，这样就不用像系统调用一样在用户空间和内核空间来回捣腾了。</p>
<p>Robert教授：这是个很好的想法，实际上很多操作系统都提供这种叫做内存映射文件（Memory-mapped file access）的机制，在这个机制里面通过 page table，可以将用户空间的虚拟地址空间，对应到文件内容，这样你就可以通过内存地址直接读写文件。实际上，你们将在 mmap 实验中完成这个机制。对于许多程序来说，这个机制的确会比直接调用 read&#x2F;write 系统调用要快的多。</p>
</blockquote>
<h3 id="ECALL-指令之前的状态"><a href="#ECALL-指令之前的状态" class="headerlink" title="ECALL 指令之前的状态"></a>ECALL 指令之前的状态</h3><p>我们将要跟踪一个 XV6 的系统调用，也就是 shell 将它的提示信息通过 write 系统调用走到操作系统再输出到 console 的过程。你们可以看到，用户代码 <code>sh.c</code> 初始了这一切。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304020426371.png" alt="img"></p>
<p>上图中选中的行，是一个 write 系统调用，它将 <code>$ </code> 写入到文件描述符 2。接下来我将打开 gdb 并启动 XV6。</p>
<p>作为用户代码的 Shell 调用 write 时，<strong>实际上调用的是关联到 Shell 的一个库函数。</strong>你可以查看这个库函数的源代码，在 <code>usys.s</code>。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304020452675.png" alt="img"></p>
<p>上面这几行代码就是实际被调用的 write 函数的实现。这是个非常短的函数：</p>
<ul>
<li>首先将 <code>SYS_write</code> 加载到 <code>a7</code> 寄存器，<code>SYS_write</code> 是常量16。这里告诉内核，我想要运行第 16 个系统调用，而这个系统调用正好是 write 。</li>
<li>之后这个函数中执行了 ecall 指令，<strong>从这里开始代码执行跳转到了内核。</strong>内核完成它的工作之后，代码执行会返回到用户空间，继续执行 ecall 之后的指令，也就是 ret ，最终返回到 Shell 中。所以  ret 从 write 库函数返回到了 Shell 中。</li>
</ul>
<p>为了展示这里的系统调用，我会在 ecall 指令处放置一个断点，为了能放置断点，我们需要知道 ecall 指令的地址，我们可以通过查看由 XV6 编译过程产生的 <code>sh.asm</code> 找出这个地址。<code>sh.asm</code> 是带有指令地址的汇编代码（注，asm文件3.7有介绍）。我这里会在 ecall 指令处放置一个断点，这条指令的地址是 <code>0xde6</code> 。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304020622313.png" alt="img"></p>
<p>现在，我要让 XV6 开始运行。我期望的是 XV6 在 Shell 代码中正好在执行 ecall 之前就会停住。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304020635391.png" alt="img"></p>
<p>完美，从gdb可以看出，我们下一条要执行的指令就是 ecall。我们来检验一下我们真的在我们以为自己在的位置，让我们来打印程序计数器 PC 正好我们期望在的位置 <code>0xde6</code>。</p>
<p>我们还可以输入 <code>info reg</code> 打印全部 32 个用户寄存器，</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304020656731.png" alt="img"></p>
<p>这里有一些数值我们还不知道，也不关心，<strong>但是这里的 a0，a1，a2 是 Shell 传递给 write 系统调用的参数：</strong></p>
<ul>
<li>a0 是文件描述符 2；</li>
<li>a1 是 Shell 想要写入字符串的指针；</li>
<li>a2 是想要写入的字符数。我们还可以通过打印 Shell 想要写入的字符串内容，来证明断点停在我们认为它应该停在的位置。</li>
</ul>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304020725526.png" alt="img"></p>
<p>可以看出，输出的确是 <code>$</code> 和空格。所以，我们现在位于我们期望所在的 <code>write</code> 系统调用函数中。</p>
<blockquote>
<p>上图的寄存器中，程序计数器（pc）和堆栈指针（sp）的地址现在都在距离 0 比较近的地址，这进一步印证了当前代码运行在用户空间，因为用户空间中所有的地址都比较小。但是一旦我们进入到了内核，内核会使用大得多的内存地址。</p>
</blockquote>
<p>其中一个最重要的需要变更的状态，并且在它变更之前我们对它还有依赖的，就是是当前的 page table。我们可以查看 STAP 寄存器。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304020753530.png" alt="img"></p>
<p>这里输出的是物理内存地址，它并没有告诉我们有关 page table 中的映射关系是什么，page table 长什么样。</p>
<blockquote>
<p>在  QEMU 中有一个方法可以打印当前的 page table。从 QEMU 界面，输入 <code>ctrl a + c</code>  可以进入到 QEMU 的 console，之后输入 <code>info mem</code>，QEMU 会打印完整的 page table。</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304020813660.png" alt="img"></p>
<blockquote>
<p>这是个非常小的 page table，它只包含了 6 条映射关系。这是用户程序 shell 的 page table，而 shell 是一个非常小的程序，这 6 条映射关系是有关 shell 的指令和数据，以及一个无效的 page 用来作为 guard page，以防止 Shell 尝试使用过多的 stack page。我们可以看出这个 page 是无效的，因为在 attr 这一列它并没有设置u标志位（第三行）。<strong>attr 这一列是 PTE 的标志位，第三行的标志位是 rwx 表明这个 page 可以读，可以写，也可以执行指令。之后的是 u 标志位，它表明 PTE_U 标志位是否被设置，用户代码只能访问 PTE_U 标志位设置了的PTE。</strong>再下一个标志位我也不记得是什么了（注，从 4.3 可以看出，这个标志位是Global）。再下一个标志位是 a（Accessed），表明这条PTE是不是被使用过，再下一个标志位d（Dirty）表明这条 PTE 是不是被写过。</p>
</blockquote>
<p>现在，我们有了这个小小的 page table。顺便说一下，最后两条 PTE 的虚拟地址非常大，非常接近虚拟地址的顶端，如果你读过了 XV6 的书，你就知道这两个 page 分别是 trapframe page 和 trampoline page。你可以看到，它们都没有设置 u 标志，所以用户代码不能访问这两条 PTE。一旦我们进入到了 supervisor mode，我们就可以访问这两条 PTE 了。</p>
<p>对于这里 page table，<strong>它并没有包含任何内核部分的地址映射，这里既没有对于 kernel data 的映射，也没有对于 kernel 指令的映射。</strong>除了最后两条 PTE，这个 page table 几乎是完全为用户代码执行而创建，所以它对于在内核执行代码并没有直接特殊的作用。</p>
<blockquote>
<p>学生提问：PTE中 a 标志位是什么意思？</p>
<p>Robert教授：这表示这条PTE是不是被代码访问过，是不是曾经有一个被访问过的地址包含在这个PTE的范围内。d 标志位表明是否曾经有写指令使用过这条PTE。这些标志位由硬件维护以方便操作系统使用。对于比 XV6 更复杂的操作系统，当物理内存吃紧的时候，可能会通过将一些内存写入到磁盘来，同时将相应的PTE 设置成无效，来释放物理内存 page。你可以想到，这里有很多策略可以让操作系统来挑选哪些 page 可以释放。我们可以查看 a 标志位来判断这条PTE是否被使用过，如果它没有被使用或者最近没有被使用，那么这条 PTE 对应的 page 适合用来保存到磁盘中。类似的，D 标志位告诉内核，这个 page 最近被修改过。不过 XV6 没有这样的策略。</p>
</blockquote>
<p>接下来，我会在 Shell 中打印出 write 函数的内容。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304021050514.png" alt="img"></p>
<p>程序计数器现在指向 ecall 指令，我们接下来要执行 ecall 指令。现在我们还在用户空间，但是马上我们就要进入内核空间了。</p>
<h3 id="ECALL-指令之后的状态"><a href="#ECALL-指令之后的状态" class="headerlink" title="ECALL 指令之后的状态"></a>ECALL 指令之后的状态</h3><p>现在我执行 <code>ecall</code> 指令：</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304085159639.png" alt="image-20220304085159639"></p>
<p>第一个问题，执行完了 <code>ecall</code> 之后我们现在在哪？我们可以打印 PC 来查看。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304085251190.png" alt="img"></p>
<p>可以看到程序计数器的值变化了，之前我们的程序计数器还在一个很小的地址 <code>0xde6</code>，但是现在在一个大得多的地址。我们还可以查看 page table，我通过在 QEMU 中执行 <code>info mem</code> 来查看当前的 page table，可以看出，这还是与之前完全相同的 page table，所以 page table 没有改变。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304102125562.png" alt="img"></p>
<p>根据现在的程序计数器，代码正在 trampoline page 的最开始，这是用户内存中一个非常大的地址。所以现在我们的指令正运行在内存的 trampoline page 中，我们可以来查看一下现在将要运行的指令。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304102143159.png" alt="img"></p>
<blockquote>
<p>这些指令是内核在 supervisor mode 中将要执行的最开始的几条指令，也是在 trap 机制中最开始要执行的几条指令。因为 gdb 有一些奇怪的行为，我们实际上已经执行了位于 trampoline page 最开始的一条指令（注，也就是 <code>csrrw</code> 指令，交换了寄存器 a0 和 sscratch 的内容），我们将要执行的是第二条指令。</p>
<p>我们可以查看寄存器，寄存器的值并没有改变，这里还是用户程序拥有的一些寄存器内容。</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304102226036.png" alt="img"></p>
<p>现在寄存器里面还都是用户程序的数据，并且这些数据也还只保存在这些寄存器中，所以我们需要非常小心，在将寄存器数据保存在某处之前，我们在这个时间点不能使用任何寄存器，否则的话我们是没法恢复寄存器数据的。如果内核在这个时间点使用了任何一个寄存器，内核会覆盖寄存器内的用户数据，之后如果我们尝试要恢复用户程序，我们就不能恢复寄存器中的正确数据，用户程序的执行也会相应的出错。</p>
<blockquote>
<p>学生提问：我想知道 <code>csrrw</code> 指令是干什么的？</p>
<p>Robert教授：我们过几分钟会讨论这部分，这条指令交换了寄存器 a0 和 sscratch 的内容。这个操作超级重要，它回答了这个问题，内核的 trap 代码如何能够在不使用任何寄存器的前提下做任何操作。这条指令将 a0 的数据保存在了 sscratch 中，同时又将 sscratch 内的数据保存在 a0 中。之后内核就可以任意的使用 a0 寄存器了。</p>
</blockquote>
<p>我们现在在这个地址 <code>0x3ffffff000</code>，也就是上面 page table 输出的最后一个 page，这是 trampoline page。我们现在正在 trampoline page 中执行程序，这个 page 包含了内核的 trap 处理代码。<strong>ECALL 并不会切换page table，这是ecall指令的一个非常重要的特点。所以这意味着，trap 处理代码必须存在于每一个 user page table 中。因为 ecall 并不会切换 page table，我们需要在 user page table 中的某个地方来执行最初的内核代码。而这个 trampoline page，是由内核小心的映射到每一个 user page table 中的，以使得当我们仍然在使用user page table 时，内核在一个地方能够执行 trap 机制的最开始的一些指令。</strong></p>
<blockquote>
<p>总结一下，ecall 指令并不会切换 page table，所以需要在用户态下，执行最开始的一些 kernel 指令。</p>
</blockquote>
<p>这里的控制是通过 STVEC 寄存器完成的，这是一个只能在 supervisor mode 下读写的特权寄存器。在从用户空间进入到内核空间之前，内核会设置好 STVEC 寄存器指向内核希望 trap 代码运行的位置。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304102532719.png" alt="img"></p>
<p>如你所见，内核已经事先设置好了 STVEC 寄存器的内容为 <code>0x3ffffff000</code>，这就是 trampoline page 的起始位置。STVEC 寄存器的内容，就是在 ecall 指令执行之后，我们会在这个特定地址执行指令的原因。</p>
<blockquote>
<p>即使 trampoline page 是在用户地址空间的 user page table 完成的映射，用户代码也不能写它，因为这些 page 对应的 PTE 并没有设置 PTE_U 标志位。这也是 trap 机制是安全的原因。</p>
</blockquote>
<p><strong>我一直在告诉你们我们现在已经在 supervisor mode 了，但是实际上我并没有任何能直接确认当前在哪种 mode 下的方法。不过我的确发现程序计数器现在正在 trampoline page 执行代码，而这些 page 对应的 PTE 并没有设置 PTE_U 标志位。所以现在只有当代码在 supervisor mode 时，才可能在程序运行的同时而不崩溃。所以，我从代码没有崩溃和程序计数器的值推导出我们必然在 supervisor mode。</strong></p>
<p>我们是通过 ecall 走到 trampoline page 的，而 ecall 实际上只会改变三件事情：</p>
<ul>
<li><p>ecall 将代码从 user mode 改到 supervisor mode；</p>
</li>
<li><p>ecall 将程序计数器的值保存在了 SEPC 寄存器，我们可以通过打印程序计数器看到这里的效果；</p>
</li>
</ul>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304102644227.png" alt="img"></p>
<p>尽管其他的寄存器还是还是用户寄存器，但是这里的程序计数器明显已经不是用户代码的程序计数器。这里的程序计数器 PC 是从 STVEC 寄存器拷贝过来的值。我们也可以打印 SEPC 寄存器，这是 ecall 保存用户程序计数器的地方。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304102700097.png" alt="img"></p>
<p>这个寄存器里面有熟悉的地址 <code>0xde6</code>，这是 ecall 指令在用户空间的地址。所以 ecall 至少保存了程序计数器的数值。</p>
<ul>
<li>ecall 会跳转到 STVEC 寄存器指向的指令</li>
</ul>
<p>所以现在，ecall 帮我们做了一点点工作，但是实际上我们离执行内核中的 C 代码还差的很远，接下来：</p>
<ul>
<li>我们需要保存 32 个用户寄存器的内容，方便后续恢复；</li>
<li>需要切换到 kernel page table；</li>
<li>我们需要创建或者找到一个 kernel stack，并将 stack Pointer 寄存器的内容指向那个 kernel stack，这样才能给 C 代码提供栈；</li>
<li>我们还需要跳转到内核中 C 代码的某些合理的位置。</li>
</ul>
<p>ecall 并不会为我们做这里的任何一件事。所以你现在可能会问，为什么 ecall 不多做点工作来将代码执行从用户空间切换到内核空间呢？为什么 ecall 不会保存用户寄存器，或者切换 page table 指针来指向 kernel page table，或者自动的设置 Stack Pointer 指向 kernel stack，或者直接跳转到 kernel的 C 代码，而不是在这里运行复杂的汇编代码？</p>
<p>实际上，有的机器在执行系统调用时，会在硬件中完成所有这些工作。但是 RISC-V 并不会，RISC-V 秉持了这样一个观点：ecall 只完成尽量少必须要完成的工作，其他的工作都交给软件完成。<strong>这里的原因是，RISC-V 设计者想要为软件和操作系统的程序员提供最大的灵活性，这样他们就能按照他们想要的方式开发操作系统。</strong></p>
<p>下面举几个例子，说明为什么 XV6 中 ecall 这里很简单：</p>
<ul>
<li>因为这里的 ecall 是如此的简单，或许某些操作系统可以在不切换 page table 的前提下，执行部分系统调用。切换 page table 的代价比较高，如果 ecall 打包完成了这部分工作，那就不能对一些系统调用进行改进，使其不用在不必要的场景切换 page table。</li>
<li>某些操作系统同时将 user 和 kernel 的虚拟地址映射到一个 page table 中，这样在 user 和 kernel 之间切换时根本就不用切换 page table。对于这样的操作系统来说，如果 ecall 切换了 page table 那将会是一种浪费，并且也减慢了程序的运行。</li>
<li>或许在一些系统调用过程中，一些寄存器不用保存，而哪些寄存器需要保存，哪些不需要，取决于软件，编程语言，和编译器。通过不保存所有的 32 个寄存器或许可以节省大量的程序运行时间，所以你不会想要 ecall 迫使你保存所有的寄存器。</li>
<li>最后，对于某些简单的系统调用或许根本就不需要任何 stack，所以对于一些非常关注性能的操作系统，ecall 不会自动为你完成 stack 切换是极好的。</li>
</ul>
<blockquote>
<p>学生提问：为什么我们在 gdb 中看不到 ecall 的具体内容？我觉得我们是直接跳到 trampoline 代码的。</p>
<p>Robert教授：ecall 只会更新 CPU 中的 mode 标志位为 supervisor，并且设置程序计数器成 STVEC 寄存器内的值。在进入到用户空间之前，内核会将 trampoline page 的地址存在 STVEC 寄存器中。所以 ecall 的下一条指令的位置是 STVEC 指向的地址，也就是 trampoline page 的起始地址。</p>
<p><strong>此注释中的这些步骤：切换 mode 、将 PC 设置成 STVEC 中的值、跳转到 PC 指向的位置。这三步一气呵成，实际上 ecall 是 CPU 的指令，自然在gdb中看不到具体内容。</strong></p>
</blockquote>
<h3 id="uservec-函数"><a href="#uservec-函数" class="headerlink" title="uservec 函数"></a>uservec 函数</h3><p>回到 XV6 和 RISC-V，现在程序位于 trampoline page 的起始，也是 uservec 函数的起始。我们现在需要做的第一件事情就是保存寄存器的内容。在 RISC-V 上，如果不能使用寄存器，基本上不能做任何事情。所以，对于保存这些寄存器，我们有什么样的选择呢？</p>
<p>在一些其他的机器中，我们或许直接就将 32 个寄存器中的内容写到物理内存中某些合适的位置。但是我们不能在 RISC-V 中这样做，因为在RISC-V中，supervisor mode 下的代码不允许直接访问物理内存。所以<strong>我们只能使用 page table 中的内容</strong>，但是从前面的输出来看，page table 中也没有多少内容。</p>
<p>虽然 XV6 并没有使用，但是另一种可能的操作是，直接将 SATP 寄存器指向 kernel page table，之后我们就可以直接使用所有的 kernel mapping 来帮助我们存储用户寄存器。这是合法的，因为 supervisor mode 可以更改 SATP 寄存器。</p>
<p>但是在 trap 代码当前的位置，也就是 trap 机制的最开始，我们并不知道 kernel page table 的地址。并且，更改 SATP 寄存器的指令，要求写入 SATP 寄存器的内容来自于另一个寄存器。所以，为了能执行更新 page table 的指令，我们需要一些空闲的寄存器，这样我们才能先将 page table 的地址存在这些寄存器中，然后再执行修改SATP寄存器的指令。</p>
<blockquote>
<p>总结，一是没有空闲的寄存器，二是一开始不知道 kernel page table 的地址，导致没办法直接将 SATP 指向 kernel page table。</p>
</blockquote>
<p>对于保存用户寄存器，XV6 在 RISC-V 上的实现包括了两个部分。</p>
<p>第一个部分是，XV6 在每个 user page table 映射了 trapframe page，这样每个进程都有自己的 trapframe page。这个 page 包含了很多有趣的数据，但是现在最重要的数据是用来保存用户寄存器的 32 个空槽位。所以，在 trap 处理代码中，现在的好消息是，我们在 user page table 有一个之前由 kernel 设置好的映射关系，这个映射关系指向了一个可以用来存放这个进程的用户寄存器的内存位置。这个位置的虚拟地址总是 <code>0x3ffffffe000</code>。</p>
<p>如果你想查看 XV6 在 trapframe page 中存放了什么，这部分代码在 <code>proc.h</code> 中的 trapframe 结构体中。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304103134450.png" alt="img"></p>
<p>你可以看到很多槽位的名字都对应了特定的寄存器。在最开始还有 5 个数据，这些是内核事先存放在 trapframe 中的数据。比如第一个数据保存了 kernel page table 地址，这将会是 trap 处理代码将要加载到 SATP 寄存器的数值。</p>
<p>所以，如何保存用户寄存器的一半答案是，内核非常方便的将 trapframe page 映射到了每个 user page table。</p>
<p>另一半的答案在于我们之前提过的 SSCRATCH 寄存器。在进入到 user space 之前，内核会将 trapframe page 的地址保存在这个寄存器中，也就是 <code>0x3fffffe000</code> 这个地址。更重要的是，RISC-V 有一个指令允许交换任意两个寄存器的值。而 SSCRATCH 寄存器的作用就是保存另一个寄存器的值，并将自己的值加载给另一个寄存器。如果我查看 <code>trampoline.S</code> 代码：</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304103419959.png" alt="img"></p>
<p>第一件事情就是执行 csrrw 指令，这个指令交换了 a0 和 sscratch 两个寄存器的内容。为了看这里的实际效果，我们来打印 a0，</p>
<p>a0现在的值是 <code>0x3fffffe000</code>，这是 trapframe page 的虚拟地址。它之前保存在 SSCRATCH 寄存器中，但是我们现在交换到了 a0 中。我们也可以打印 SSCRATCH 寄存器，</p>
<p>它现在的内容是 2，这是 a0 寄存器之前的值。a0 寄存器保存的是 write 函数的第一个参数，在这个场景下，是 Shell 传入的文件描述符2。所以我们现在将 a0 的值保存起来了，并且我们有了指向 trapframe page 的指针。现在我们正在朝着保存用户寄存器的道路上前进。实际上，这就是 <code>trampoline.S</code> 中接下来 30多个奇怪指令的工作。这些指令就是的执行 <code>sd</code>，将每个寄存器保存在 <code>trapframe</code> 的不同偏移位置。因为 <code>a0</code> 在交换完之后包含的是 <code>trapframe page</code> 地址，也就是 <code>0x3fffffe000</code>。所以，每个寄存器被保存在了 <code>偏移量 + a0 </code> 的位置。</p>
<blockquote>
<p>学生提问：当与 a0 寄存器进行交换时，trapframe 的地址是怎么出现在 SSCRATCH 寄存器中的？</p>
<p>Robert教授：<strong>在内核前一次切换回用户空间时，内核会执行 <code>set sscratch</code> 指令，将这个寄存器的内容设置为 <code>0x3fffffe000</code>，也就是 trapframe page 的虚拟地址。</strong>所以，当我们在运行用户代码，比如运行 Shell 时，SSCRATCH 保存的就是指向 trapframe 的地址。之后，Shell 执行了 ecall 指令，跳转到了 trampoline page，这个 page 中的第一条指令会交换 a0 和 SSCRATCH 寄存器的内容。所以，SSCRATCH 中的值，也就是指向 trapframe 的指针现在存储于 a0 寄存器中。</p>
<p>同一个学生提问：这是发生在进程创建的过程中吗？这个 SSCRATCH 寄存器存在于哪？</p>
<p>Robert教授：这个寄存器存在于 CPU 上，这是 CPU 上的一个特殊寄存器。内核在什么时候设置的它呢？这有点复杂。它被设置的实际位置，我们可以看下图，</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304103532426.png"></p>
<blockquote>
<p>选中的代码是内核在返回到用户空间之前执行的最后两条指令。在内核返回到用户空间时，会恢复所有的用户寄存器。之后会再次执行交换指令，csrrw。因为之前内核已经设置了 a0 保存的是 trapframe 地址，经过交换之后 SSCRATCH 仍然指向了 trapframe page 地址，而 a0 也恢复成了之前的数值。最后 sret 返回到了用户空间。</p>
<p>你或许会好奇，a0 是如何有 trapframe page 的地址。我们可以查看 <code>trap.c</code> 代码，</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304103603251.png" alt="img"></p>
<blockquote>
<p>这是内核返回到用户空间的最后的C函数，C 函数做的最后一件事情是调用 fn 函数，传递的参数是TRAMFRAME 和 user page table。在C代码中，当你调用函数，第一个参数会存在 a0，这就是为什么 a0 里面的数值是指向 trapframe 的指针。fn 函数是就是刚刚我向你展示的位于 <code>trampoline.S</code> 中的代码。</p>
<p>学生提问：当你启动一个进程，之后进程在运行，之后在某个时间点进程执行了 ecall 指令，那么你是在什么时候执行上一个问题中的 fn 函数呢？因为这是进程的第一个 ecall 指令，所以这个进程之前应该没有调用过fn函数吧。</p>
<p>Robert教授：一台机器总是从内核开始运行的，当机器启动的时候，它就是在内核中，任何时候，不管是进程第一次启动还是从一个系统调用返回，进入到用户空间的唯一方法是就是执行 sret 指令。sret 指令是由RISC-V 定义的用来从 supervisor mode 转换到 user mode。所以，在任何用户代码执行之前，内核会执行 fn 函数，并设置好所有的东西，例如 SSCRATCH，STVEC 寄存器。</p>
<p>学生提问：当我们在汇编代码中执行 ecall 指令，是什么触发了 trampoline 代码的执行，是 CPU 中的从user 到 supervisor 的标志位切换吗？</p>
<p>Robert教授：在我们的例子中，Shell在用户空间执行了ecall指令。ecall会完成几件事情，ecall指令会设置当前为 supervisor mode，保存程序计数器到SEPC寄存器，并且将程序计数器设置成控制寄存器 STVEC 的内容。STVEC 是内核在进入到用户空间之前设置好的众多数据之一，内核会将其设置成 trampoline page 的起始位置。所以，当 ecall 指令执行时，ecall 会将 STVEC 拷贝到程序计数器，之后程序继续执行，但是却会在当前程序计数器所指的地址，也就是 trampoline page 的起始地址执行。</p>
<p>学生提问：寄存器保存在了 trapframe page，但是这些寄存器用户程序也能访问，为什么我们要使用内存中一个新的区域（指的是trapframe page），而不是使用程序的栈？</p>
<p>Robert教授：好的，这里或许有两个问题。第一个是，为什么我们要保存寄存器？为什么内核要保存寄存器的原因，是因为内核即将要运行会覆盖这些寄存器的C代码。如果我们想正确的恢复用户程序，我们需要将这些寄存器恢复成它们在 ecall 调用之前的数值，所以我们需要将所有的寄存器都保存在 trapframe 中，这样才能在之后恢复寄存器的值。</p>
<p>另一个问题是，<strong>为什么这些寄存器保存在 trapframe，而不是用户代码的栈中？这个问题的答案是，我们不确定用户程序是否有栈，必然有一些编程语言没有栈，</strong>对于这些编程语言的程序，Stack Pointer不指向任何地址。当然，也有一些编程语言有栈，但是或许它的格式很奇怪，内核并不能理解。比如，编程语言以堆中以小块来分配栈，编程语言的运行时知道如何使用这些小块的内存来作为栈，但是内核并不知道。所以，如果我们想要运行任意编程语言实现的用户程序，内核就不能假设用户内存的哪部分可以访问，哪部分有效，哪部分存在。所以内核需要自己管理这些寄存器的保存，这就是为什么内核将这些内容保存在属于内核内存的trapframe中，而不是用户内存。</p>
</blockquote>
<p>程序现在仍然在trampoline的最开始，也就是 uservec 函数的最开始，我们基本上还没有执行任何内容。我在寄存器拷贝的结束位置设置了一个断点，我们在 gdb 中让代码继续执行，现在我们停在了下面这条 ld（load）指令。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104009495.png" alt="img"></p>
<p>这条指令正在将 a0 指向的内存地址往后数的第8个字节开始的数据加载到 Stack Pointer 寄存器。a0 的内容现在是trapframe page的地址，从本节第一张图中，trapframe 的格式可以看出，第 8 个字节开始的数据是内核的Stack Pointer（kernel_sp）。trapframe 中的 kernel_sp 是由 kernel 在进入用户空间之前就设置好的，它的值是这个进程的 kernel stack。所以这条指令的作用是初始化 Stack Pointer 指向这个进程的 kernel stack 的最顶端。指向完这条指令之后，我们打印一下当前的 Stack Pointer 寄存器，</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104045039.png" alt="img"></p>
<p>这是这个进程的 kernel stack。因为 XV6 在每个 kernel stack 下面放置一个 guard page，所以 kernel stack 的地址都比较大。</p>
<p>下一条指令是向 tp 寄存器写入数据。因为在 RISC-V 中，没有一个直接的方法来确认当前运行在多核处理器的哪个核上，XV6 会将 CPU 核的编号也就是 hartid 保存在 tp 寄存器。在内核中好几个地方都会使用了这个值，例如，内核可以通过这个值确定某个 CPU 核上运行了哪些进程。我们执行这条指令，并且打印 tp 寄存器。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104101258.png" alt="img"></p>
<p>我们现在运行在CPU核0，这说的通，因为我之前配置了QEMU只给XV6分配一个核，所以我们只能运行在核0上。</p>
<blockquote>
<p>tp 寄存器保存的是当前运行在哪个核中</p>
</blockquote>
<p>下一条指令是向 t0 寄存器写入数据。这里写入的是我们将要执行的第一个 C 函数的指针，也就是函数 usertrap 的指针。我们在后面会使用这个指针。</p>
<blockquote>
<p>向 t0 寄存器写入的是即将要执行的第一个 C 函数的指针</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104155385.png" alt="img"></p>
<p>下一条指令是向 t1 寄存器写入数据。这里写入的是 kernel page table 的地址，我们可以打印 t1 寄存器的内容。</p>
<blockquote>
<p>t1 寄存器写入的是 kernel page table 的地址。</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104210332.png" alt="img"></p>
<p>实际上严格来说，t1 的内容并不是 kernel page table 的地址，这是你需要向 SATP 寄存器写入的数据。它包含了 kernel page table 的地址，但是移位了（注，详见4.3），并且包含了各种标志位。</p>
<p>下一条指令是交换 SATP 和 t1 寄存器。这条指令执行完成之后，<strong>当前程序会从 user page table 切换到 kernel page table。</strong>现在我们在 QEMU 中打印 page table，可以看出与之前的 page table 完全不一样。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104239186.png" alt="img"></p>
<p>现在这里输出的是由内核设置好的巨大的 kernel page table。所以现在我们成功的切换了 page table，我们在这个位置进展的很好，Stack Pointer 指向了 kernel stack；我们有了 kernel page table，可以读取 kernel data。</p>
<p>我们已经准备好了执行内核中的C代码了。</p>
<p>这里还有个问题，为什么代码没有崩溃？毕竟我们在内存中的某个位置执行代码，程序计数器保存的是虚拟地址，如果我们切换了 page table，为什么同一个虚拟地址不会通过新的 page table 寻址走到一些无关的 page中？看起来我们现在没有崩溃并且还在执行这些指令。有人来猜一下原因吗？</p>
<blockquote>
<p>学生回答：因为我们还在 trampoline 代码中，而 trampoline 代码在用户空间和内核空间都映射到了同一个地址。</p>
<p>教授回答：完全正确，我不知道你们是否还记得 user page table 的内容，trampoline page在user page table中的映射与kernel page table中的映射是完全一样的。这两个page table中其他所有的映射都是不同的，只有trampoline page的映射是一样的，因此我们在切换page table时，寻址的结果不会改变，我们实际上就可以继续在同一个代码序列中执行程序而不崩溃。这是trampoline page的特殊之处，它同时在user page table和kernel page table都有相同的映射关系。</p>
</blockquote>
<p>之所以叫trampoline page，是因为你某种程度在它上面“弹跳”了一下，然后从用户空间走到了内核空间。</p>
<p>最后一条指令是 <code>jr t0</code> 。执行了这条指令，我们就要从 trampoline 跳到内核的C代码中。这条指令的作用是跳转到 t0 指向的函数中。我们打印 t0 对应的一些指令，</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104355536.png" alt="img"></p>
<p>可以看到 t0 的位置对应于一个叫做 usertrap 函数的开始。接下来我们就要以 kernel stack，kernel page table跳转到 usertrap 函数。</p>
<h3 id="usertrap-函数"><a href="#usertrap-函数" class="headerlink" title="usertrap 函数"></a>usertrap 函数</h3><p>usertrap函数是位于 <code>trap.c</code> 文件的一个函数。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104429488.png" alt="img"></p>
<p>既然我们已经运行在C代码中，接下来，我在gdb中输入 <code>tui enable</code> 打开对于 C 代码的展示。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104450725.png" alt="img"></p>
<p>有很多原因都可以让程序运行进入到 <code>usertrap</code> 函数中来，比如系统调用，运算时除以0，使用了一个未被映射的虚拟地址，或者是设备中断。<code>usertrap</code> 某种程度上存储并恢复硬件状态，但是它也需要检查触发 trap 的原因，以确定相应的处理方式，我们在接下来执行 usertrap 的过程中会同时看到这两个行为。</p>
<p>接下来，让我们一步步执行 usertrap 函数：</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104505409.png" alt="img"></p>
<p>它做的第一件事情是<strong>更改 STVEC 寄存器。</strong>取决于 trap 是来自于用户空间还是内核空间，实际上 XV6 处理 trap 的方法是不一样的。目前为止，我们只讨论过当 trap 是由用户空间发起时会发生什么。如果 trap 从内核空间发起，将会是一个非常不同的处理流程，因为从内核发起的话，程序已经在使用 kernel page table。所以当 trap 发生时，程序执行仍然在内核的话，很多处理都不必存在。</p>
<p>在内核中执行任何操作之前，usertrap 中先将 STVEC 指向了 kernelvec 变量，这是内核空间 trap 处理代码的位置，而不是用户空间 trap 处理代码的位置。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104548581.png" alt="img"></p>
<p>出于各种原因，我们需要知道当前运行的是什么进程，我们通过调用 myproc 函数来做到这一点。myproc 函数实际上会查找一个根据当前 CPU 核的编号索引的数组，CPU 核的编号是 hartid，如果你还记得，我们之前在uservec 函数中将它存在了 tp 寄存器。这是 myproc 函数找出当前运行进程的方法。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104616898.png" alt="img"></p>
<p>接下来我们要保存用户程序计数器，它仍然保存在 SEPC 寄存器中，但是可能发生这种情况：当程序还在内核中执行时，我们可能切换到另一个进程，并进入到那个程序的用户空间，然后那个进程可能再调用一个系统调用进而导致 SEPC 寄存器的内容被覆盖。所以，我们需要保存当前进程的 SEPC 寄存器到一个与该进程关联的内存中，这样这个数据才不会被覆盖。这里我们使用 trapframe 来保存这个程序计数器。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104752934.png" alt="img"></p>
<p>接下来我们需要找出我们现在会在 usertrap 函数的原因。根据触发 trap 的原因，RISC-V 的 SCAUSE 寄存器会有不同的数字。数字8表明，我们现在在 trap 代码中是因为系统调用。</p>
<blockquote>
<p>可以打印 SCAUSE 寄存器，它的确包含了数字8，我们的确是因为系统调用才走到这里的。</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104812798.png" alt="img"></p>
<p>所以，我们可以进到这个 if 语句中。接下来第一件事情是检查是不是有其他的进程杀掉了当前进程，但是我们的 shell 没有被杀掉，所以检查通过。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104823029.png" alt="img"></p>
<p>在 RISC-V 中，存储在 SEPC 寄存器中的程序计数器，是用户程序中触发 trap 的指令的地址。但是当我们恢复用户程序时，我们希望在下一条指令恢复，也就是 ecall 之后的一条指令。所以对于系统调用，我们对于保存的用户程序计数器加 4，这样我们会在 ecall 的下一条指令恢复，而不是重新执行 ecall 指令。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104846355.png" alt="img"></p>
<p>XV6 会在处理系统调用的时候使能中断，这样中断可以更快的服务，有些系统调用需要许多时间处理。中断总是会被 RISC-V 的 trap 硬件关闭，所以在这个时间点，我们需要<strong>显式的打开中断。</strong></p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104917288.png" alt="img"></p>
<p>下一行代码中，我们会调用 syscall 函数。这个函数定义在 <code>syscall.c</code>。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304104928779.png" alt="img"></p>
<p>它的作用是从 syscall 表单中，根据系统调用的编号查找相应的系统调用函数。如果你还记得之前的内容，Shell 调用的 write 函数将 a7 设置成了系统调用编号，对于 write 来说就是 16。<strong>所以 syscall 函数的工作就是获取由 trampoline 代码保存在 trapframe 中 a7 的数字，然后用这个数字索引实现了每个系统调用的表单。</strong></p>
<p>我们可以打印 num ，发现的确是16。这与 Shell 调用的 write 函数写入的数字是一致的。之后查看通过 num 索引得到的函数，正是 sys_write 函数。sys_write 函数是内核对于 write 系统调用的具体实现。这里再往后的代码执行就非常复杂了，我就不具体介绍了。在这节课中，对于系统调用的实现，我只对进入和跳出内核感兴趣，这里我让代码直接执行 <code>sys_write</code> 函数。</p>
<p>这里有件有趣的事情，系统调用需要找到它们的参数。你们还记得 write 函数的参数吗？分别是文件描述符 2，写入数据缓存的指针，写入数据的长度 2。syscall 函数直接通过 trapframe 来获取这些参数，就像这里刚刚可以查看 trapframe 中的 a7 寄存器一样，我们可以查看 a0 寄存器，这是第一个参数，a1是第二个参数，a2是第三个参数。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304105043494.png" alt="img"></p>
<p>现在 syscall 执行了真正的系统调用，之后 sys_write 返回了。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304105057200.png" alt="img"></p>
<p>这里向 trapframe 中的 a0 赋值的原因是：所有的系统调用都有一个返回值，比如 write 会返回实际写入的字节数，<strong>而 RISC-V 上的C代码的习惯是函数的返回值存储于寄存器 a0，</strong>所以为了模拟函数的返回，我们将返回值存储在 trapframe 的 a0 中。之后，当我们返回到用户空间，trapframe 中的 a0 槽位的数值会写到实际的 a0 寄存器，Shell会认为 a0 寄存器中的数值是 write 系统调用的返回值。执行完这一行代码之后，我们打印这里 trapframe 中 a0 的值，可以看到输出 2。</p>
<p>这意味这 sys_write 的返回值是 2，符合传入的参数，这里只写入了 2个字节。从 syscall 函数返回之后，我们回到了 <code>trap.c</code> 中的 usertrap 函数。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304105139151.png" alt="img"></p>
<p>我们再次检查当前用户进程是否被杀掉了，因为我们不想恢复一个被杀掉的进程。当然，在我们的场景中，Shell没有被杀掉。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304105152631.png" alt="img"></p>
<p>最后，usertrap调用了一个函数 <code>usertrapret</code>。</p>
<h3 id="usertrapret-函数"><a href="#usertrapret-函数" class="headerlink" title="usertrapret 函数"></a>usertrapret 函数</h3><p>usertrap函数的最后调用了usertrapret函数，来设置好我之前说过的，在返回到用户空间之前内核要做的工作。我们可以查看这个函数的内容。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304105214655.png" alt="img"></p>
<p>它首先关闭了中断。我们之前在系统调用的过程中是打开了中断的，这里关闭中断是因为我们将要更新 STVEC 寄存器来指向用户空间的 trap 处理代码，而之前在内核中的时候，我们指向的是内核空间的 trap 处理代码（6.6）。<strong>我们关闭中断因为当我们将 STVEC 更新到指向用户空间的 trap 处理代码时，我们仍然在内核中执行代码。如果这时发生了一个中断，那么程序执行会走向用户空间的 trap 处理代码</strong>，即便我们现在仍然在内核中，出于各种各样具体细节的原因，这会导致内核出错。所以我们这里关闭中断。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304105308767.png" alt="img"></p>
<p>在下一行我们设置了 STVEC 寄存器指向 trampoline 代码，在那里最终会执行 sret 指令返回到用户空间。位于 trampoline 代码最后的 sret 指令会重新打开中断。这样，即使我们刚刚关闭了中断，当我们在执行用户代码时中断是打开的。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304105340881.png" alt="img"></p>
<p>接下来的几行填入了 trapframe 的内容，这些内容对于执行 trampoline 代码非常有用。这里的代码就是：</p>
<ul>
<li>存储了kernel page table的指针</li>
<li>存储了当前用户进程的kernel stack</li>
<li>存储了usertrap函数的指针，这样trampoline代码才能跳转到这个函数（注，详见6.5中 <em>ld t0 (16)a0</em> 指令）</li>
<li>从 tp 寄存器中读取当前的CPU核编号，并存储在trapframe中，这样trampoline代码才能恢复这个数字，因为用户代码可能会修改这个数字</li>
</ul>
<p>现在我们在usertrapret函数中，我们正在设置trapframe中的数据，这样下一次从用户空间转换到内核空间时可以用到这些数据。</p>
<blockquote>
<p>学生提问：为什么trampoline代码中不保存SEPC寄存器？</p>
<p>Robert教授：可以存储。trampoline代码没有像其他寄存器一样保存这个寄存器，但是我们非常欢迎大家修改XV6来保存它。如果你还记得的话（详见6.6），这个寄存器实际上是在C代码usertrap中保存的，而不是在汇编代码trampoline中保存的。我想不出理由这里哪种方式更好。用户寄存器（User Registers）必须在汇编代码中保存，因为任何需要经过编译器的语言，例如C语言，都不能修改任何用户寄存器。所以对于用户寄存器，必须要在进入C代码之前在汇编代码中保存好。但是对于SEPC寄存器（注，控制寄存器），我们可以早点保存或者晚点保存。</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304105546413.png" alt="img"></p>
<p>接下来我们要设置 SSTATUS 寄存器，这是一个控制寄存器。这个寄存器的 SPP bit 位控制了 sret 指令的行为，该 bit 为 0 表示下次执行 sret 的时候，我们想要返回 user mode 而不是 supervisor mode。这个寄存器的 SPIE bit位控制了，在执行完 sret 之后，是否打开中断。因为我们在返回到用户空间之后，我们的确希望打开中断，所以这里将 SPIE bit 位设置为1。修改完这些 bit 位之后，我们会把新的值写回到 SSTATUS 寄存器。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304105638012.png" alt="img"></p>
<p>我们在 trampoline 代码的最后执行了sret指令。这条指令会将程序计数器设置成 SEPC 寄存器的值，所以现在我们将 SEPC 寄存器的值设置成之前保存的用户程序计数器的值。在不久之前，我们在 usertrap 函数中将用户程序计数器保存在trapframe中的epc字段。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304105707488.png" alt="img"></p>
<p>接下来，我们根据user page table地址生成相应的SATP值，这样我们在返回到用户空间的时候才能完成page table的切换。实际上，我们会在汇编代码trampoline中完成page table的切换，并且也只能在trampoline中完成切换，因为只有trampoline中代码是同时在用户和内核空间中映射。但是我们现在还没有在trampoline代码中，我们现在还在一个普通的C函数中，所以这里我们将page table指针准备好，并将这个指针作为第二个参数传递给汇编代码，这个参数会出现在a1寄存器。</p>
<p>倒数第二行的作用是计算出我们将要跳转到汇编代码的地址。我们期望跳转的地址是tampoline中的userret函数，这个函数包含了所有能将我们带回到用户空间的指令。所以这里我们计算出了userret函数的地址。</p>
<p>倒数第一行，将fn指针作为一个函数指针，执行相应的函数（也就是userret函数）并传入两个参数，两个参数存储在a0，a1寄存器中。</p>
<h3 id="userret-函数"><a href="#userret-函数" class="headerlink" title="userret 函数"></a>userret 函数</h3><p>现在程序执行又到了trampoline代码。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304105840754.png" alt="img"></p>
<p>第一步是切换page table。在执行 <code>csrw satp, a1</code> 之前，page table应该还是巨大的kernel page table。这条指令会将user page table（在usertrapret中作为第二个参数传递给了这里的userret函数，所以存在a1寄存器中）存储在SATP寄存器中。执行完这条指令之后，page table就变成了小得多的user page table。但是幸运的是，user page table也映射了trampoline page，所以程序还能继续执行而不是崩溃。（注，sfence.vma是清空页表缓存，详见4.4）。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304105932915.png" alt="img"></p>
<p>在uservec函数中，第一件事情就是交换SSRATCH和a0寄存器。而这里，我们将 SSCRATCH 寄存器恢复成保存好的用户的a0寄存器。在这里 a0 是trapframe的地址，因为C代码usertrapret函数中将trapframe地址作为第一个参数传递过来了。112是a0寄存器在trapframe中的位置。（注，这里有点绕，本质就是通过当前的a0寄存器找出存在trapframe中的a0寄存器）我们先将这个地址里的数值保存在t0寄存器中，之后再将t0寄存器的数值保存在SSCRATCH寄存器中。</p>
<p>目前为止，所有的寄存器内容还是属于内核。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304110045221.png" alt="img"></p>
<p>接下来的这些指令将 a0 寄存器指向的 trapframe 中，之前保存的寄存器的值加载到对应的各个寄存器中。之后，我们离能真正运行用户代码就很近了。</p>
<blockquote>
<p>学生提问：现在 trapframe 中的 a0 寄存器是我们执行系统调用的返回值吗？</p>
<p>Robert教授：是的，系统调用的返回值覆盖了我们保存在 trapframe 中的 a0 寄存器的值（详见6.6）。我们希望用户程序 Shell 在 a0 寄存器中看到系统调用的返回值。所以，trapframe 中的 a0 寄存器现在是系统调用的返回值 2。相应的 SSCRATCH 寄存器中的数值也应该是 2，可以通过打印寄存器的值来验证。</p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304110411221.png" alt="img"></p>
<p>现在我们打印所有的寄存器，</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304110421371.png" alt="img"></p>
<p>我不确定你们是否还记得，但是这些寄存器的值就是我们在最最开始看到的用户寄存器的值。例如SP寄存器保存的是user stack地址，这是一个在较小的内存地址；a1寄存器是我们传递给write的buffer指针，a2是我们传递给write函数的写入字节数。</p>
<p>a0 寄存器现在还是个例外，它现在仍然是指向 trapframe 的指针，而不是保存了的用户数据。</p>
<p>接下来，在我们即将返回到用户空间之前，我们交换SSCRATCH寄存器和a0寄存器的值。前面我们看过了SSCRATCH现在的值是系统调用的返回值2，a0寄存器是trapframe的地址。交换完成之后，a0持有的是系统调用的返回值，SSCRATCH持有的是trapframe的地址。之后trapframe的地址会一直保存在SSCRATCH中，直到用户程序执行了另一次trap。现在我们还在kernel中。</p>
<p>sret是我们在kernel中的最后一条指令，当我执行完这条指令：</p>
<ul>
<li>程序会切换回 user mode；</li>
<li>SEPC 寄存器的数值会被拷贝到 PC 寄存器（程序计数器）；</li>
<li>重新打开中断。</li>
</ul>
<p>现在我们回到了用户空间，打印PC寄存器：</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304110453852.png" alt="image-20220304110453852"></p>
<p>这是一个较小的指令地址，非常像是在用户内存中。如果我们查看 <code>sh.asm</code>，可以看到这个地址是 write 函数的 ret 指令地址。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220304110507023.png" alt="img"></p>
<p>所以，现在我们回到了用户空间，执行完 ret 指令之后我们就可以从 write 系统调用返回到 shell 中了。或者更严格的说，是从触发了系统调用的 write 库函数中返回到 shell 中。</p>
<p>总结一下，系统调用被刻意设计的看起来像是函数调用，但是背后的 user&#x2F;kernel 转换比函数调用要复杂的多。之所以这么复杂，很大一部分原因是要保持 user&#x2F;kernel 之间的隔离性，内核不能信任来自用户空间的任何内容。</p>
<p>另一方面，XV6 实现 trap 的方式比较特殊，XV6 并不关心性能。但是通常来说，操作系统的设计人员和 CPU 设计人员非常关心如何提升 trap 的效率和速度。必然还有跟我们这里不一样的方式来实现 trap，当你在实现的时候，可以从以下几个问题出发：</p>
<ul>
<li>硬件和软件需要协同工作，你可能需要重新设计 XV6，重新设计 RISC-V 来使得这里的处理流程更加简单，更加快速。</li>
<li>另一个需要时刻记住的问题是，恶意软件是否能滥用这里的机制来打破隔离性。</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://acking.cc/2023/01/28/ch08/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/uploads/1.jpg">
      <meta itemprop="name" content="Sam Shen">
      <meta itemprop="description" content="share cs knowledge">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AcKing">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/mit6.s081-ch8" class="post-title-link post-title-link-external" itemprop="url">mit6.s081-ch8<i class="fa fa-external-link-alt"></i></a>
          
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2023-01-28 00:00:00 / Modified: 20:36:32" itemprop="dateCreated datePublished" datetime="2023-01-28T00:00:00+08:00">2023-01-28</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mit6-s081/" itemprop="url" rel="index"><span itemprop="name">mit6.s081</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/mit6-s081/OS/" itemprop="url" rel="index"><span itemprop="name">OS</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="chapter-8-Page-Fault"><a href="#chapter-8-Page-Fault" class="headerlink" title="chapter 8 Page Fault"></a>chapter 8 Page Fault</h1><h3 id="Page-Fault-basics"><a href="#Page-Fault-basics" class="headerlink" title="Page Fault basics"></a>Page Fault basics</h3><p>今天的课程内容是 page fault，以及通过 page fault 可以实现的一系列虚拟内存功能。这里相关的功能有：</p>
<ul>
<li>lazy allocation 这是下一个 lab 的内容</li>
<li>copy-on-write fork</li>
<li>demand paging</li>
<li>memory mapped files</li>
</ul>
<p>几乎所有稍微正经的操作系统都实现了这些功能，比如 Linux 就实现了所有的这些功能。然而在 XV6 中，实话实说，这些功能都没实现。在 XV6 中，一旦用户空间进程触发了 page fault，会导致进程被杀掉，这是非常保守的处理方式。</p>
<p>在这节课，我们将会探讨在发生 page fault 时可以做的一些有趣的事情。这节课对于代码的讲解会比较少，相应的在设计层面会有更多的内容，毕竟我们也没有代码可以讲解（因为 XV6 中没有实现）。</p>
<p>另一件重要的事情是，今天课程的内容对应了后面几个实验。下一个实验 lazy lab 今天会发布出来，copy-on-write、fork 和 mmap 也是后续实验的内容。这些都是操作系统中非常有趣的部分，我们将会在实验中花大量时间来研究它。</p>
<p>在进入到具体细节之前，我们先来简单回顾一下虚拟内存，你可以认为虚拟内存有两个主要的优点：</p>
<ul>
<li>第一个是 Isolation，隔离性。虚拟内存使得操作系统可以为每个应用程序提供属于它们自己的地址空间。所以一个应用程序不可能有意或者无意的修改另一个应用程序的内存数据。虚拟内存同时也提供了用户空间和内核空间的隔离性，我们在之前的课程已经谈过很多相关内容，并且你们通过 page table lab 也可以理解虚拟内存的隔离性。</li>
<li>另一个好处是 level of indirection，提供了一层抽象。处理器和所有的指令都可以使用虚拟地址，而内核会定义从虚拟地址到物理地址的映射关系，这一层抽象是我们这节课要讨论的许多有趣功能的基础。不过到目前为止，在 XV6 中内存地址的映射都比较无聊，实际上在内核中基本上是直接映射（注，也就是虚拟地址等于物理地址）。当然也有几个比较有意思的地方：<ul>
<li>trampoline page，它使得内核可以将一个物理内存 page 映射到多个用户地址的虚拟空间中。</li>
<li>guard page，它同时在内核空间和用户空间用来保护 stack</li>
</ul>
</li>
</ul>
<p>到目前为止，我们介绍的内存地址映射相对来说比较静态。不管是 user page table 还是 kernel page table，都是在最开始的时候设置好，之后就不会再做任何变动。</p>
<p><strong>page fault 可以让这里的地址映射关系变得动态起来。通过 page fault，内核可以更新 page table，这是一个非常强大的功能。</strong>因为现在可以动态的更新虚拟地址这一层抽象，结合 page table 和 page fault，内核将会有巨大的灵活性。我们接下来会看到各种各样利用动态变更 page table 实现的有趣的功能。</p>
<p>但是在那之前，我们需要思考的是，内核需要什么样的信息才能够响应 page fault。</p>
<ul>
<li><strong>我们需要出错的虚拟地址，或者是触发 page fault 的源。</strong>可以假设的是，你们在 page table lab 中已经看过一些相关的 panic，所以你们可能已经知道，当出现 page fault 的时候，XV6 内核会打印出错的虚拟地址，并且这个地址会被保存在 <code>STVAL</code> 寄存器中。所以，当一个用户应用程序触发了 page fault，page fault 会使用与 Robert 教授上节课介绍的相同的 trap 机制，将程序运行切换到内核，同时也会将出错的地址存放在 STVAL 寄存器中。这是我们需要知道的第一个信息。</li>
<li><strong>我们需要知道的第二个信息是出错的原因，我们或许想要对不同场景的 page fault 有不同的响应。</strong>不同的场景是指，比如因为 <code>load</code> 指令触发的 page fault、因为 <code>store</code> 指令触发的 page fault 又或者是因为 <code>jump</code> 指令触发的 page fault。实际上，如果你查看 RISC-V 的文档，在 <code>SCAUSE</code>（注，Supervisor cause寄存器，保存了 trap 机制中进入到 supervisor mode 的原因）寄存器的介绍中，有多个与 page fault 相关的原因。比如，13 表示是因为 <code>load</code> 引起的 page fault；15 表示是因为 <code>store</code> 引起的 page fault；12 表示是因为 <code>指令执行</code> 引起的 page fault。<strong>所以第二个信息存在 SCAUSE 寄存器中，其中总共有3个类型的原因与 page fault 相关，分别是读、写和指令。</strong>ECALL 进入到 supervisor mode 对应的是 8，这是我们在上节课中应该看到的 SCAUSE 值。<strong>基本上来说，page fault 和其他的异常使用与系统调用相同的 trap 机制，从用户空间切换到内核空间。</strong>如果是因为 page fault 触发的 trap 机制并且进入到内核空间，STVAL 寄存器和 SCAUSE 寄存器都会有相应的值。</li>
</ul>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306184054218.png" alt="img"></p>
<ul>
<li><strong>我们想要知道的第三个信息是触发 page fault 的指令的地址。</strong>从上节课可以知道，作为 trap 处理代码的一部分，这个地址存放在 <code>SEPC</code>（Supervisor Exception Program Counter）寄存器中，并同时会保存在 trapframe -&gt; epc 中。</li>
</ul>
<p>所以，从硬件和 XV6 的角度来说，当出现了 page fault，现在有了 3 个对我们来说极其有价值的信息，分别是：</p>
<ul>
<li>引起 page fault 的内存源地址</li>
<li>引起 page fault 的原因类型</li>
<li>引起 page fault 时的 PC 值，这表明了 page fault 在用户空间发生的位置</li>
</ul>
<blockquote>
<p>我们之所以关心触发 page fault 时的程序计数器值，<strong>是因为在 page fault handler 中我们或许想要修复 page table，并重新执行对应的指令。</strong>理想情况下，修复完 page table 之后，指令就可以无错误的运行了。所以，能够恢复因为 page fault 而中断的指令运行是很重要的。</p>
</blockquote>
<p>接下来我们将查看不同虚拟内存功能的实现机制，来帮助我们理解如何利用 page fault handler 修复 page table 并做一些有趣的事情。</p>
<h3 id="Lazy-page-allocation"><a href="#Lazy-page-allocation" class="headerlink" title="Lazy page allocation"></a>Lazy page allocation</h3><p>我们首先来看一下内存  allocation，或者更具体的说 sbrk。sbrk 是 XV6 提供的系统调用，<strong>它使得用户应用程序能扩大自己的 heap 。</strong>当一个应用程序启动的时候，sbrk 指向的是 heap 的最底端，同时也是 stack 的最顶端。这个位置通过代表进程的数据结构中的 <code>sz</code> 字段表示，这里以 <code>p-&gt;sz</code> 表示。</p>
<blockquote>
<p>这里需要记住 <code>p -&gt; sz</code> 的含义，是指栈的顶部，堆的底部。</p>
</blockquote>
<p>当调用 <code>sbrk</code> 时，它的参数是整数，代表了你想要申请的 page 数量（<strong>注，原视频说的是 page，但是根据 Linux <a target="_blank" rel="noopener" href="https://man7.org/linux/man-pages/man2/sbrk.2.html">man page</a>，实际中 sbrk 的参数是字节数</strong>）。sbrk 会扩展 heap 的上边界（也就是会扩大 heap）。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306184329253.png" alt="image-20220306184329253"></p>
<p>这意味着，当 sbrk 实际发生或者被调用的时候，内核会分配一些物理内存，并将这些内存映射到用户应用程序的地址空间，然后将内存内容初始化为 0，再返回 sbrk 系统调用。这样，应用程序可以通过多次 sbrk 系统调用来增加它所需要的内存。类似的，应用程序还可以通过给 sbrk 传入负数作为参数，来减少或者压缩它的地址空间，在这节课我们只关注增加内存的场景。</p>
<blockquote>
<p>sbrk 传入参数的正负会决定是增加还是减小地址空间</p>
</blockquote>
<p><strong>在 XV6 中，sbrk 的实现默认是 eager allocation。</strong>这表示了，一旦调用了 sbrk，内核会<strong>立即</strong>分配应用程序所需要的物理内存。但是实际上，对于应用程序来说很难预测自己需要多少内存，所以通常来说，应用程序倾向于申请多于自己所需要的内存。这意味着，进程的内存消耗会增加许多，但是有部分内存永远也不会被应用程序所使用到。</p>
<blockquote>
<p> 你或许会认为这里很蠢，怎么可以这样呢？你可以设想自己写了一个应用程序，读取了一些输入然后通过一个矩阵进行一些运算。你需要为最坏的情况做准备，比如说为最大可能的矩阵分配内存，但是应用程序可能永远也用不上这些内存，通常情况下，应用程序会在一个小得多的矩阵上进行运算。<strong>所以，程序员过多的申请内存但是过少的使用内存，这种情况还挺常见的。</strong></p>
</blockquote>
<p>原则上来说，这不是一个大问题。但是使用虚拟内存和 page fault handler，我们完全可以用某种更聪明的方法来解决这里的问题，这里就是利用 <em>lazy allocation</em>，其核心思想非常简单，sbrk 系统调基本上不做任何事情，唯一需要做的事情就是提升 <code>p-&gt;sz</code>，将 <code>p-&gt;sz</code> 增加 n，其中 n 是需要新分配的内存 page 数量。但是内核在这个时间点并不会分配任何物理内存。之后在某个时间点，应用程序使用到了新申请的那部分内存，这时会触发 page fault，因为我们还没有将新的内存映射到 page table。所以，如果我们解析一个大于旧的 <code>p-&gt;sz</code> ，但是又小于新的 <code>p-&gt;sz</code> （注，也就是旧的 <code>p -&gt; sz + n</code>）的虚拟地址，我们希望内核能够分配一个内存 page，并且重新执行指令。</p>
<p>所以，当我们看到了一个 page fault，相应的虚拟地址小于当前 <code>p-&gt;sz</code> ，同时大于 stack（对应上文所说的大于旧的，小于新的），那么我们就知道这是一个来自于 heap 的地址，但是内核还没有分配任何物理内存。所以对于这个 page fault 的响应也理所当然的直接明了：<strong>在 page fault handler 中，通过 kalloc 函数分配一个内存 page；初始化这个 page 内容为 0；将这个内存 page 映射到 user page table 中；最后重新执行指令。</strong>比方说，如果是 load 指令，或者 store 指令要访问属于当前进程但是还未被分配的内存，在我们映射完新申请的物理内存 page 之后，重新执行指令应该就能通过了。</p>
<blockquote>
<p>学生提问：在 eager allocation 的场景，一个进程可能消耗了太多的内存进而耗尽了物理内存资源。如果我们不使用 eager allocation，而是使用 lazy allocation，应用程序怎么才能知道当前已经没有物理内存可用了？</p>
<p>Frans教授：这是个非常好的问题。从应用程序的角度来看，会有一个错觉：存在无限多可用的物理内存。但是在某个时间点，应用程序可能会用光了物理内存，之后如果应用程序再访问一个未被分配的 page，但这时又没有物理内存，这时内核可以有两个选择，我稍后会介绍更复杂的那个。你们在 lazy lab 中要做的是，返回一个错误并杀掉进程。因为现在已经 <strong>OOM（Out Of Memory）</strong>了，内核也无能为力，所以在这个时间点可以杀掉进程。在这节课稍后的部分会介绍，可以有更加聪明的解决方案。</p>
<p>学生提问：如何判断一个地址是新分配的内存还是一个无效的地址？</p>
<p>Frans教授：在地址空间中，我们有 stack，data 和 text。通常来说我们将 <em>p-&gt;sz</em> 设置成一个更大的数，新分配的内存位于旧的 <em>p-&gt;sz</em> 和新的 <em>p-&gt;sz</em> 之间，但是这部分内存还没有实际在物理内存上进行分配。如果使用的地址低于 <em>p-&gt;sz</em>，那么这是一个用户空间的有效地址。如果大于 <em>p-&gt;sz</em>，对应的就是一个程序错误，这意味着用户应用程序在尝试解析一个自己不拥有的内存地址。希望这回答了你的问题。</p>
</blockquote>
<p>为了进一步理解 lazy allocation，我们大概来看一下它的代码会是怎么样？这也是今天唯一编程相关的内容。实际上你可能会感到奇怪，相关的代码是如此的简单。这部分代码介绍对于接下来的 lazy lab 或许会有很大的帮助。</p>
<p>我们首先要修改的是 sys_sbrk 函数，sys_sbrk 会完成实际增加应用程序的地址空间，分配内存等等一系列相关的操作。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306184922759.png" alt="img"></p>
<p>这里我们要修改这个函数，让它只对 p-&gt;sz 加 n，并不执行增加内存的操作。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306184942825.png" alt="img"></p>
<p>修改完之后启动 XV6，并且执行 <code>echo hi</code> ，我们会得到一个 page fault.</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306184958660.png" alt="img"></p>
<p>之所以会得到一个 page fault 是因为，在 shell 中执行程序，shell 会先 fork 一个子进程，子进程会通过 <code>exec </code> 执行 <code>echo</code> 。在这个过程中，shell 会申请一些内存，所以 shell 会调用 sys_sbrk，然后就出错了（注，因为前面修改了代码，调用 sys_sbrk 不会实际分配所需要的内存）。</p>
<p>这里输出的内容包含了一些有趣的信息：</p>
<ul>
<li>这里输出了 SCAUSE 寄存器内容，我们可以看到它的值是15，表明这是一个 store page fault（详见8.1）；</li>
<li>我们可以看到进程的 pid 是3，这极可能是 Shell 的 pid；</li>
<li>我们还可以看到 SEPC 寄存器的值，是 <code>0x12a4</code>；</li>
<li>最后还可以看到出错的虚拟内存地址，也就是 STVAL 寄存器的内容，是 <code>0x4008</code>。</li>
</ul>
<p>我们可以查看 shell 的汇编代码，这是由 Makefile 创建的。我们搜索 SEPC 对应的地址，可以看到这的确是一个store 指令。这看起来就是我们出现 page fault 的位置。</p>
<p>如果我们向前看看汇编代码，我们可以看到 page fault 是出现在 malloc 的实现代码中。这也非常合理，在 malloc 的实现中，我们使用 sbrk 系统调用来获得一些内存，之后会初始化我们刚刚获取到的内存，在 <code>0x12a4</code> 位置，刚刚获取的内存中写入数据，但是实际上我们在向未被分配的内存写入数据。</p>
<p>另一个可以证明内存还没有分配的地方是，XV6 中 Shell 通常是有 4 个 page，包含了 text 和 data。出错的地址在 4 个 page 之外，也就是第 5 个 page，实际上我们在 4 个 page 之外 8 个字节。这也合理，因为在 <code>0x12a4</code> 对应的指令中，a0 持有的是 <code>0x4000</code>，而 8 相对 a0 的偏移量。偏移之后的地址就是我们想要使用的地址（注，也就是出错的地址）。</p>
<p>以上就是 page fault 的信息。我们接下来看看如何能够聪明的处理这里的 page fault。</p>
<p>首先查看 <code>trap.c</code> 中的 <code>usertrap</code> 函数，<code>usertrap</code> 在 lec06 中有介绍。在 <code>usertrap</code> 中根据不同的 <code>SCAUSE</code> 完成不同的操作。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306185259532.png" alt="img"></p>
<p><strong>在 lec06 中，我们是因为 SCAUSE &#x3D;&#x3D; 8 进入的 trap，这是我们处理普通系统调用的代码。如果 SCAUSE 不等于 8，接下来会检查是否有任何的设备中断，如果有的话处理相关的设备中断。如果两个条件都不满足，这里会打印一些信息，并且杀掉进程。</strong></p>
<p>现在我们需要增加一个检查，判断 SCAUSE &#x3D;&#x3D; 15，如果符合条件，我们需要一些定制化的处理。我们这里想要做什么样的定制化处理呢？</p>
<blockquote>
<p>学生回答：我们想要检查 p-&gt;sz 是否大于当前存在 STVAL 寄存器中的虚拟地址。如果大于的话，就实际分配物理内存。</p>
</blockquote>
<p>这是一种处理方式，这里我会以演示为目的简单的处理一下，在 lazy lab 中你们需要完成更多的工作。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306185352953.png" alt="img"></p>
<p>在上面增加的代码中，首先打印一些调试信息。之后分配一个物理内存 page，如果 ka 等于 0，表明没有物理内存我们现在 OOM 了，我们会杀掉进程。如果有物理内存，首先会将内存内容设置为 0，之后将物理内存 page 指向用户地址空间中合适的虚拟内存地址。具体来说，我们首先将虚拟地址向下取整，这里引起 page fault 的虚拟地址是 <code>0x4008</code>，向下取整之后是 <code>0x4000</code>。之后我们将物理内存地址跟取整之后的虚拟内存地址的关系加到 <code>page table</code> 中。对应的 <code>PTE</code> 需要设置常用的权限标志位，在这里是 <code>U，W，R</code> bit 位。</p>
<p>接下来运行一些这部分代码。先重新编译 XV6，再执行 <code>echo hi</code>，我们或许可以乐观的认为现在可以正常工作了。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306185456978.png" alt="img"></p>
<p>但是实际上并没有正常工作。我们这里有两个 page fault，第一个对应的虚拟内存地址是 <code>0x4008</code>，但是很明显在处理这个 <code>page fault</code> 时，我们又有了另一个 <code>page fault</code>  <code>0x13f48</code>。现在唯一的问题是，<code>uvmunmap</code> 在报错，一些它尝试 unmap 的 page 并不存在。</p>
<blockquote>
<p>Q：这里 unmap 的内存是什么？</p>
</blockquote>
<blockquote>
<p>学生回答：之前 lazy allocation 但是又没有实际分配的内存。</p>
</blockquote>
<p>是的，完全正确。这里 unmap 的是之前 lazy allocated，但是又还没有用到的地址。所以对于这个内存，并没有对应的物理内存。所以在 uvmunmap 函数中，当 PTE 的 V 标志位为 0 并且没有对应的 mapping，这并不是一个实际的 panic，这是我们预期的行为。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306185828056.png" alt="img"></p>
<p>实际上，对于这个 page 我们并不用做任何事情，我们可以直接 continue 跳到下一个 page。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306185905449.png" alt="img"></p>
<p>接下来，我们再重新编译 XV6，并执行“echo hi”。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306185921796.png" alt="img"></p>
<p>现在我们可以看到 2个page fault，但是echo hi正常工作了。现在，我们一定程度上有了最基本最简单的lazy allocation。这里有什么问题吗？</p>
<blockquote>
<p>学生提问：我并不能理解为什么在 uvmunmap 中可以直接改成 continue？</p>
<p>Frans教授：之前的 panic 表明，我们尝试在释放一个并没有 map 的 page。怎么会发生这种情况呢？唯一的原因是 sbrk 增加了 <code>p-&gt;sz</code> ，但是应用程序还没有使用那部分内存。因为对应的物理内存还没有分配，所以这部分新增加的内存的确没有映射关系。我们现在是 lazy allocation，我们只会为需要的内存分配物理内存page。如果我们不需要这部分内存，那么就不会存在 map 关系，这非常的合理。相应的，我们对于这部分内存也不能释放，因为没有实际的物理内存可以释放，所以这里最好的处理方式就是 continue，跳过并处理下一个page。</p>
<p>学生提问：在 <code>uvmunmap</code> 中，我认为之前的panic存在是有理由的，我们是不是应该判断一下，然后对于特定的场景还是 panic？</p>
<p>Frans教授：为什么之前的 panic 会存在？对于未修改的 XV6，永远也不会出现用户内存未 map 的情况，所以一旦出现这种情况需要 panic。但是现在我们更改了 XV6，所以我们需要去掉这里的 panic，因为之前的不可能变成了可能。</p>
</blockquote>
<p>这部分内容对于下一个实验有很大的帮助，实际上这是下一个实验 3 个部分中的一个，但是很明显这部分不足以完成下一个 lazy lab。我们这里做了一些修改，但是很多地方还是有可能出错。就像有人提到的，我这里并没有检查触发 page fault 的虚拟地址是否小于 <em>p-&gt;sz</em>。还有其他的可能出错的地方吗？</p>
<blockquote>
<p>学生回答：通过 sbrk 增加的用户进程的内存数是一个整型数而不是一个无符号整型数，可能会传入负数。</p>
</blockquote>
<p>是的，可能会使用负数，这意味着缩小用户内存。当我们在缩小用户内存时，我们也需要小心一些。实际上，在一个操作系统中，我们可能会在各种各样的用户场景中使用这里的 PTE，对于不同的用户场景我们或许需要稍微修改XV6，这就是接下来的 lazy lab 的内容。你们需要完成足够多的修改，才能通过所有的测试用例。</p>
<h3 id="Zero-Fill-On-Demand"><a href="#Zero-Fill-On-Demand" class="headerlink" title="Zero Fill On Demand"></a>Zero Fill On Demand</h3><p>接下来我将讨论基于 page fault 和 page table 可以做的一些其他酷的事情。另一个简单但是使用的非常频繁的功能是 zero-fill-on-demand。</p>
<p>当你查看一个用户程序的地址空间时，存在 text 区域，data 区域，同时还有一个 BSS 区域<strong>（注：BSS区域包含了未被初始化或者初始化为0的全局或者静态变量）。</strong>当编译器在生成二进制文件时，编译器会填入这三个区域。text 区域是程序的指令，data 区域存放的是初始化了的全局变量，BSS 包含了未被初始化或者初始化为0的全局变量。</p>
<p>之所以这些变量要单独列出来，是因为例如你在 C 语言中定义了一个大的矩阵作为全局变量，它的元素初始值都是 0，为什么要为这个矩阵分配内存呢？其实只需要记住这个矩阵的内容是 0 就行。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306190202512.png" alt="img"></p>
<p>在一个正常的操作系统中，如果执行 exec，exec 会申请地址空间，里面会存放 text 和 data。因为 BSS 里面保存了未被初始化的全局变量，这里或许有许多许多个 page，但是所有的 page 内容都为 0。</p>
<p><strong>通常可以调优的地方是，我有如此多的内容全是 0 的 page，在物理内存中，我只需要分配一个 page，这个 page 的内容全是 0。然后将所有虚拟地址空间的全 0 的 page 都 map 到这一个物理 page上。这样至少在程序启动的时候能节省大量的物理内存分配。</strong></p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306190226653.png" alt="img"></p>
<p>当然这里的 mapping 需要非常的小心，<strong>我们不能允许对于这个 page 执行写操作，</strong>因为所有的虚拟地址空间 page 都期望 page 的内容是全 0，所以<strong>这里的 PTE 都是只读的。</strong>之后在某个时间点，应用程序尝试写 BSS 中的一个 page 时，比如说需要更改一两个变量的值，我们会得到 page fault。那么，对于这个特定场景中的 page fault我们该做什么呢？</p>
<blockquote>
<p>学生回答：我认为我们应该创建一个新的 page，将其内容设置为 0，并重新执行指令。</p>
</blockquote>
<blockquote>
<p>教授：是的，完全正确。假设 store 指令发生在 BSS 最顶端的 page 中。我们想要做的是：</p>
<ul>
<li>在物理内存中申请一个新的内存 page，将其内容设置为 0，因为我们预期这个内存的内容为 0。</li>
<li>之后我们需要更新这个 page 的 mapping 关系，首先 PTE 要设置成可读可写，然后将其指向新的物理 page。</li>
<li>这里相当于更新了 PTE，之后我们可以重新执行指令。</li>
</ul>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306190323359.png" alt="img"></p>
<p><strong>为什么这是一个好的优化，或者说为什么操作系统要这么做？</strong></p>
<blockquote>
<p>学生回答：这样节省一部分内存。你可以在需要的时候才申请内存。</p>
</blockquote>
<blockquote>
<p>教授：是的，这里类似于 lazy allocation。假设程序申请了一个大的数组，来保存可能的最大的输入，并且这个数组是全局变量且初始为 0，但是最后或许只有一小部分内容会被使用。</p>
</blockquote>
<p>第二个好处是在 <code>exec</code> 中需要做的工作变少了。程序可以启动的更快，这样你可以获得更好的交互体验，因为你只需要分配一个内容全是 0 的物理 page。所有的虚拟 page 都可以映射到这一个物理 page 上。</p>
<blockquote>
<p>学生提问：但是因为每次都会触发一个 page fault，update 和 write 会变得更慢吧？</p>
<p>Frans教授：是的，这是个很好的观点，所以这里是实际上我们将一些操作推迟到了 page fault 再去执行。并且我们期望并不是所有的 page 都被使用了。如果一个 page 是 4096 字节，我们只需要对每 4096 个字节消耗一次 page fault 即可。但是这里是个好的观点，我们的确增加了一些由 page fault 带来的代价。</p>
</blockquote>
<blockquote>
<p>Q：page fault 的代价是多少呢？我们该如何看待它？这是一个与 store 指令相当的代价，还是说代价要高的多？</p>
<p>学生回答：代价要高的多。store 指令可能需要消耗一些时间来访问 RAM，但是 page fault 需要走到内核。</p>
</blockquote>
<p>是的，在 lec06 中你们已经看到了，仅仅是在 trap 处理代码中，就有至少有 100 个 store 指令用来存储当前的寄存器。除此之外，还有从用户空间转到内核空间的额外开销。所以，page fault 并不是没有代价的，之前问的那个问题是一个非常好的问题。</p>
<h3 id="Copy-on-Write-Fork"><a href="#Copy-on-Write-Fork" class="headerlink" title="Copy on Write Fork"></a>Copy on Write Fork</h3><p>这个是一个非常常见的优化，许多操作系统都实现了它，同时它也是后面一个实验的内容。这就是 copy-on-write fork，有时也称为 COW fork。</p>
<p>当 Shell 处理指令时，它会通过 fork 创建一个子进程。fork 会创建一个 Shell 进程的拷贝，所以这时我们有一个父进程（即 Shell）和一个子进程。Shell 的子进程执行的第一件事情就是调用 exec 运行一些其他程序，比如运行 echo。现在的情况是，fork 创建了 Shell 地址空间的一个完整的拷贝，而 exec 做的第一件事情就是丢弃这个地址空间，取而代之的是一个包含了 echo 的地址空间。这里看起来有点浪费。</p>
<p>所以，我们最开始有了一个父进程的虚拟地址空间，然后我们有了子进程的虚拟地址空间。在物理内存中，XV6 中的 Shell 通常会有 4 个page，当调用 fork 时，基本上就是创建了 4 个新的 page，并将父进程 page 的内容拷贝到 4 个新的子进程的 page 中。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306190627018.png" alt="img"></p>
<p>但是之后，一旦调用了 exec，我们又会释放这些 page，并分配新的 page 来包含 echo 相关的内容。<strong>所以对于这个特定场景有一个非常有效的优化：当我们创建子进程时，与其创建、分配并拷贝内容到新的物理内存，其实我们可以直接共享父进程的物理内存 page。所以这里，我们可以设置子进程的 PTE 指向父进程对应的物理内存 page。</strong></p>
<blockquote>
<p>总结一下，就是 fork 之后，子进程直接共享父进程的物理内存 page，需要注意的是，需要将父进程和子进程的 PTE 标志位均设为只读。 </p>
</blockquote>
<p>当然，需要提及的是，我们这里需要非常小心。因为一旦子进程想要修改这些内存的内容，相应的更新应该对父进程不可见，因为我们希望在父进程和子进程之间有强隔离性，所以这里我们需要更加小心一些。<strong>为了确保进程间的隔离性，我们可以将这里的父进程和子进程的 PTE 的标志位都设置成只读的。</strong></p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306190723589.png" alt="img"></p>
<p>在某个时间点，当我们需要更改内存的内容时，我们会得到 page fault。因为父进程和子进程都会继续运行，而父进程或者子进程都可能会执行 store 指令来更新一些全局变量，这时就会触发 page fault，因为现在在向一个只读的 PTE 写数据。</p>
<p>在得到 page fault 之后，我们需要拷贝相应的物理 page：</p>
<ul>
<li>假设现在是子进程在执行 store 指令，那么我们会分配一个新的物理内存 page，然后将 page fault 相关的物理内存 page 拷贝到新分配的物理内存 page 中</li>
<li>并将新分配的物理内存 page 映射到子进程。</li>
<li>这时，新分配的物理内存 page 只对子进程的地址空间可见，所以我们可以将相应的 PTE 设置成可读写，并且我们可以重新执行 store 指令。实际上，对于触发刚刚 page fault 的物理 page，因为现在只对父进程可见，相应的PTE对于父进程也变成可读写的了。</li>
</ul>
<blockquote>
<p><em>这块我不太赞同，关于父进程的相应 PTE 是否会变为可读写的，父进程怎么判断是否还有子进程绑定到该 PTE 上。</em></p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306190907604.png" alt="img"></p>
<p>所以现在，我们拷贝了一个 page，将新的 page 映射到相应的用户地址空间，并重新执行用户指令。重新执行用户指令是指调用 userret 函数（注，详见6.8），也即是 lec06 中介绍的返回到用户空间的方法。</p>
<blockquote>
<p>学生提问：我们如何发现父进程写了这部分内存地址？是与子进程相同的方法吗？</p>
<p>Frans教授：是的，因为子进程的地址空间来自于父进程的地址空间的拷贝。如果我们使用了特定的虚拟地址，因为地址空间是相同的，不论是父进程还是子进程，都会有相同的处理方式。</p>
<p>学生提问：对于一些没有父进程的进程，比如系统启动的第一个进程，它会对于自己的 PTE 设置成只读的吗？还是设置成可读写的，然后在 fork 的时候再修改成只读的？</p>
<p>Frans教授：这取决于你。实际上在 lazy lab 之后，会有一个 copy-on-write lab。在这个 lab 中，你自己可以选择实现方式。当然最简单的方式就是将 PTE 设置成只读的，当你要写这些 page 时，你会得到一个 page fault，之后你可以再按照上面的流程进行处理。</p>
<p>学生提问：因为我们经常会拷贝用户进程对应的 page，内存硬件有没有实现特定的指令来完成拷贝，因为通常来说内存会有一些读写指令，但是因为我们现在有了从 page A 拷贝到 page B 的需求，会有相应的拷贝指令吗？</p>
<p>Frans教授：x86 有硬件指令可以用来拷贝一段内存。但是 RISC-V 并没有这样的指令。当然在一个高性能的实现中，所有这些读写操作都会流水线化，并且按照内存的带宽速度来运行。</p>
<p>在我们这个例子中，我们只需要拷贝 1 个 page，对于一个未修改的 XV6 系统，我们需要拷贝 4 个 page。所以这里的方法明显更好，因为内存消耗的更少，并且性能会更高，fork 会执行的更快。</p>
<p><strong>这个问题牛逼</strong>：学生提问：当发生 page fault 时，我们其实是在向一个只读的地址执行写操作。内核如何能分辨现在是一个 copy-on-write fork 的场景，而不是应用程序在向一个正常的只读地址写数据。是不是说默认情况下，用户程序的 PTE 都是可读写的，除非在 copy-on-write fork 的场景下才可能出现只读的 PTE ？</p>
<p>Frans教授：内核必须要能够识别这是一个 copy-on-write 场景。几乎所有的 page table 硬件都支持了这一点。我们之前并没有提到相关的内容，下图是一个常见的多级 page table。对于 PTE 的标志位，我之前介绍过第 0 bit到第 7 bit，但是没有介绍最后两位 RSW。这两位保留给 supervisor software 使用，supervisor softeware 指的就是内核。内核可以随意使用这两个 bit 位。<strong>所以可以做的一件事情就是，将bit 8 标识为当前是一个copy-on-write page。</strong></p>
</blockquote>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306191211399.png" alt="img"></p>
<blockquote>
<p>当内核在管理这些 page table 时，对于 copy-on-write 相关的 page，内核可以设置相应的 bit 位，这样当发生 page fault 时，我们可以发现如果 copy-on-write bit 位设置了，我们就可以执行相应的操作了。否则的话，比如说 lazy allocation，我们就做一些其他的处理操作。</p>
<p>在 copy-on-write lab 中，你们会使用 <code>RSW</code> 在 PTE 中设置一个 copy-on-write 标志位。</p>
</blockquote>
<p>在 copy-on-write lab 中，还有个细节需要注意。<strong>目前在 XV6 中，除了 trampoline page 外，一个物理内存 page 只属于一个用户进程。</strong> trampoline page 永远也不会释放，所以也不是什么大问题。但是对于这里的物理内存 page，现在有多个用户进程或者说多个地址空间都指向了相同的物理内存 page，举个例子，当父进程退出时我们需要更加的小心，因为我们要判断是否能立即释放相应的物理 page。如果有子进程还在使用这些物理  page，而内核又释放了这些物理 page，我们将会出问题。那么现在释放内存 page 的依据是什么呢？</p>
<p>我们需要对于每一个物理内存 page 的引用进行计数，当我们释放虚拟 page 时，我们将物理内存 page 的引用数减 1，如果引用数等于 0，那么我们就能释放物理内存 page。所以在 copy-on-write lab 中，你们需要引入一些额外的数据结构或者元数据信息来完成引用计数。</p>
<blockquote>
<p>学生提问：我们可以将引用计数存在 RSW 对应的 2 个bit中吗？并且限制不超过 4 个引用。</p>
<p>Frans教授：讲道理，如果引用超过了 4 次，那么将会是一个问题。因为一个内存引用超过了 4 次，你将不能再使用这里的优化了。但是这里的实现方式是自由的。</p>
<p>学生提问：真的有必要额外增加一位来表示当前的 page 是 copy-on-write 吗？因为内核可以维护有关进程的一些信息…</p>
<p>Frans教授：是的，你可以在管理用户地址空间时维护一些其他的元数据信息，这样你就知道这部分虚拟内存地址如果发生了 page fault，那么必然是 copy-on-write 场景。实际上，在后面的一个实验中，你们需要出于相同的原因扩展 XV6 管理的元数据。在你们完成这些实验时，具体的实现是很自由的。</p>
</blockquote>
<h3 id="Demand-Paging"><a href="#Demand-Paging" class="headerlink" title="Demand Paging"></a>Demand Paging</h3><p>接下来我们将介绍 Demand paging。这是另一个非常流行的功能，许多操作系统都实现了它。</p>
<p>我们回到 exec，在未修改的 XV6 中，操作系统会加载程序内存的 text 、data 区域，并且以 eager 的方式将这些区域加载进 page table。</p>
<p>但是根据我们在 lazy allocation 和 zero-filled on demand 的经验，为什么我们要以 eager 的方式将程序加载到内存中？为什么不再等等，直到应用程序实际需要这些指令的时候再加载内存？程序的二进制文件可能非常的巨大，将它全部从磁盘加载到内存中将会是一个代价很高的操作。又或者 data 区域的大小远大于常见的场景所需要的大小，我们并不一定需要将整个二进制都加载到内存中。</p>
<p>所以对于 exec，在虚拟地址空间中，我们为 text 和 data 分配好地址段，但是相应的 PTE 并不对应任何物理内存page。对于这些 PTE，我们只需要将 valid bit 位设置为 0 即可。</p>
<p>如果我们修改 XV6 使其按照上面的方式工作，我们什么时候会得到第一个 page fault 呢？或者说，用户应用程序运行的第一条指令是什么？用户应用程序在哪里启动的？</p>
<p>应用程序是从地址 0 开始运行。text 区域从地址 0 开始向上增长。位于地址 0 的指令是会触发第一个 page fault的指令，因为我们还没有真正的加载内存。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306191520405.png" alt="img"></p>
<p>那么该如何处理这里的 page fault 呢？</p>
<ul>
<li>首先我们可以发现，这些 page 是 on-demand page。我们需要在某个地方记录了这些 page 对应的程序文件，我们在 page fault handler 中需要从程序文件中读取 page 数据，加载到内存中；</li>
<li>之后将内存 page 映射到 page table；</li>
<li>最后再重新执行指令。</li>
</ul>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306191611689.png" alt="img"></p>
<p>之后程序就可以运行了。在最坏的情况下，用户程序使用了 text 和 data 中的所有内容，那么我们将会在应用程序的每个 page 都收到一个 page fault。但是如果我们幸运的话，用户程序并没有使用所有的 text 区域或者 data 区域，那么我们一方面可以节省一些物理内存，另一方面我们可以让 exec 运行的更快（注，因为不需要为整个程序分配内存）。</p>
<p>前面描述的流程其实是有点问题的：<strong>我们将要读取的文件，它的 text 和 data 区域可能大于物理内存的容量。又或者多个应用程序按照 demand paging 的方式启动，它们二进制文件的和大于实际物理内存的容量。</strong>对于 demand paging 来说，假设内存已经耗尽了或者说 OOM 了，这个时候如果得到了一个 page fault，需要从文件系统拷贝中拷贝一些内容到内存中，但这时你又没有任何可用的物理内存 page，这其实回到了之前的一个问题：在 lazy allocation 中，如果内存耗尽了该如何办？</p>
<p>如果内存耗尽了，一个选择是撤回 page（evict page）。比如说将部分内存 page 中的内容写回到文件系统再撤回 page。一旦你撤回并释放了 page，那么你就有了一个新的空闲的 page，你可以使用这个刚刚空闲出来的 page，分配给刚刚的 page fault handler，再重新执行指令。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306191824249.png" alt="img"></p>
<p>重新运行指令稍微有些复杂，这包含了整个 userret 函数背后的机制以及将程序运行切换回用户空间等等。</p>
<p>以上就是常见操作系统的行为。这里的关键问题是，什么样的 page 可以被撤回？并且该使用什么样的策略来撤回page？</p>
<blockquote>
<p>学生回答：Least Recently Used(LRU)</p>
</blockquote>
<blockquote>
<p>教授：是的，这是最常用的策略，Least Recently Used，或者叫 LRU。除了这个策略之外，还有一些其他的小优化。如果你要撤回一个 page，你需要在 dirty page 和 non-dirty page 中做选择。dirty page 是曾经被写过的 page，而 non-dirty page 是只被读过，但是没有被写过的 page。你们会选择哪个来撤回？</p>
</blockquote>
<blockquote>
<p>学生回答：我会选择 dirty page，因为它在某个时间点会被重新写回到内存中。</p>
</blockquote>
<blockquote>
<p>教授：如果 dirty page 之后再被修改，现在你或许需要对它写两次了（注，一次内存，一次文件），<strong>现实中会选择 non-dirty page</strong>。如果 non-dirty page 出现在 page table 中，你可以将内存 page 中的内容写到文件中，之后将相应的 PTE 标记为 non-valid，这就完成了所有的工作。之后你可以在另一个 page table 重复使用这个 page。所以<strong>通常来说这里优先会选择 non-dirty page 来撤回。</strong></p>
</blockquote>
<blockquote>
<p>学生提问：对于一个 cache，我们可以认为它被修改了但是还没有回写到后端存储时是 dirty 的。那么对于内存 page 来说，怎么判断 dirty？它只存在于内存中，而不存在于其他地方。那么它什么时候会变成 dirty 呢？</p>
<p>Frans教授：对于memory mapped files，你将一个文件映射到内存中，然后恢复它，你就会设置内存 page为 dirty。</p>
<p>学生提问：所以这只对一个不仅映射了内存，还映射了文件的 page 有效？</p>
<p>Frans教授：是的，完全正确。（注，这里应该是答非所问，一个 page 只要最近被写过，那么就会是 dirty的）</p>
</blockquote>
<p>如果你们再看 PTE，我们有 RSW 位，你们可以发现在 bit7，对应的就是 Dirty bit。当硬件向一个 page 写入数据，会设置 dirty bit，之后操作系统就可以发现这个 page 曾经被写入了。类似的，还有一个 Access bit，任何时候一个 page 被读或者被写了，这个 Access bit 会被设置。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306192032842.png" alt="img"></p>
<p>为什么这两个信息重要呢？它们能怎样帮助内核呢？</p>
<blockquote>
<p>学生回答：没有被 Access 过的 page 可以直接撤回，是吗？</p>
</blockquote>
<p>是的，或者说如果你想实现 LRU，你需要找到一个在一定时间内没有被访问过的 page，那么这个 page 可以被用来撤回。而被访问过的 page 不能被撤回。所以 Access bit 通常被用来实现这里的LRU策略。</p>
<blockquote>
<p>学生提问：那是不是要定时的将 Access bit 恢复成 0？</p>
<p>Frans教授：是的，这是一个典型操作系统的行为。操作系统会扫描整个内存，这里有一些著名的算法例如 clock algorithm，就是一种实现方式。</p>
<p>另一个学生提问：为什么需要恢复这个 bit？</p>
<p>Frans教授：如果你想知道 page 最近是否被使用过，你需要定时比如每 100 毫秒或者每秒清除 Access  bit，如果在下一个 100 毫秒这个 page 被访问过，那你就知道这个 page 在上一个 100 毫秒中被使用了。而Access bit为0的page在上100毫秒未被使用。这样你就可以统计每个内存page使用的频度，这是一个成熟的LRU实现的基础。（注，可以通过 Access bit 来决定内存 page 在 LRU 中的排名）</p>
</blockquote>
<h3 id="Memory-Paging-Files"><a href="#Memory-Paging-Files" class="headerlink" title="Memory Paging Files"></a>Memory Paging Files</h3><p>这节课最后要讨论的内容，也是后面的一个实验，就是 memory mapped files。<strong>这里的核心思想是，将完整或者部分文件加载到内存中，这样就可以通过内存地址相关的 load 或者 store 指令来操纵文件。</strong>为了支持这个功能，一个现代的操作系统会提供一个叫做 mmap 的系统调用。这个系统调用会接收一个虚拟内存地址（VA），长度（len），protection，一些标志位，一个打开文件的文件描述符，和偏移量（offset）。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306192556016.png" alt="img"></p>
<p><strong>这里的语义是，从文件描述符对应的文件的偏移量的位置开始，映射长度为 len 的内容到虚拟内存地址 VA，同时我们需要加上一些保护，比如只读或者读写。</strong></p>
<p>假设文件内容是读写并且内核实现 mmap 的方式是 eager 方式（不过大部分系统都不会这么做），内核会从文件的 offset 位置开始，将数据拷贝到内存，设置好 PTE 指向物理内存的位置。之后应用程序就可以使用 load 或者 store 指令来修改内存中对应的文件内容。当完成操作之后，会有一个对应的 unmap 系统调用，参数是虚拟地址（VA），长度（len）。来表明应用程序已经完成了对文件的操作，在 unmap 时间点，我们需要将 dirty block 写回到文件中。我们可以很容易的找到哪些 block 是 dirty 的，因为它们在 PTE 中的 dirty bit 为1。</p>
<p><img src="https://blog-img-acking.oss-cn-beijing.aliyuncs.com/img/image-20220306192814771.png" alt="img"></p>
<p>当然，在任何聪明的内存管理机制中，所有的这些都是以 lazy 的方式实现。你不会立即将文件内容拷贝到内存中，而是先记录一下这个 PTE 属于这个文件描述符。相应的信息通常在 VMA 结构体中保存，VMA 全称是 <em>Virtual Memory Area</em>。例如对于这里的文件 f，会有一个 VMA，在 VMA 中我们会记录文件描述符，偏移量等等，这些信息用来表示对应的内存虚拟地址的实际内容在哪，这样当我们得到一个位于 VMA 地址范围的 page fault 时，内核可以从磁盘中读数据，并加载到内存中。所以这里回答之前一个问题，dirty bit 是很重要的，因为在 unmap 中，你需要向文件回写dirty block。</p>
<blockquote>
<p>学生提问：mmap 的参数中，len 和 flag 是什么意思？</p>
<p>Frans教授：len 是文件中你想映射到内存中的字节数。prot 是 read&#x2F;write。flags 会在 mmap lab 中出现，我认为它表示了这个区域是私有的还是共享的。如果是共享的，那么这个区域可以在多个进程之间共享。</p>
<p>学生提问：如果其他进程直接修改了文件的内容，那么是不是意味着修改的内容不会体现在这里的内存中？</p>
<p>Frans教授：是的。但是如果文件是共享的，那么你应该同步这些变更。我记不太清楚在 mmap 中，文件共享时会发生什么。</p>
</blockquote>
<p>你们会在 file system lab 之后做这里相关的 mmap lab，这将会是我们最后一个虚拟内存实验。</p>
<p>最后来总结一下最近几节课的内容，我们首先详细看了一下 page table 是如何工作的，之后我们详细看了一下 trap 是如何工作的。而 page fault 结合了这两部分的内容，可以用来实现非常强大且优雅的虚拟内存功能。</p>
<p>我们这节课介绍的内容，只是操作系统里面基于 page fault 功能的子集。一个典型的操作系统实现了今天讨论的所有内容，如果你查看 Linux，它包含了所有的内容，以及许多其他有趣的功能。今天的内容希望能给让你们理解，一旦你可以在 page fault handler 中动态的更新 page table，虚拟内存将会变得有多强大。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Sam Shen"
      src="/uploads/1.jpg">
  <p class="site-author-name" itemprop="name">Sam Shen</p>
  <div class="site-description" itemprop="description">share cs knowledge</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">6</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Sam Shen</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://muse.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
